{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67f7dd71",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T05:01:48.376026Z",
     "iopub.status.busy": "2024-01-08T05:01:48.375573Z",
     "iopub.status.idle": "2024-01-08T05:01:56.694311Z",
     "shell.execute_reply": "2024-01-08T05:01:56.692991Z"
    },
    "papermill": {
     "duration": 8.348857,
     "end_time": "2024-01-08T05:01:56.697253",
     "exception": false,
     "start_time": "2024-01-08T05:01:48.348396",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import re,torch,os\n",
    "from collections import Counter,defaultdict\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "from sklearn.linear_model import Lasso, ElasticNet, BayesianRidge, LassoLarsIC\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import KFold, cross_val_score, StratifiedKFold, GridSearchCV, train_test_split\n",
    "from scipy.stats import skew, kurtosis\n",
    "import warnings\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.metrics import mean_squared_error\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.ensemble import StackingRegressor, VotingRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "import lightgbm as lgb\n",
    "\n",
    "\n",
    "import random\n",
    "seed=2023\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bb52cf7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T05:01:56.748726Z",
     "iopub.status.busy": "2024-01-08T05:01:56.748231Z",
     "iopub.status.idle": "2024-01-08T05:02:22.170274Z",
     "shell.execute_reply": "2024-01-08T05:02:22.169353Z"
    },
    "papermill": {
     "duration": 25.45058,
     "end_time": "2024-01-08T05:02:22.172684",
     "exception": false,
     "start_time": "2024-01-08T05:01:56.722104",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train_logs):8405898\n",
      "len(test_logs):6\n"
     ]
    }
   ],
   "source": [
    "train_logs=pd.read_csv(\"/kaggle/input/linking-writing-processes-to-writing-quality/train_logs.csv\")\n",
    "print(f\"len(train_logs):{len(train_logs)}\")\n",
    "train_logs=train_logs.sort_values(by=['id', 'down_time'])\n",
    "train_logs = train_logs.reset_index(drop=True)\n",
    "train_logs['event_id'] = train_logs.groupby('id').cumcount() + 1\n",
    "train_scores=pd.read_csv(\"/kaggle/input/linking-writing-processes-to-writing-quality/train_scores.csv\")\n",
    "test_logs=pd.read_csv(\"/kaggle/input/linking-writing-processes-to-writing-quality/test_logs.csv\")\n",
    "print(f\"len(test_logs):{len(test_logs)}\")\n",
    "test_logs=test_logs.sort_values(by=['id', 'down_time'])\n",
    "test_logs = test_logs.reset_index(drop=True)\n",
    "test_logs['event_id'] = test_logs.groupby('id').cumcount() + 1\n",
    "test_logs.to_csv(\"test_logs.csv\",index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c52b14b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T05:02:22.225316Z",
     "iopub.status.busy": "2024-01-08T05:02:22.224839Z",
     "iopub.status.idle": "2024-01-08T05:02:22.243695Z",
     "shell.execute_reply": "2024-01-08T05:02:22.242377Z"
    },
    "papermill": {
     "duration": 0.048604,
     "end_time": "2024-01-08T05:02:22.246219",
     "exception": false,
     "start_time": "2024-01-08T05:02:22.197615",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def getEssays(df):\n",
    "    textInputDf = df[['id', 'activity', 'cursor_position', 'text_change']]\n",
    "    textInputDf = textInputDf[textInputDf.activity != 'Nonproduction']\n",
    "    valCountsArr = textInputDf['id'].value_counts(sort=False).values\n",
    "    lastIndex = 0\n",
    "    essaySeries = pd.Series()\n",
    "    \n",
    "    for index, valCount in enumerate(valCountsArr):\n",
    "        currTextInput = textInputDf[['activity', 'cursor_position', 'text_change']].iloc[lastIndex : lastIndex + valCount]\n",
    "        lastIndex += valCount\n",
    "        essayText = \"\"\n",
    "        \n",
    "        for Input in currTextInput.values:\n",
    "            if Input[0] == 'Replace':\n",
    "                replaceTxt = Input[2].split(' => ')\n",
    "                essayText = essayText[:Input[1] - len(replaceTxt[1])] + replaceTxt[1] + essayText[Input[1] - len(replaceTxt[1]) + len(replaceTxt[0]):]\n",
    "                continue\n",
    "            if Input[0] == 'Paste':\n",
    "                essayText = essayText[:Input[1] - len(Input[2])] + Input[2] + essayText[Input[1] - len(Input[2]):]\n",
    "                continue\n",
    "            if Input[0] == 'Remove/Cut':\n",
    "                essayText = essayText[:Input[1]] + essayText[Input[1] + len(Input[2]):]\n",
    "                continue\n",
    "            \n",
    "            if \"M\" in Input[0]:\n",
    "                croppedTxt = Input[0][10:]\n",
    "                splitTxt = croppedTxt.split(' To ')\n",
    "                valueArr = [item.split(', ') for item in splitTxt]\n",
    "                moveData = (int(valueArr[0][0][1:]), \n",
    "                            int(valueArr[0][1][:-1]), \n",
    "                            int(valueArr[1][0][1:]), \n",
    "                            int(valueArr[1][1][:-1]))\n",
    "                \n",
    "                if moveData[0] != moveData[2]:\n",
    "                    if moveData[0] < moveData[2]:\n",
    "                        essayText = essayText[:moveData[0]] + essayText[moveData[1]:moveData[3]] +\\\n",
    "                        essayText[moveData[0]:moveData[1]] + essayText[moveData[3]:]\n",
    "                    else:\n",
    "                        essayText = essayText[:moveData[2]] + essayText[moveData[0]:moveData[1]] +\\\n",
    "                        essayText[moveData[2]:moveData[0]] + essayText[moveData[1]:]\n",
    "                continue\n",
    "            \n",
    "            essayText = essayText[:Input[1] - len(Input[2])] + Input[2] + essayText[Input[1] - len(Input[2]):]\n",
    "        \n",
    "        essaySeries[index] = essayText\n",
    "    \n",
    "    essaySeries.index =  textInputDf['id'].unique()\n",
    "    return pd.DataFrame(essaySeries, columns=['essay']).reset_index().rename(columns={\"index\":'id'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0bd5e8e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T05:02:22.298192Z",
     "iopub.status.busy": "2024-01-08T05:02:22.297369Z",
     "iopub.status.idle": "2024-01-08T05:02:22.321101Z",
     "shell.execute_reply": "2024-01-08T05:02:22.320232Z"
    },
    "papermill": {
     "duration": 0.05328,
     "end_time": "2024-01-08T05:02:22.323656",
     "exception": false,
     "start_time": "2024-01-08T05:02:22.270376",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def q1(x):\n",
    "    return x.quantile(0.25)\n",
    "\n",
    "def q3(x):\n",
    "    return x.quantile(0.75)\n",
    "\n",
    "AGGREGATIONS = ['count', 'mean', 'std', 'min', 'max', 'first', 'last', 'sem', q1, 'median', q3, 'skew', kurtosis, 'sum']\n",
    "\n",
    "def split_essays_into_words(df):\n",
    "    essay_df = df\n",
    "    essay_df['word'] = essay_df['essay'].apply(lambda x: re.split(' |\\\\n|\\\\.|\\\\?|\\\\!', x))\n",
    "    essay_df = essay_df.explode('word')\n",
    "    essay_df['word_len'] = essay_df['word'].apply(lambda x: len(x))\n",
    "    essay_df = essay_df[essay_df['word_len'] != 0]\n",
    "    return essay_df\n",
    "\n",
    "def compute_word_aggregations(word_df):\n",
    "    word_agg_df = word_df[['id','word_len']].groupby(['id']).agg(AGGREGATIONS)\n",
    "    word_agg_df.columns = ['_'.join(x) for x in word_agg_df.columns]\n",
    "    word_agg_df['id'] = word_agg_df.index\n",
    "    \n",
    "    for word_l in [5, 6, 7, 8, 9, 10, 11, 12]:\n",
    "        word_agg_df[f'word_len_ge_{word_l}_count'] = word_df[word_df['word_len'] >= word_l].groupby(['id']).count().iloc[:, 0]\n",
    "        word_agg_df[f'word_len_ge_{word_l}_count'] = word_agg_df[f'word_len_ge_{word_l}_count'].fillna(0)\n",
    "    \n",
    "    word_agg_df = word_agg_df.reset_index(drop=True)\n",
    "    return word_agg_df\n",
    "\n",
    "def split_essays_into_sentences(df):\n",
    "    essay_df = df\n",
    "    essay_df['sent'] = essay_df['essay'].apply(lambda x: re.split('\\\\.|\\\\?|\\\\!', x))\n",
    "    essay_df = essay_df.explode('sent')\n",
    "    essay_df['sent'] = essay_df['sent'].apply(lambda x: x.replace('\\n', '').strip())\n",
    "    essay_df['sent_len'] = essay_df['sent'].apply(lambda x: len(x))\n",
    "    essay_df['sent_word_count'] = essay_df['sent'].apply(lambda x: len(x.split(' ')))\n",
    "    essay_df = essay_df[essay_df.sent_len != 0].reset_index(drop=True)\n",
    "    return essay_df\n",
    "\n",
    "def compute_sentence_aggregations(df):\n",
    "    sent_agg_df = pd.concat(\n",
    "        [df[['id','sent_len']].groupby(['id']).agg(AGGREGATIONS), df[['id','sent_word_count']].groupby(['id']).agg(AGGREGATIONS)], axis=1\n",
    "    )\n",
    "    sent_agg_df.columns = ['_'.join(x) for x in sent_agg_df.columns]\n",
    "    sent_agg_df['id'] = sent_agg_df.index\n",
    "    \n",
    "    for sent_l in [50, 60, 75, 100]:\n",
    "        sent_agg_df[f'sent_len_ge_{sent_l}_count'] = df[df['sent_len'] >= sent_l].groupby(['id']).count().iloc[:, 0]\n",
    "        sent_agg_df[f'sent_len_ge_{sent_l}_count'] = sent_agg_df[f'sent_len_ge_{sent_l}_count'].fillna(0)\n",
    "    \n",
    "    sent_agg_df = sent_agg_df.reset_index(drop=True)\n",
    "    sent_agg_df.drop(columns=[\"sent_word_count_count\"], inplace=True)\n",
    "    sent_agg_df = sent_agg_df.rename(columns={\"sent_len_count\":\"sent_count\"})\n",
    "    return sent_agg_df\n",
    "\n",
    "def split_essays_into_paragraphs(df):\n",
    "    essay_df = df\n",
    "    essay_df['paragraph'] = essay_df['essay'].apply(lambda x: x.split('\\n'))\n",
    "    essay_df = essay_df.explode('paragraph')\n",
    "    essay_df['paragraph_len'] = essay_df['paragraph'].apply(lambda x: len(x)) \n",
    "    essay_df['paragraph_word_count'] = essay_df['paragraph'].apply(lambda x: len(x.split(' ')))\n",
    "    essay_df = essay_df[essay_df.paragraph_len != 0].reset_index(drop=True)\n",
    "    return essay_df\n",
    "\n",
    "def compute_paragraph_aggregations(df):\n",
    "    paragraph_agg_df = pd.concat(\n",
    "        [df[['id','paragraph_len']].groupby(['id']).agg(AGGREGATIONS), df[['id','paragraph_word_count']].groupby(['id']).agg(AGGREGATIONS)], axis=1\n",
    "    ) \n",
    "    paragraph_agg_df.columns = ['_'.join(x) for x in paragraph_agg_df.columns]\n",
    "    paragraph_agg_df['id'] = paragraph_agg_df.index\n",
    "    paragraph_agg_df = paragraph_agg_df.reset_index(drop=True)\n",
    "    paragraph_agg_df.drop(columns=[\"paragraph_word_count_count\"], inplace=True)\n",
    "    paragraph_agg_df = paragraph_agg_df.rename(columns={\"paragraph_len_count\":\"paragraph_count\"})\n",
    "    return paragraph_agg_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0f7d1f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T05:02:22.374537Z",
     "iopub.status.busy": "2024-01-08T05:02:22.374064Z",
     "iopub.status.idle": "2024-01-08T05:02:53.182196Z",
     "shell.execute_reply": "2024-01-08T05:02:53.180876Z"
    },
    "papermill": {
     "duration": 30.862225,
     "end_time": "2024-01-08T05:02:53.210171",
     "exception": false,
     "start_time": "2024-01-08T05:02:22.347946",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_essays\n",
      "train_word_agg_df\n",
      "train_sent_agg_df\n",
      "train_paragraph_agg_df\n",
      "test_essays\n",
      "test_word_agg_df\n",
      "test_sent_agg_df\n",
      "test_paragraph_agg_df\n"
     ]
    }
   ],
   "source": [
    "print(\"train_essays\")\n",
    "train_essays = pd.read_csv('/kaggle/input/writing-quality-challenge-constructed-essays/train_essays_fast.csv')\n",
    "print(\"train_word_agg_df\")\n",
    "train_word_agg_df = compute_word_aggregations(split_essays_into_words(train_essays))\n",
    "print(\"train_sent_agg_df\")\n",
    "train_sent_agg_df = compute_sentence_aggregations(split_essays_into_sentences(train_essays))\n",
    "print(\"train_paragraph_agg_df\")\n",
    "train_paragraph_agg_df = compute_paragraph_aggregations(split_essays_into_paragraphs(train_essays))\n",
    "print(\"test_essays\")\n",
    "test_essays = getEssays(test_logs)\n",
    "test_essays_copy=test_essays.copy()\n",
    "print(\"test_word_agg_df\")\n",
    "test_word_agg_df = compute_word_aggregations(split_essays_into_words(test_essays))\n",
    "print(\"test_sent_agg_df\")\n",
    "test_sent_agg_df = compute_sentence_aggregations(split_essays_into_sentences(test_essays))\n",
    "print(\"test_paragraph_agg_df\")\n",
    "test_paragraph_agg_df = compute_paragraph_aggregations(split_essays_into_paragraphs(test_essays))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00f4e777",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T05:02:53.263739Z",
     "iopub.status.busy": "2024-01-08T05:02:53.263312Z",
     "iopub.status.idle": "2024-01-08T05:09:33.844092Z",
     "shell.execute_reply": "2024-01-08T05:09:33.842815Z"
    },
    "papermill": {
     "duration": 400.610593,
     "end_time": "2024-01-08T05:09:33.846445",
     "exception": false,
     "start_time": "2024-01-08T05:02:53.235852",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineering features for training data\n",
      "Starting to engineer features\n",
      "Engineering time data\n",
      "-> for gap 1\n",
      "-> for gap 2\n",
      "-> for gap 3\n",
      "-> for gap 5\n",
      "-> for gap 10\n",
      "-> for gap 20\n",
      "-> for gap 50\n",
      "-> for gap 100\n",
      "Engineering cursor position data\n",
      "-> for gap 1\n",
      "-> for gap 2\n",
      "-> for gap 3\n",
      "-> for gap 5\n",
      "-> for gap 10\n",
      "-> for gap 20\n",
      "-> for gap 50\n",
      "-> for gap 100\n",
      "Engineering word count data\n",
      "-> for gap 1\n",
      "-> for gap 2\n",
      "-> for gap 3\n",
      "-> for gap 5\n",
      "-> for gap 10\n",
      "-> for gap 20\n",
      "-> for gap 50\n",
      "-> for gap 100\n",
      "Engineering statistical summaries for features\n",
      "Engineering activity counts data\n",
      "Engineering event counts data\n",
      "Engineering text change counts data\n",
      "Engineering punctuation counts data\n",
      "Engineering input words data\n",
      "Engineering ratios data\n",
      "Done!\n",
      "-------------------------\n",
      "Engineering features for test data\n",
      "Starting to engineer features\n",
      "Engineering time data\n",
      "-> for gap 1\n",
      "-> for gap 2\n",
      "-> for gap 3\n",
      "-> for gap 5\n",
      "-> for gap 10\n",
      "-> for gap 20\n",
      "-> for gap 50\n",
      "-> for gap 100\n",
      "Engineering cursor position data\n",
      "-> for gap 1\n",
      "-> for gap 2\n",
      "-> for gap 3\n",
      "-> for gap 5\n",
      "-> for gap 10\n",
      "-> for gap 20\n",
      "-> for gap 50\n",
      "-> for gap 100\n",
      "Engineering word count data\n",
      "-> for gap 1\n",
      "-> for gap 2\n",
      "-> for gap 3\n",
      "-> for gap 5\n",
      "-> for gap 10\n",
      "-> for gap 20\n",
      "-> for gap 50\n",
      "-> for gap 100\n",
      "Engineering statistical summaries for features\n",
      "Engineering activity counts data\n",
      "Engineering event counts data\n",
      "Engineering text change counts data\n",
      "Engineering punctuation counts data\n",
      "Engineering input words data\n",
      "Engineering ratios data\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "class Preprocessor:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.activities = ['Input', 'Remove/Cut', 'Nonproduction', 'Replace', 'Paste', 'Move From']\n",
    "        self.events = ['q', 'Space', 'Backspace', 'Shift', 'ArrowRight', 'Leftclick', 'ArrowLeft', '.', ',',\n",
    "                       'ArrowDown', 'ArrowUp', 'Enter', 'CapsLock', \"'\", 'Delete', 'Unidentified']\n",
    "        self.text_changes = ['q', ' ', 'NoChange', '.', ',', '\\n', \"'\", '\"', '-', '?', ';', '=', '/', '\\\\', ':']\n",
    "        self.punctuations = ['\"', '.', ',', \"'\", '-', ';', ':', '?', '!', '<', '>', '/', '@', '#', '$', '%', '^', '&', '*', '(', ')', '_', '+']\n",
    "        self.gaps = [1, 2, 3, 5, 10, 20, 50, 100]\n",
    "        self.idf = defaultdict(float)\n",
    "\n",
    "    def activity_counts(self, df):\n",
    "        tmp_df = df.groupby('id').agg({'activity': list}).reset_index()\n",
    "        ret = list()\n",
    "        for li in tmp_df['activity'].values:\n",
    "            items = list(Counter(li).items())\n",
    "            di = dict()\n",
    "            for k in self.activities:\n",
    "                di[k] = 0\n",
    "            for item in items:\n",
    "                k, v = item[0], item[1]\n",
    "                if k in di:\n",
    "                    di[k] = v\n",
    "            ret.append(di)\n",
    "        ret = pd.DataFrame(ret)\n",
    "        cols = [f'activity_{i}_count' for i in range(len(ret.columns))]\n",
    "        ret.columns = cols\n",
    "        cnts = ret.sum(1)\n",
    "\n",
    "        for col in cols:\n",
    "            if col in self.idf.keys():\n",
    "                idf = self.idf[col]\n",
    "            else:\n",
    "                idf = np.log(df.shape[0] / (ret[col].sum() + 1))\n",
    "                self.idf[col] = idf\n",
    "            ret[col] = 1 + np.log(ret[col] / cnts)\n",
    "            ret[col] *= idf\n",
    "\n",
    "        return ret\n",
    "\n",
    "    def event_counts(self, df, colname):\n",
    "        tmp_df = df.groupby('id').agg({colname: list}).reset_index()\n",
    "        ret = list()\n",
    "        for li in tmp_df[colname].values:\n",
    "            items = list(Counter(li).items())\n",
    "            di = dict()\n",
    "            for k in self.events:\n",
    "                di[k] = 0\n",
    "            for item in items:\n",
    "                k, v = item[0], item[1]\n",
    "                if k in di:\n",
    "                    di[k] = v\n",
    "            ret.append(di)\n",
    "        ret = pd.DataFrame(ret)\n",
    "        cols = [f'{colname}_{i}_count' for i in range(len(ret.columns))]\n",
    "        ret.columns = cols\n",
    "        cnts = ret.sum(1)\n",
    "\n",
    "        for col in cols:\n",
    "            if col in self.idf.keys():\n",
    "                idf = self.idf[col]\n",
    "            else:\n",
    "                idf = df.shape[0] / (ret[col].sum() + 1)\n",
    "                idf = np.log(idf)\n",
    "                self.idf[col] = idf\n",
    "\n",
    "            ret[col] = 1 + np.log(ret[col] / cnts)\n",
    "            ret[col] *= idf\n",
    "\n",
    "        return ret\n",
    "\n",
    "    def text_change_counts(self, df):\n",
    "        tmp_df = df.groupby('id').agg({'text_change': list}).reset_index()\n",
    "        ret = list()\n",
    "        for li in tmp_df['text_change'].values:\n",
    "            items = list(Counter(li).items())\n",
    "            di = dict()\n",
    "            for k in self.text_changes:\n",
    "                di[k] = 0\n",
    "            for item in items:\n",
    "                k, v = item[0], item[1]\n",
    "                if k in di:\n",
    "                    di[k] = v\n",
    "            ret.append(di)\n",
    "        ret = pd.DataFrame(ret)\n",
    "        cols = [f'text_change_{i}_count' for i in range(len(ret.columns))]\n",
    "        ret.columns = cols\n",
    "        cnts = ret.sum(1)\n",
    "\n",
    "        for col in cols:\n",
    "            if col in self.idf.keys():\n",
    "                idf = self.idf[col]\n",
    "            else:\n",
    "                idf = df.shape[0] / (ret[col].sum() + 1)\n",
    "                idf = np.log(idf)\n",
    "                self.idf[col] = idf\n",
    "\n",
    "            ret[col] = 1 + np.log(ret[col] / cnts)\n",
    "            ret[col] *= idf\n",
    "\n",
    "        return ret\n",
    "\n",
    "    def match_punctuations(self, df):\n",
    "        tmp_df = df.groupby('id').agg({'down_event': list}).reset_index()\n",
    "        ret = list()\n",
    "        for li in tmp_df['down_event'].values:\n",
    "            cnt = 0\n",
    "            items = list(Counter(li).items())\n",
    "            for item in items:\n",
    "                k, v = item[0], item[1]\n",
    "                if k in self.punctuations:\n",
    "                    cnt += v\n",
    "            ret.append(cnt)\n",
    "        ret = pd.DataFrame({'punct_cnt': ret})\n",
    "        return ret\n",
    "\n",
    "    def get_input_words(self, df):\n",
    "        tmp_df = df[(~df['text_change'].str.contains('=>')) & (df['text_change'] != 'NoChange')].reset_index(drop=True)\n",
    "        tmp_df = tmp_df.groupby('id').agg({'text_change': list}).reset_index()\n",
    "        tmp_df['text_change'] = tmp_df['text_change'].apply(lambda x: ''.join(x))\n",
    "        tmp_df['text_change'] = tmp_df['text_change'].apply(lambda x: re.findall(r'q+', x))\n",
    "        tmp_df['input_word_count'] = tmp_df['text_change'].apply(len)\n",
    "        tmp_df['input_word_length_mean'] = tmp_df['text_change'].apply(lambda x: np.mean([len(i) for i in x] if len(x) > 0 else 0))\n",
    "        tmp_df['input_word_length_max'] = tmp_df['text_change'].apply(lambda x: np.max([len(i) for i in x] if len(x) > 0 else 0))\n",
    "        tmp_df['input_word_length_std'] = tmp_df['text_change'].apply(lambda x: np.std([len(i) for i in x] if len(x) > 0 else 0))\n",
    "        tmp_df.drop(['text_change'], axis=1, inplace=True)\n",
    "        return tmp_df\n",
    "\n",
    "    def make_feats(self, df):\n",
    "        print(\"Starting to engineer features\")\n",
    "        feats = pd.DataFrame({'id': df['id'].unique().tolist()})\n",
    "        print(\"Engineering time data\")\n",
    "        for gap in self.gaps:\n",
    "            print(f\"-> for gap {gap}\")\n",
    "            df[f'up_time_shift{gap}'] = df.groupby('id')['up_time'].shift(gap)\n",
    "            df[f'action_time_gap{gap}'] = df['down_time'] - df[f'up_time_shift{gap}']\n",
    "        df.drop(columns=[f'up_time_shift{gap}' for gap in self.gaps], inplace=True)\n",
    "\n",
    "        print(\"Engineering cursor position data\")\n",
    "        for gap in self.gaps:\n",
    "            print(f\"-> for gap {gap}\")\n",
    "            df[f'cursor_position_shift{gap}'] = df.groupby('id')['cursor_position'].shift(gap)\n",
    "            df[f'cursor_position_change{gap}'] = df['cursor_position'] - df[f'cursor_position_shift{gap}']\n",
    "            df[f'cursor_position_abs_change{gap}'] = np.abs(df[f'cursor_position_change{gap}'])\n",
    "        df.drop(columns=[f'cursor_position_shift{gap}' for gap in self.gaps], inplace=True)\n",
    "\n",
    "        print(\"Engineering word count data\")\n",
    "        for gap in self.gaps:\n",
    "            print(f\"-> for gap {gap}\")\n",
    "            df[f'word_count_shift{gap}'] = df.groupby('id')['word_count'].shift(gap)\n",
    "            df[f'word_count_change{gap}'] = df['word_count'] - df[f'word_count_shift{gap}']\n",
    "            df[f'word_count_abs_change{gap}'] = np.abs(df[f'word_count_change{gap}'])\n",
    "        df.drop(columns=[f'word_count_shift{gap}' for gap in self.gaps], inplace=True)\n",
    "\n",
    "        print(\"Engineering statistical summaries for features\")\n",
    "        feats_stat = [\n",
    "            ('event_id', ['max']),\n",
    "            ('down_time',['mean', 'std', 'min', 'max', 'last', 'first', 'sem', 'median', 'sum']),\n",
    "            ('up_time',['mean', 'std', 'min', 'max', 'last', 'first', 'sem', 'median', 'sum']),\n",
    "            ('action_time', ['max', 'min', 'mean', 'std', 'quantile', 'sem', 'sum', 'skew', pd.DataFrame.kurt,'last', 'first','median']),\n",
    "            ('activity', ['nunique']),\n",
    "            ('down_event', ['nunique']),\n",
    "            ('up_event', ['nunique']),\n",
    "            ('text_change', ['nunique']),\n",
    "            ('cursor_position', ['nunique', 'max', 'quantile', 'sem', 'mean', 'std', 'min','last', 'first',  'median', 'sum']),\n",
    "            ('word_count', ['nunique', 'max', 'quantile', 'sem', 'mean', 'std', 'min', 'last', 'first','median', 'sum'])]\n",
    "        for gap in self.gaps:\n",
    "            feats_stat.extend([\n",
    "                (f'action_time_gap{gap}', ['max', 'min', 'mean', 'std', 'quantile', 'sem', 'sum', 'skew', pd.DataFrame.kurt]),\n",
    "                (f'cursor_position_change{gap}', ['max', 'mean', 'std', 'quantile', 'sem', 'sum', 'skew', pd.DataFrame.kurt]),\n",
    "                (f'word_count_change{gap}', ['max', 'mean', 'std', 'quantile', 'sem', 'sum', 'skew', pd.DataFrame.kurt])\n",
    "            ])\n",
    "\n",
    "        pbar = feats_stat\n",
    "        for item in pbar:\n",
    "            colname, methods = item[0], item[1]\n",
    "            for method in methods:\n",
    "                if isinstance(method, str):\n",
    "                    method_name = method\n",
    "                else:\n",
    "                    method_name = method.__name__\n",
    "                tmp_df = df.groupby(['id']).agg({colname: method}).reset_index().rename(columns={colname: f'{colname}_{method_name}'})\n",
    "                feats = feats.merge(tmp_df, on='id', how='left')\n",
    "\n",
    "        print(\"Engineering activity counts data\")\n",
    "        tmp_df = self.activity_counts(df)\n",
    "        feats = pd.concat([feats, tmp_df], axis=1)\n",
    "        print(\"Engineering event counts data\")\n",
    "        tmp_df = self.event_counts(df, 'down_event')\n",
    "        feats = pd.concat([feats, tmp_df], axis=1)\n",
    "        tmp_df = self.event_counts(df, 'up_event')\n",
    "        feats = pd.concat([feats, tmp_df], axis=1)\n",
    "\n",
    "        print(\"Engineering text change counts data\")\n",
    "        tmp_df = self.text_change_counts(df)\n",
    "        feats = pd.concat([feats, tmp_df], axis=1)\n",
    "\n",
    "        print(\"Engineering punctuation counts data\")\n",
    "        tmp_df = self.match_punctuations(df)\n",
    "        feats = pd.concat([feats, tmp_df], axis=1)\n",
    "\n",
    "        print(\"Engineering input words data\")\n",
    "        tmp_df = self.get_input_words(df)\n",
    "        feats = pd.merge(feats, tmp_df, on='id', how='left')\n",
    "\n",
    "        print(\"Engineering ratios data\")\n",
    "        feats['word_time_ratio'] = feats['word_count_max'] / feats['up_time_max']\n",
    "        feats['word_event_ratio'] = feats['word_count_max'] / feats['event_id_max']\n",
    "        feats['event_time_ratio'] = feats['event_id_max']  / feats['up_time_max']\n",
    "        feats['idle_time_ratio'] = feats['action_time_gap1_sum'] / feats['up_time_max']\n",
    "        \n",
    "        print(\"Done!\")\n",
    "        return feats\n",
    "\n",
    "preprocessor = Preprocessor()\n",
    "print(\"Engineering features for training data\")\n",
    "train_feats = preprocessor.make_feats(train_logs)\n",
    "print(\"-\" * 25)\n",
    "print(\"Engineering features for test data\")\n",
    "test_feats = preprocessor.make_feats(test_logs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca117209",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T05:09:33.904942Z",
     "iopub.status.busy": "2024-01-08T05:09:33.904174Z",
     "iopub.status.idle": "2024-01-08T05:09:45.828410Z",
     "shell.execute_reply": "2024-01-08T05:09:45.827005Z"
    },
    "papermill": {
     "duration": 11.957447,
     "end_time": "2024-01-08T05:09:45.831546",
     "exception": false,
     "start_time": "2024-01-08T05:09:33.874099",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for logs in [train_logs, test_logs]:\n",
    "    logs['up_time_lagged'] = logs.groupby('id')['up_time'].shift(1).fillna(logs['down_time'])\n",
    "    logs['time_diff'] = abs(logs['down_time'] - logs['up_time_lagged']) / 1000\n",
    "\n",
    "    group = logs.groupby('id')['time_diff']\n",
    "    largest_lantency = group.max()\n",
    "    smallest_lantency = group.min()\n",
    "    median_lantency = group.median()\n",
    "    initial_pause = logs.groupby('id')['down_time'].first() / 1000\n",
    "    pauses_half_sec = group.apply(lambda x: ((x > 0.5) & (x <= 1)).sum())\n",
    "    pauses_1_sec = group.apply(lambda x: ((x > 1) & (x <= 1.5)).sum())\n",
    "    pauses_1_half_sec = group.apply(lambda x: ((x > 1.5) & (x <= 2)).sum())\n",
    "    pauses_2_sec = group.apply(lambda x: ((x > 2) & (x <= 3)).sum())\n",
    "    pauses_3_sec = group.apply(lambda x: (x > 3).sum())\n",
    "\n",
    "    data.append(pd.DataFrame({\n",
    "        'id': logs['id'].unique(),\n",
    "        'largest_lantency': largest_lantency,\n",
    "        'smallest_lantency': smallest_lantency,\n",
    "        'median_lantency': median_lantency,\n",
    "        'initial_pause': initial_pause,\n",
    "        'pauses_half_sec': pauses_half_sec,\n",
    "        'pauses_1_sec': pauses_1_sec,\n",
    "        'pauses_1_half_sec': pauses_1_half_sec,\n",
    "        'pauses_2_sec': pauses_2_sec,\n",
    "        'pauses_3_sec': pauses_3_sec,\n",
    "    }).reset_index(drop=True))\n",
    "\n",
    "train_eD592674, test_eD592674 = data\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "train_feats = train_feats.merge(train_eD592674, on='id', how='left')\n",
    "test_feats = test_feats.merge(test_eD592674, on='id', how='left')\n",
    "train_feats = train_feats.merge(train_scores, on='id', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a5b6ed8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T05:09:45.892352Z",
     "iopub.status.busy": "2024-01-08T05:09:45.891648Z",
     "iopub.status.idle": "2024-01-08T05:09:45.948852Z",
     "shell.execute_reply": "2024-01-08T05:09:45.947377Z"
    },
    "papermill": {
     "duration": 0.09138,
     "end_time": "2024-01-08T05:09:45.951947",
     "exception": false,
     "start_time": "2024-01-08T05:09:45.860567",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_feats=train_feats.merge(train_word_agg_df,on='id', how='left')\n",
    "train_feats=train_feats.merge(train_sent_agg_df,on='id', how='left')\n",
    "train_feats=train_feats.merge(train_paragraph_agg_df,on='id', how='left')\n",
    "\n",
    "test_feats=test_feats.merge(test_word_agg_df,on='id', how='left')\n",
    "test_feats=test_feats.merge(test_sent_agg_df,on='id', how='left')\n",
    "test_feats=test_feats.merge(test_paragraph_agg_df,on='id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3be6786f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T05:09:46.011292Z",
     "iopub.status.busy": "2024-01-08T05:09:46.010829Z",
     "iopub.status.idle": "2024-01-08T05:09:46.129427Z",
     "shell.execute_reply": "2024-01-08T05:09:46.128259Z"
    },
    "papermill": {
     "duration": 0.151443,
     "end_time": "2024-01-08T05:09:46.131877",
     "exception": false,
     "start_time": "2024-01-08T05:09:45.980434",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique_cols:['cursor_position_min', 'word_count_change1_quantile', 'word_count_change2_quantile', 'activity_5_count', 'smallest_lantency']\n"
     ]
    }
   ],
   "source": [
    "keys=train_feats.keys().values\n",
    "unique_cols=[key for key in keys if train_feats[key].nunique()<2]\n",
    "print(f\"unique_cols:{unique_cols}\")\n",
    "train_feats = train_feats.drop(columns=unique_cols)\n",
    "test_feats = test_feats.drop(columns=unique_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7369efa8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T05:09:46.192302Z",
     "iopub.status.busy": "2024-01-08T05:09:46.191599Z",
     "iopub.status.idle": "2024-01-08T05:09:46.198451Z",
     "shell.execute_reply": "2024-01-08T05:09:46.197278Z"
    },
    "papermill": {
     "duration": 0.040931,
     "end_time": "2024-01-08T05:09:46.201356",
     "exception": false,
     "start_time": "2024-01-08T05:09:46.160425",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_feats = train_feats.drop('score',axis=1)\n",
    "# train_feats = pd.concat([train_feats, train_scores['score']], axis=1)\n",
    "\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras import layers, models \n",
    "# from tensorflow.keras.layers import Dense, Reshape, LeakyReLU\n",
    "# from tensorflow.keras.optimizers import Adam \n",
    "# from tensorflow.keras.losses import MeanSquaredError\n",
    "\n",
    "# generator = Sequential()\n",
    "# generator.add(Dense(128, input_shape=(100,)))\n",
    "# generator.add(LeakyReLU(alpha=0.01)) \n",
    "# generator.add(Dense(256))\n",
    "# generator.add(LeakyReLU(alpha=0.01))\n",
    "# generator.add(Dense(404)) \n",
    "\n",
    "# discriminator = Sequential()\n",
    "# discriminator.add(Dense(256, input_shape=(404,)))\n",
    "# discriminator.add(LeakyReLU(alpha=0.01))\n",
    "# discriminator.add(Dense(128))\n",
    "# discriminator.add(LeakyReLU(alpha=0.01))\n",
    "# discriminator.add(Dense(1))\n",
    "\n",
    "# gan_model = Sequential()\n",
    "# gan_model.add(generator)\n",
    "# discriminator.trainable = False\n",
    "# gan_model.add(discriminator)\n",
    "\n",
    "# discriminator.compile(loss=MeanSquaredError(), optimizer=Adam(learning_rate=0.0002, beta_1=0.5))\n",
    "# gan_model.compile(loss=MeanSquaredError(), optimizer=Adam(learning_rate=0.0002, beta_1=0.5))\n",
    "\n",
    "# epochs = 1000\n",
    "# batch_size = 128\n",
    "\n",
    "# for epoch in range(epochs):\n",
    "#     idx = np.random.randint(0, train_feats.shape[0], batch_size)\n",
    "#     real_samples = train_feats.drop(columns=['id']).iloc[idx].values\n",
    "#     fake_samples = generator.predict(np.random.rand(batch_size, 100))\n",
    "#     real_labels = real_samples \n",
    "#     fake_labels = fake_samples\n",
    "#     real_samples_tf = tf.convert_to_tensor(real_samples, dtype=tf.float32)\n",
    "#     fake_samples_tf = tf.convert_to_tensor(fake_samples, dtype=tf.float32)\n",
    "    \n",
    "    \n",
    "#     d_loss_real = discriminator.train_on_batch(real_samples_tf, real_labels)\n",
    "#     d_loss_fake = discriminator.train_on_batch(fake_samples_tf, fake_labels )\n",
    "#     d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "    \n",
    "#     noise = np.random.rand(batch_size, 100)\n",
    "#     valid_labels = noise\n",
    "#     g_loss = gan_model.train_on_batch(noise, valid_labels)\n",
    "    \n",
    "#     if epoch % 100 == 0:\n",
    "#         print(f\"Epoch {epoch}, D Loss: {d_loss}, G_Loss: {g_loss}\")\n",
    "\n",
    " \n",
    "\n",
    "# generated_feats = generator.predict(np.random.rand(2471,100))\n",
    "\n",
    "# generated_ids = range(1, len(generated_feats) + 1)\n",
    "# df_generated = pd.DataFrame(generated_feats, columns=train_feats.columns[1:])\n",
    "# df_generated['id'] = [f\"{i:08d}\" for i in generated_ids]\n",
    "\n",
    "# train_feats = pd.concat([train_feats, df_generated], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4fc698b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T05:09:46.265021Z",
     "iopub.status.busy": "2024-01-08T05:09:46.264292Z",
     "iopub.status.idle": "2024-01-08T05:09:46.272235Z",
     "shell.execute_reply": "2024-01-08T05:09:46.271184Z"
    },
    "papermill": {
     "duration": 0.041946,
     "end_time": "2024-01-08T05:09:46.274918",
     "exception": false,
     "start_time": "2024-01-08T05:09:46.232972",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_pipeline(model):\n",
    "    return Pipeline([\n",
    "        ('remove_infs', FunctionTransformer(lambda x: np.nan_to_num(x, nan=np.nan, posinf=0, neginf=0))),\n",
    "        ('imputer', SimpleImputer(strategy='mean')),\n",
    "        ('normalizer', FunctionTransformer(lambda x: np.log1p(np.abs(x)))),\n",
    "        ('scaler', RobustScaler()),\n",
    "        ('model', model)\n",
    "    ])\n",
    "\n",
    "def train_valid_split(data_x, data_y, train_idx, valid_idx):\n",
    "    x_train = data_x.iloc[train_idx]\n",
    "    y_train = data_y[train_idx]\n",
    "    x_valid = data_x.iloc[valid_idx]\n",
    "    y_valid = data_y[valid_idx]\n",
    "    return x_train, y_train, x_valid, y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89bac7d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T05:09:46.333294Z",
     "iopub.status.busy": "2024-01-08T05:09:46.332846Z",
     "iopub.status.idle": "2024-01-08T05:09:46.343233Z",
     "shell.execute_reply": "2024-01-08T05:09:46.342050Z"
    },
    "papermill": {
     "duration": 0.042816,
     "end_time": "2024-01-08T05:09:46.345811",
     "exception": false,
     "start_time": "2024-01-08T05:09:46.302995",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lasso = make_pipeline(\n",
    "    Lasso(\n",
    "        alpha=0.001,\n",
    "        fit_intercept=True,\n",
    "        max_iter=50,\n",
    "        selection='random',\n",
    "        random_state=42\n",
    "    )\n",
    ")\n",
    "\n",
    "ENet = make_pipeline(\n",
    "    ElasticNet(\n",
    "        alpha=0.1,\n",
    "        fit_intercept=True,\n",
    "        l1_ratio=0.1,\n",
    "        max_iter=100,\n",
    "        random_state=42\n",
    "    )\n",
    ")\n",
    "\n",
    "GBoost = make_pipeline(\n",
    "    GradientBoostingRegressor(\n",
    "        learning_rate=0.1,\n",
    "        max_depth=3,\n",
    "        min_samples_leaf=4,\n",
    "        min_samples_split=2,\n",
    "        n_estimators=50,\n",
    "        subsample=0.8,\n",
    "        random_state=42\n",
    "    )\n",
    ")\n",
    "\n",
    "ridge = make_pipeline(\n",
    "    Ridge(\n",
    "        alpha=1.0,\n",
    "        fit_intercept=True,\n",
    "        solver='svd'\n",
    "    )\n",
    ")\n",
    "\n",
    "lr = make_pipeline(\n",
    "    LinearRegression(\n",
    "        fit_intercept=True,\n",
    "        positive=False\n",
    "    )\n",
    ")\n",
    "\n",
    "rf = make_pipeline(\n",
    "    RandomForestRegressor(\n",
    "        bootstrap=True,\n",
    "        max_depth=20,\n",
    "        max_features='auto',\n",
    "        min_samples_leaf=2,\n",
    "        min_samples_split=10,\n",
    "        n_estimators=200,\n",
    "        random_state=42\n",
    "    )\n",
    ")\n",
    "\n",
    "svr = make_pipeline(\n",
    "    SVR(\n",
    "        kernel='rbf',\n",
    "        C=100,\n",
    "        epsilon=0.1\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "993425b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T05:09:46.403968Z",
     "iopub.status.busy": "2024-01-08T05:09:46.403011Z",
     "iopub.status.idle": "2024-01-08T05:09:46.417854Z",
     "shell.execute_reply": "2024-01-08T05:09:46.416662Z"
    },
    "papermill": {
     "duration": 0.046556,
     "end_time": "2024-01-08T05:09:46.420306",
     "exception": false,
     "start_time": "2024-01-08T05:09:46.373750",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cb_param = {\n",
    "    'n_estimators': 2424,\n",
    "    'depth': 7,\n",
    "    'od_wait': 15,\n",
    "    'l2_leaf_reg': 5.7698693615696754,\n",
    "    'colsample_bylevel': 0.7197709029314262,\n",
    "    'subsample': 0.46524030005499395,\n",
    "    'learning_rate': 0.009934387110797558,\n",
    "    'bagging_temperature': 0.3562146562395841,\n",
    "    'border_count': 255,\n",
    "    'min_data_in_leaf': 79,\n",
    "    'random_state': 42,\n",
    "    'verbose': 0\n",
    "}\n",
    "cbr = CatBoostRegressor(**cb_param)\n",
    "\n",
    "xgb_param = {\n",
    "    'objective': 'reg:squarederror',\n",
    "    'n_estimators': 1002,\n",
    "    'learning_rate': 0.02670836201283028,\n",
    "    'max_depth': 4,\n",
    "    'subsample': 0.487752178166985,\n",
    "    'colsample_bytree': 0.45093000793609206,\n",
    "    'colsample_bylevel': 0.71,\n",
    "    'eta': 0.011957851912348194,\n",
    "    'gamma': 0.0022864202534752924,\n",
    "    'reg_alpha': 0.02437079001480029,\n",
    "    'reg_lambda': 6.834478468800099,\n",
    "    'max_delta_step': 8,\n",
    "    'min_child_weight': 0.32060573402630715,\n",
    "    'random_state': 42,\n",
    "    'eval_metric': 'rmse',\n",
    "    'verbose' : 1,\n",
    "}          \n",
    "xgbr = XGBRegressor(**xgb_param)\n",
    "\n",
    "lgbm_param = {\n",
    "    'reg_alpha': 0.5087856916700971,\n",
    "    'reg_lambda': 0.2405984837342317,\n",
    "    'colsample_bytree': 0.8378257913675838,\n",
    "    'subsample': 0.5411528279742139,\n",
    "    'learning_rate': 0.016140199269271273,\n",
    "    'max_depth': 40,\n",
    "    'num_leaves': 15,\n",
    "    'min_child_samples': 13,\n",
    "    'bagging_fraction': 0.8410863683391213,\n",
    "    'lambda_l1': 1.8151102699226822e-06,\n",
    "    'lambda_l2': 0.017602890537921387,\n",
    "    'bagging_freq': 2,\n",
    "    'n_estimators': 1024,\n",
    "    'metric': 'rmse',\n",
    "    'random_state': 42,\n",
    "    'force_col_wise': True,\n",
    "    'verbosity': 1,\n",
    "}\n",
    "lgbmr = LGBMRegressor(**lgbm_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b6b3715",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T05:09:46.478535Z",
     "iopub.status.busy": "2024-01-08T05:09:46.477667Z",
     "iopub.status.idle": "2024-01-08T05:09:46.484508Z",
     "shell.execute_reply": "2024-01-08T05:09:46.483487Z"
    },
    "papermill": {
     "duration": 0.038718,
     "end_time": "2024-01-08T05:09:46.487033",
     "exception": false,
     "start_time": "2024-01-08T05:09:46.448315",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "stack_gen = StackingRegressor(\n",
    "    estimators=[\n",
    "        ('enet', ENet),\n",
    "        ('lasso', lasso),\n",
    "        ('ridge', ridge),\n",
    "        ('gboost', GBoost),\n",
    "        ('rf', rf),\n",
    "        ('cbr', cbr),\n",
    "        ('svr', svr) \n",
    "    ], \n",
    "    final_estimator=lr, \n",
    "    passthrough=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6f52a263",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T05:09:46.544527Z",
     "iopub.status.busy": "2024-01-08T05:09:46.544119Z",
     "iopub.status.idle": "2024-01-08T05:09:46.622479Z",
     "shell.execute_reply": "2024-01-08T05:09:46.621393Z"
    },
    "papermill": {
     "duration": 0.110626,
     "end_time": "2024-01-08T05:09:46.625354",
     "exception": false,
     "start_time": "2024-01-08T05:09:46.514728",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_feats.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "x              = train_feats.drop(['id', 'score'], axis=1)\n",
    "y              = train_feats['score'].values\n",
    "\n",
    "test_ids = test_feats['id'].values\n",
    "testin_x = test_feats.drop(['id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "37b989c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T05:09:46.684438Z",
     "iopub.status.busy": "2024-01-08T05:09:46.683723Z",
     "iopub.status.idle": "2024-01-08T05:09:46.689204Z",
     "shell.execute_reply": "2024-01-08T05:09:46.688056Z"
    },
    "papermill": {
     "duration": 0.03755,
     "end_time": "2024-01-08T05:09:46.691488",
     "exception": false,
     "start_time": "2024-01-08T05:09:46.653938",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_splits = 10 \n",
    "random_state = 42\n",
    "early_stopping_rounds = 400\n",
    "skf = StratifiedKFold(n_splits=n_splits, random_state=random_state, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d4b54e16",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-01-08T05:09:46.749282Z",
     "iopub.status.busy": "2024-01-08T05:09:46.748870Z",
     "iopub.status.idle": "2024-01-08T05:12:07.812411Z",
     "shell.execute_reply": "2024-01-08T05:12:07.811183Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 141.096106,
     "end_time": "2024-01-08T05:12:07.815450",
     "exception": false,
     "start_time": "2024-01-08T05:09:46.719344",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold_1 Training\n",
      "[0]\tvalidation_0-rmse:1.00887\tvalidation_1-rmse:1.01504\n",
      "[10]\tvalidation_0-rmse:0.87988\tvalidation_1-rmse:0.89172\n",
      "[20]\tvalidation_0-rmse:0.78590\tvalidation_1-rmse:0.80209\n",
      "[30]\tvalidation_0-rmse:0.71682\tvalidation_1-rmse:0.73715\n",
      "[40]\tvalidation_0-rmse:0.66830\tvalidation_1-rmse:0.69464\n",
      "[50]\tvalidation_0-rmse:0.63241\tvalidation_1-rmse:0.66401\n",
      "[60]\tvalidation_0-rmse:0.60426\tvalidation_1-rmse:0.64434\n",
      "[70]\tvalidation_0-rmse:0.58415\tvalidation_1-rmse:0.63024\n",
      "[80]\tvalidation_0-rmse:0.56817\tvalidation_1-rmse:0.62203\n",
      "[90]\tvalidation_0-rmse:0.55491\tvalidation_1-rmse:0.61333\n",
      "[100]\tvalidation_0-rmse:0.54347\tvalidation_1-rmse:0.60851\n",
      "[110]\tvalidation_0-rmse:0.53433\tvalidation_1-rmse:0.60455\n",
      "[120]\tvalidation_0-rmse:0.52593\tvalidation_1-rmse:0.60249\n",
      "[130]\tvalidation_0-rmse:0.51842\tvalidation_1-rmse:0.59990\n",
      "[140]\tvalidation_0-rmse:0.51135\tvalidation_1-rmse:0.59861\n",
      "[150]\tvalidation_0-rmse:0.50553\tvalidation_1-rmse:0.59652\n",
      "[160]\tvalidation_0-rmse:0.49958\tvalidation_1-rmse:0.59612\n",
      "[170]\tvalidation_0-rmse:0.49364\tvalidation_1-rmse:0.59555\n",
      "[180]\tvalidation_0-rmse:0.48762\tvalidation_1-rmse:0.59562\n",
      "[190]\tvalidation_0-rmse:0.48199\tvalidation_1-rmse:0.59526\n",
      "[200]\tvalidation_0-rmse:0.47716\tvalidation_1-rmse:0.59449\n",
      "[210]\tvalidation_0-rmse:0.47242\tvalidation_1-rmse:0.59417\n",
      "[220]\tvalidation_0-rmse:0.46696\tvalidation_1-rmse:0.59324\n",
      "[230]\tvalidation_0-rmse:0.46191\tvalidation_1-rmse:0.59359\n",
      "[240]\tvalidation_0-rmse:0.45676\tvalidation_1-rmse:0.59384\n",
      "[250]\tvalidation_0-rmse:0.45181\tvalidation_1-rmse:0.59395\n",
      "[260]\tvalidation_0-rmse:0.44706\tvalidation_1-rmse:0.59427\n",
      "[270]\tvalidation_0-rmse:0.44233\tvalidation_1-rmse:0.59522\n",
      "[280]\tvalidation_0-rmse:0.43809\tvalidation_1-rmse:0.59524\n",
      "[290]\tvalidation_0-rmse:0.43439\tvalidation_1-rmse:0.59536\n",
      "[300]\tvalidation_0-rmse:0.42964\tvalidation_1-rmse:0.59577\n",
      "[310]\tvalidation_0-rmse:0.42501\tvalidation_1-rmse:0.59695\n",
      "[320]\tvalidation_0-rmse:0.42127\tvalidation_1-rmse:0.59787\n",
      "[330]\tvalidation_0-rmse:0.41653\tvalidation_1-rmse:0.59842\n",
      "[340]\tvalidation_0-rmse:0.41226\tvalidation_1-rmse:0.59842\n",
      "[350]\tvalidation_0-rmse:0.40803\tvalidation_1-rmse:0.59854\n",
      "[360]\tvalidation_0-rmse:0.40382\tvalidation_1-rmse:0.59937\n",
      "[370]\tvalidation_0-rmse:0.39980\tvalidation_1-rmse:0.59919\n",
      "[380]\tvalidation_0-rmse:0.39535\tvalidation_1-rmse:0.60005\n",
      "[390]\tvalidation_0-rmse:0.39101\tvalidation_1-rmse:0.60043\n",
      "[400]\tvalidation_0-rmse:0.38728\tvalidation_1-rmse:0.60162\n",
      "[410]\tvalidation_0-rmse:0.38392\tvalidation_1-rmse:0.60138\n",
      "[420]\tvalidation_0-rmse:0.38032\tvalidation_1-rmse:0.60257\n",
      "[430]\tvalidation_0-rmse:0.37641\tvalidation_1-rmse:0.60305\n",
      "[440]\tvalidation_0-rmse:0.37267\tvalidation_1-rmse:0.60296\n",
      "[450]\tvalidation_0-rmse:0.36878\tvalidation_1-rmse:0.60231\n",
      "[460]\tvalidation_0-rmse:0.36499\tvalidation_1-rmse:0.60315\n",
      "[470]\tvalidation_0-rmse:0.36164\tvalidation_1-rmse:0.60339\n",
      "[480]\tvalidation_0-rmse:0.35820\tvalidation_1-rmse:0.60317\n",
      "[490]\tvalidation_0-rmse:0.35454\tvalidation_1-rmse:0.60335\n",
      "[500]\tvalidation_0-rmse:0.35108\tvalidation_1-rmse:0.60461\n",
      "[510]\tvalidation_0-rmse:0.34765\tvalidation_1-rmse:0.60418\n",
      "[520]\tvalidation_0-rmse:0.34405\tvalidation_1-rmse:0.60457\n",
      "[530]\tvalidation_0-rmse:0.34033\tvalidation_1-rmse:0.60474\n",
      "[540]\tvalidation_0-rmse:0.33732\tvalidation_1-rmse:0.60466\n",
      "[550]\tvalidation_0-rmse:0.33406\tvalidation_1-rmse:0.60493\n",
      "[560]\tvalidation_0-rmse:0.33075\tvalidation_1-rmse:0.60479\n",
      "[570]\tvalidation_0-rmse:0.32754\tvalidation_1-rmse:0.60529\n",
      "[580]\tvalidation_0-rmse:0.32417\tvalidation_1-rmse:0.60518\n",
      "[590]\tvalidation_0-rmse:0.32085\tvalidation_1-rmse:0.60608\n",
      "[600]\tvalidation_0-rmse:0.31826\tvalidation_1-rmse:0.60596\n",
      "[610]\tvalidation_0-rmse:0.31496\tvalidation_1-rmse:0.60585\n",
      "[620]\tvalidation_0-rmse:0.31203\tvalidation_1-rmse:0.60584\n",
      "[630]\tvalidation_0-rmse:0.30947\tvalidation_1-rmse:0.60631\n",
      "[640]\tvalidation_0-rmse:0.30675\tvalidation_1-rmse:0.60649\n",
      "[645]\tvalidation_0-rmse:0.30523\tvalidation_1-rmse:0.60666\n",
      "\n",
      "Fold_2 Training\n",
      "[0]\tvalidation_0-rmse:1.01004\tvalidation_1-rmse:1.00463\n",
      "[10]\tvalidation_0-rmse:0.87956\tvalidation_1-rmse:0.88262\n",
      "[20]\tvalidation_0-rmse:0.78592\tvalidation_1-rmse:0.79808\n",
      "[30]\tvalidation_0-rmse:0.71794\tvalidation_1-rmse:0.73998\n",
      "[40]\tvalidation_0-rmse:0.66873\tvalidation_1-rmse:0.69728\n",
      "[50]\tvalidation_0-rmse:0.63248\tvalidation_1-rmse:0.66892\n",
      "[60]\tvalidation_0-rmse:0.60552\tvalidation_1-rmse:0.64896\n",
      "[70]\tvalidation_0-rmse:0.58493\tvalidation_1-rmse:0.63727\n",
      "[80]\tvalidation_0-rmse:0.56781\tvalidation_1-rmse:0.62764\n",
      "[90]\tvalidation_0-rmse:0.55355\tvalidation_1-rmse:0.61777\n",
      "[100]\tvalidation_0-rmse:0.54220\tvalidation_1-rmse:0.61380\n",
      "[110]\tvalidation_0-rmse:0.53281\tvalidation_1-rmse:0.61011\n",
      "[120]\tvalidation_0-rmse:0.52415\tvalidation_1-rmse:0.60788\n",
      "[130]\tvalidation_0-rmse:0.51667\tvalidation_1-rmse:0.60635\n",
      "[140]\tvalidation_0-rmse:0.50975\tvalidation_1-rmse:0.60541\n",
      "[150]\tvalidation_0-rmse:0.50332\tvalidation_1-rmse:0.60426\n",
      "[160]\tvalidation_0-rmse:0.49702\tvalidation_1-rmse:0.60364\n",
      "[170]\tvalidation_0-rmse:0.49052\tvalidation_1-rmse:0.60254\n",
      "[180]\tvalidation_0-rmse:0.48407\tvalidation_1-rmse:0.60242\n",
      "[190]\tvalidation_0-rmse:0.47836\tvalidation_1-rmse:0.60288\n",
      "[200]\tvalidation_0-rmse:0.47355\tvalidation_1-rmse:0.60127\n",
      "[210]\tvalidation_0-rmse:0.46936\tvalidation_1-rmse:0.60091\n",
      "[220]\tvalidation_0-rmse:0.46439\tvalidation_1-rmse:0.60140\n",
      "[230]\tvalidation_0-rmse:0.45944\tvalidation_1-rmse:0.60039\n",
      "[240]\tvalidation_0-rmse:0.45495\tvalidation_1-rmse:0.59980\n",
      "[250]\tvalidation_0-rmse:0.44967\tvalidation_1-rmse:0.59936\n",
      "[260]\tvalidation_0-rmse:0.44432\tvalidation_1-rmse:0.59857\n",
      "[270]\tvalidation_0-rmse:0.43989\tvalidation_1-rmse:0.59841\n",
      "[280]\tvalidation_0-rmse:0.43473\tvalidation_1-rmse:0.59851\n",
      "[290]\tvalidation_0-rmse:0.43044\tvalidation_1-rmse:0.59884\n",
      "[300]\tvalidation_0-rmse:0.42564\tvalidation_1-rmse:0.59955\n",
      "[310]\tvalidation_0-rmse:0.42144\tvalidation_1-rmse:0.59930\n",
      "[320]\tvalidation_0-rmse:0.41706\tvalidation_1-rmse:0.59948\n",
      "[330]\tvalidation_0-rmse:0.41274\tvalidation_1-rmse:0.59968\n",
      "[340]\tvalidation_0-rmse:0.40832\tvalidation_1-rmse:0.59940\n",
      "[350]\tvalidation_0-rmse:0.40385\tvalidation_1-rmse:0.59946\n",
      "[360]\tvalidation_0-rmse:0.40002\tvalidation_1-rmse:0.59982\n",
      "[370]\tvalidation_0-rmse:0.39578\tvalidation_1-rmse:0.59950\n",
      "[380]\tvalidation_0-rmse:0.39214\tvalidation_1-rmse:0.59956\n",
      "[390]\tvalidation_0-rmse:0.38870\tvalidation_1-rmse:0.59970\n",
      "[400]\tvalidation_0-rmse:0.38478\tvalidation_1-rmse:0.59993\n",
      "[410]\tvalidation_0-rmse:0.38107\tvalidation_1-rmse:0.60080\n",
      "[420]\tvalidation_0-rmse:0.37703\tvalidation_1-rmse:0.60110\n",
      "[430]\tvalidation_0-rmse:0.37351\tvalidation_1-rmse:0.60164\n",
      "[440]\tvalidation_0-rmse:0.36927\tvalidation_1-rmse:0.60144\n",
      "[450]\tvalidation_0-rmse:0.36570\tvalidation_1-rmse:0.60149\n",
      "[460]\tvalidation_0-rmse:0.36200\tvalidation_1-rmse:0.60181\n",
      "[470]\tvalidation_0-rmse:0.35892\tvalidation_1-rmse:0.60201\n",
      "[480]\tvalidation_0-rmse:0.35522\tvalidation_1-rmse:0.60247\n",
      "[490]\tvalidation_0-rmse:0.35120\tvalidation_1-rmse:0.60218\n",
      "[500]\tvalidation_0-rmse:0.34764\tvalidation_1-rmse:0.60185\n",
      "[510]\tvalidation_0-rmse:0.34374\tvalidation_1-rmse:0.60216\n",
      "[520]\tvalidation_0-rmse:0.34046\tvalidation_1-rmse:0.60221\n",
      "[530]\tvalidation_0-rmse:0.33704\tvalidation_1-rmse:0.60252\n",
      "[540]\tvalidation_0-rmse:0.33341\tvalidation_1-rmse:0.60315\n",
      "[550]\tvalidation_0-rmse:0.33028\tvalidation_1-rmse:0.60255\n",
      "[560]\tvalidation_0-rmse:0.32742\tvalidation_1-rmse:0.60278\n",
      "[570]\tvalidation_0-rmse:0.32444\tvalidation_1-rmse:0.60291\n",
      "[580]\tvalidation_0-rmse:0.32114\tvalidation_1-rmse:0.60334\n",
      "[590]\tvalidation_0-rmse:0.31822\tvalidation_1-rmse:0.60397\n",
      "[600]\tvalidation_0-rmse:0.31498\tvalidation_1-rmse:0.60427\n",
      "[610]\tvalidation_0-rmse:0.31183\tvalidation_1-rmse:0.60337\n",
      "[620]\tvalidation_0-rmse:0.30901\tvalidation_1-rmse:0.60380\n",
      "[630]\tvalidation_0-rmse:0.30567\tvalidation_1-rmse:0.60439\n",
      "[640]\tvalidation_0-rmse:0.30280\tvalidation_1-rmse:0.60502\n",
      "[650]\tvalidation_0-rmse:0.29981\tvalidation_1-rmse:0.60552\n",
      "[660]\tvalidation_0-rmse:0.29685\tvalidation_1-rmse:0.60603\n",
      "[670]\tvalidation_0-rmse:0.29436\tvalidation_1-rmse:0.60616\n",
      "[680]\tvalidation_0-rmse:0.29114\tvalidation_1-rmse:0.60684\n",
      "[683]\tvalidation_0-rmse:0.29044\tvalidation_1-rmse:0.60701\n",
      "\n",
      "Fold_3 Training\n",
      "[0]\tvalidation_0-rmse:1.00907\tvalidation_1-rmse:1.00472\n",
      "[10]\tvalidation_0-rmse:0.87864\tvalidation_1-rmse:0.88289\n",
      "[20]\tvalidation_0-rmse:0.78501\tvalidation_1-rmse:0.79960\n",
      "[30]\tvalidation_0-rmse:0.71622\tvalidation_1-rmse:0.73997\n",
      "[40]\tvalidation_0-rmse:0.66679\tvalidation_1-rmse:0.69879\n",
      "[50]\tvalidation_0-rmse:0.63079\tvalidation_1-rmse:0.66990\n",
      "[60]\tvalidation_0-rmse:0.60460\tvalidation_1-rmse:0.64953\n",
      "[70]\tvalidation_0-rmse:0.58348\tvalidation_1-rmse:0.63623\n",
      "[80]\tvalidation_0-rmse:0.56645\tvalidation_1-rmse:0.62763\n",
      "[90]\tvalidation_0-rmse:0.55352\tvalidation_1-rmse:0.62265\n",
      "[100]\tvalidation_0-rmse:0.54320\tvalidation_1-rmse:0.61812\n",
      "[110]\tvalidation_0-rmse:0.53377\tvalidation_1-rmse:0.61551\n",
      "[120]\tvalidation_0-rmse:0.52566\tvalidation_1-rmse:0.61310\n",
      "[130]\tvalidation_0-rmse:0.51754\tvalidation_1-rmse:0.61196\n",
      "[140]\tvalidation_0-rmse:0.51058\tvalidation_1-rmse:0.61107\n",
      "[150]\tvalidation_0-rmse:0.50435\tvalidation_1-rmse:0.60936\n",
      "[160]\tvalidation_0-rmse:0.49758\tvalidation_1-rmse:0.60957\n",
      "[170]\tvalidation_0-rmse:0.49199\tvalidation_1-rmse:0.60888\n",
      "[180]\tvalidation_0-rmse:0.48612\tvalidation_1-rmse:0.60782\n",
      "[190]\tvalidation_0-rmse:0.47979\tvalidation_1-rmse:0.60606\n",
      "[200]\tvalidation_0-rmse:0.47400\tvalidation_1-rmse:0.60487\n",
      "[210]\tvalidation_0-rmse:0.46860\tvalidation_1-rmse:0.60474\n",
      "[220]\tvalidation_0-rmse:0.46349\tvalidation_1-rmse:0.60529\n",
      "[230]\tvalidation_0-rmse:0.45889\tvalidation_1-rmse:0.60382\n",
      "[240]\tvalidation_0-rmse:0.45400\tvalidation_1-rmse:0.60356\n",
      "[250]\tvalidation_0-rmse:0.44901\tvalidation_1-rmse:0.60305\n",
      "[260]\tvalidation_0-rmse:0.44463\tvalidation_1-rmse:0.60245\n",
      "[270]\tvalidation_0-rmse:0.44028\tvalidation_1-rmse:0.60216\n",
      "[280]\tvalidation_0-rmse:0.43536\tvalidation_1-rmse:0.60269\n",
      "[290]\tvalidation_0-rmse:0.43108\tvalidation_1-rmse:0.60269\n",
      "[300]\tvalidation_0-rmse:0.42612\tvalidation_1-rmse:0.60246\n",
      "[310]\tvalidation_0-rmse:0.42185\tvalidation_1-rmse:0.60168\n",
      "[320]\tvalidation_0-rmse:0.41729\tvalidation_1-rmse:0.60153\n",
      "[330]\tvalidation_0-rmse:0.41325\tvalidation_1-rmse:0.60254\n",
      "[340]\tvalidation_0-rmse:0.40876\tvalidation_1-rmse:0.60216\n",
      "[350]\tvalidation_0-rmse:0.40499\tvalidation_1-rmse:0.60273\n",
      "[360]\tvalidation_0-rmse:0.40109\tvalidation_1-rmse:0.60268\n",
      "[370]\tvalidation_0-rmse:0.39662\tvalidation_1-rmse:0.60334\n",
      "[380]\tvalidation_0-rmse:0.39260\tvalidation_1-rmse:0.60315\n",
      "[390]\tvalidation_0-rmse:0.38843\tvalidation_1-rmse:0.60391\n",
      "[400]\tvalidation_0-rmse:0.38475\tvalidation_1-rmse:0.60472\n",
      "[410]\tvalidation_0-rmse:0.38089\tvalidation_1-rmse:0.60482\n",
      "[420]\tvalidation_0-rmse:0.37718\tvalidation_1-rmse:0.60567\n",
      "[430]\tvalidation_0-rmse:0.37362\tvalidation_1-rmse:0.60552\n",
      "[440]\tvalidation_0-rmse:0.36997\tvalidation_1-rmse:0.60635\n",
      "[450]\tvalidation_0-rmse:0.36617\tvalidation_1-rmse:0.60534\n",
      "[460]\tvalidation_0-rmse:0.36237\tvalidation_1-rmse:0.60478\n",
      "[470]\tvalidation_0-rmse:0.35864\tvalidation_1-rmse:0.60570\n",
      "[480]\tvalidation_0-rmse:0.35560\tvalidation_1-rmse:0.60615\n",
      "[490]\tvalidation_0-rmse:0.35232\tvalidation_1-rmse:0.60653\n",
      "[500]\tvalidation_0-rmse:0.34920\tvalidation_1-rmse:0.60658\n",
      "[510]\tvalidation_0-rmse:0.34614\tvalidation_1-rmse:0.60619\n",
      "[520]\tvalidation_0-rmse:0.34237\tvalidation_1-rmse:0.60643\n",
      "[530]\tvalidation_0-rmse:0.33921\tvalidation_1-rmse:0.60609\n",
      "[540]\tvalidation_0-rmse:0.33606\tvalidation_1-rmse:0.60624\n",
      "[550]\tvalidation_0-rmse:0.33282\tvalidation_1-rmse:0.60650\n",
      "[560]\tvalidation_0-rmse:0.32927\tvalidation_1-rmse:0.60761\n",
      "[570]\tvalidation_0-rmse:0.32612\tvalidation_1-rmse:0.60827\n",
      "[580]\tvalidation_0-rmse:0.32330\tvalidation_1-rmse:0.60809\n",
      "[590]\tvalidation_0-rmse:0.31992\tvalidation_1-rmse:0.60836\n",
      "[600]\tvalidation_0-rmse:0.31695\tvalidation_1-rmse:0.60805\n",
      "[610]\tvalidation_0-rmse:0.31399\tvalidation_1-rmse:0.60846\n",
      "[620]\tvalidation_0-rmse:0.31068\tvalidation_1-rmse:0.60818\n",
      "[630]\tvalidation_0-rmse:0.30738\tvalidation_1-rmse:0.60829\n",
      "[640]\tvalidation_0-rmse:0.30444\tvalidation_1-rmse:0.60832\n",
      "[650]\tvalidation_0-rmse:0.30198\tvalidation_1-rmse:0.60782\n",
      "[660]\tvalidation_0-rmse:0.29923\tvalidation_1-rmse:0.60768\n",
      "[670]\tvalidation_0-rmse:0.29669\tvalidation_1-rmse:0.60821\n",
      "[680]\tvalidation_0-rmse:0.29391\tvalidation_1-rmse:0.60864\n",
      "[690]\tvalidation_0-rmse:0.29090\tvalidation_1-rmse:0.60805\n",
      "[700]\tvalidation_0-rmse:0.28829\tvalidation_1-rmse:0.60769\n",
      "[710]\tvalidation_0-rmse:0.28572\tvalidation_1-rmse:0.60706\n",
      "[717]\tvalidation_0-rmse:0.28389\tvalidation_1-rmse:0.60730\n",
      "\n",
      "Fold_4 Training\n",
      "[0]\tvalidation_0-rmse:1.01039\tvalidation_1-rmse:0.99745\n",
      "[10]\tvalidation_0-rmse:0.88060\tvalidation_1-rmse:0.87958\n",
      "[20]\tvalidation_0-rmse:0.78610\tvalidation_1-rmse:0.79765\n",
      "[30]\tvalidation_0-rmse:0.71669\tvalidation_1-rmse:0.74169\n",
      "[40]\tvalidation_0-rmse:0.66730\tvalidation_1-rmse:0.70260\n",
      "[50]\tvalidation_0-rmse:0.63078\tvalidation_1-rmse:0.67575\n",
      "[60]\tvalidation_0-rmse:0.60315\tvalidation_1-rmse:0.65714\n",
      "[70]\tvalidation_0-rmse:0.58304\tvalidation_1-rmse:0.64541\n",
      "[80]\tvalidation_0-rmse:0.56605\tvalidation_1-rmse:0.63703\n",
      "[90]\tvalidation_0-rmse:0.55311\tvalidation_1-rmse:0.63019\n",
      "[100]\tvalidation_0-rmse:0.54119\tvalidation_1-rmse:0.62487\n",
      "[110]\tvalidation_0-rmse:0.53219\tvalidation_1-rmse:0.62359\n",
      "[120]\tvalidation_0-rmse:0.52343\tvalidation_1-rmse:0.62120\n",
      "[130]\tvalidation_0-rmse:0.51604\tvalidation_1-rmse:0.62069\n",
      "[140]\tvalidation_0-rmse:0.50877\tvalidation_1-rmse:0.61978\n",
      "[150]\tvalidation_0-rmse:0.50168\tvalidation_1-rmse:0.61886\n",
      "[160]\tvalidation_0-rmse:0.49498\tvalidation_1-rmse:0.61904\n",
      "[170]\tvalidation_0-rmse:0.48896\tvalidation_1-rmse:0.61861\n",
      "[180]\tvalidation_0-rmse:0.48227\tvalidation_1-rmse:0.61915\n",
      "[190]\tvalidation_0-rmse:0.47623\tvalidation_1-rmse:0.61865\n",
      "[200]\tvalidation_0-rmse:0.47052\tvalidation_1-rmse:0.61747\n",
      "[210]\tvalidation_0-rmse:0.46542\tvalidation_1-rmse:0.61756\n",
      "[220]\tvalidation_0-rmse:0.46077\tvalidation_1-rmse:0.61815\n",
      "[230]\tvalidation_0-rmse:0.45612\tvalidation_1-rmse:0.61854\n",
      "[240]\tvalidation_0-rmse:0.45149\tvalidation_1-rmse:0.61826\n",
      "[250]\tvalidation_0-rmse:0.44735\tvalidation_1-rmse:0.61787\n",
      "[260]\tvalidation_0-rmse:0.44304\tvalidation_1-rmse:0.61793\n",
      "[270]\tvalidation_0-rmse:0.43809\tvalidation_1-rmse:0.61818\n",
      "[280]\tvalidation_0-rmse:0.43407\tvalidation_1-rmse:0.61832\n",
      "[290]\tvalidation_0-rmse:0.42897\tvalidation_1-rmse:0.61841\n",
      "[300]\tvalidation_0-rmse:0.42434\tvalidation_1-rmse:0.61899\n",
      "[310]\tvalidation_0-rmse:0.41992\tvalidation_1-rmse:0.61886\n",
      "[320]\tvalidation_0-rmse:0.41588\tvalidation_1-rmse:0.61997\n",
      "[330]\tvalidation_0-rmse:0.41203\tvalidation_1-rmse:0.61932\n",
      "[340]\tvalidation_0-rmse:0.40861\tvalidation_1-rmse:0.61964\n",
      "[350]\tvalidation_0-rmse:0.40419\tvalidation_1-rmse:0.61914\n",
      "[360]\tvalidation_0-rmse:0.40009\tvalidation_1-rmse:0.61782\n",
      "[370]\tvalidation_0-rmse:0.39623\tvalidation_1-rmse:0.61785\n",
      "[380]\tvalidation_0-rmse:0.39243\tvalidation_1-rmse:0.61669\n",
      "[390]\tvalidation_0-rmse:0.38881\tvalidation_1-rmse:0.61723\n",
      "[400]\tvalidation_0-rmse:0.38467\tvalidation_1-rmse:0.61737\n",
      "[410]\tvalidation_0-rmse:0.38091\tvalidation_1-rmse:0.61690\n",
      "[420]\tvalidation_0-rmse:0.37711\tvalidation_1-rmse:0.61659\n",
      "[430]\tvalidation_0-rmse:0.37351\tvalidation_1-rmse:0.61718\n",
      "[440]\tvalidation_0-rmse:0.37018\tvalidation_1-rmse:0.61815\n",
      "[450]\tvalidation_0-rmse:0.36688\tvalidation_1-rmse:0.61831\n",
      "[460]\tvalidation_0-rmse:0.36286\tvalidation_1-rmse:0.61733\n",
      "[470]\tvalidation_0-rmse:0.35932\tvalidation_1-rmse:0.61727\n",
      "[480]\tvalidation_0-rmse:0.35653\tvalidation_1-rmse:0.61740\n",
      "[490]\tvalidation_0-rmse:0.35249\tvalidation_1-rmse:0.61736\n",
      "[500]\tvalidation_0-rmse:0.34898\tvalidation_1-rmse:0.61679\n",
      "[510]\tvalidation_0-rmse:0.34560\tvalidation_1-rmse:0.61763\n",
      "[520]\tvalidation_0-rmse:0.34250\tvalidation_1-rmse:0.61812\n",
      "[530]\tvalidation_0-rmse:0.33884\tvalidation_1-rmse:0.61762\n",
      "[540]\tvalidation_0-rmse:0.33536\tvalidation_1-rmse:0.61780\n",
      "[550]\tvalidation_0-rmse:0.33250\tvalidation_1-rmse:0.61778\n",
      "[560]\tvalidation_0-rmse:0.32922\tvalidation_1-rmse:0.61820\n",
      "[570]\tvalidation_0-rmse:0.32635\tvalidation_1-rmse:0.61759\n",
      "[580]\tvalidation_0-rmse:0.32338\tvalidation_1-rmse:0.61711\n",
      "[590]\tvalidation_0-rmse:0.32027\tvalidation_1-rmse:0.61782\n",
      "[600]\tvalidation_0-rmse:0.31699\tvalidation_1-rmse:0.61797\n",
      "[610]\tvalidation_0-rmse:0.31414\tvalidation_1-rmse:0.61834\n",
      "[620]\tvalidation_0-rmse:0.31093\tvalidation_1-rmse:0.61946\n",
      "[630]\tvalidation_0-rmse:0.30781\tvalidation_1-rmse:0.61834\n",
      "[640]\tvalidation_0-rmse:0.30530\tvalidation_1-rmse:0.61810\n",
      "[650]\tvalidation_0-rmse:0.30231\tvalidation_1-rmse:0.61878\n",
      "[660]\tvalidation_0-rmse:0.29934\tvalidation_1-rmse:0.61854\n",
      "[670]\tvalidation_0-rmse:0.29673\tvalidation_1-rmse:0.61853\n",
      "[680]\tvalidation_0-rmse:0.29381\tvalidation_1-rmse:0.61867\n",
      "[690]\tvalidation_0-rmse:0.29166\tvalidation_1-rmse:0.61819\n",
      "[700]\tvalidation_0-rmse:0.28939\tvalidation_1-rmse:0.61777\n",
      "[710]\tvalidation_0-rmse:0.28688\tvalidation_1-rmse:0.61760\n",
      "[720]\tvalidation_0-rmse:0.28400\tvalidation_1-rmse:0.61856\n",
      "[730]\tvalidation_0-rmse:0.28142\tvalidation_1-rmse:0.61829\n",
      "[740]\tvalidation_0-rmse:0.27860\tvalidation_1-rmse:0.61881\n",
      "[750]\tvalidation_0-rmse:0.27572\tvalidation_1-rmse:0.61819\n",
      "[760]\tvalidation_0-rmse:0.27320\tvalidation_1-rmse:0.61760\n",
      "[770]\tvalidation_0-rmse:0.27050\tvalidation_1-rmse:0.61743\n",
      "[780]\tvalidation_0-rmse:0.26771\tvalidation_1-rmse:0.61755\n",
      "[790]\tvalidation_0-rmse:0.26534\tvalidation_1-rmse:0.61739\n",
      "[800]\tvalidation_0-rmse:0.26282\tvalidation_1-rmse:0.61758\n",
      "[810]\tvalidation_0-rmse:0.26033\tvalidation_1-rmse:0.61798\n",
      "[820]\tvalidation_0-rmse:0.25785\tvalidation_1-rmse:0.61848\n",
      "[826]\tvalidation_0-rmse:0.25634\tvalidation_1-rmse:0.61874\n",
      "\n",
      "Fold_5 Training\n",
      "[0]\tvalidation_0-rmse:1.00974\tvalidation_1-rmse:1.00484\n",
      "[10]\tvalidation_0-rmse:0.87921\tvalidation_1-rmse:0.87215\n",
      "[20]\tvalidation_0-rmse:0.78625\tvalidation_1-rmse:0.78043\n",
      "[30]\tvalidation_0-rmse:0.71838\tvalidation_1-rmse:0.72058\n",
      "[40]\tvalidation_0-rmse:0.66997\tvalidation_1-rmse:0.67680\n",
      "[50]\tvalidation_0-rmse:0.63430\tvalidation_1-rmse:0.64793\n",
      "[60]\tvalidation_0-rmse:0.60675\tvalidation_1-rmse:0.62747\n",
      "[70]\tvalidation_0-rmse:0.58549\tvalidation_1-rmse:0.61433\n",
      "[80]\tvalidation_0-rmse:0.56926\tvalidation_1-rmse:0.60610\n",
      "[90]\tvalidation_0-rmse:0.55592\tvalidation_1-rmse:0.59870\n",
      "[100]\tvalidation_0-rmse:0.54489\tvalidation_1-rmse:0.59367\n",
      "[110]\tvalidation_0-rmse:0.53470\tvalidation_1-rmse:0.58937\n",
      "[120]\tvalidation_0-rmse:0.52685\tvalidation_1-rmse:0.58748\n",
      "[130]\tvalidation_0-rmse:0.51884\tvalidation_1-rmse:0.58613\n",
      "[140]\tvalidation_0-rmse:0.51199\tvalidation_1-rmse:0.58577\n",
      "[150]\tvalidation_0-rmse:0.50499\tvalidation_1-rmse:0.58436\n",
      "[160]\tvalidation_0-rmse:0.49895\tvalidation_1-rmse:0.58483\n",
      "[170]\tvalidation_0-rmse:0.49287\tvalidation_1-rmse:0.58354\n",
      "[180]\tvalidation_0-rmse:0.48689\tvalidation_1-rmse:0.58321\n",
      "[190]\tvalidation_0-rmse:0.48108\tvalidation_1-rmse:0.58318\n",
      "[200]\tvalidation_0-rmse:0.47559\tvalidation_1-rmse:0.58266\n",
      "[210]\tvalidation_0-rmse:0.47043\tvalidation_1-rmse:0.58209\n",
      "[220]\tvalidation_0-rmse:0.46530\tvalidation_1-rmse:0.58150\n",
      "[230]\tvalidation_0-rmse:0.45979\tvalidation_1-rmse:0.58081\n",
      "[240]\tvalidation_0-rmse:0.45463\tvalidation_1-rmse:0.58217\n",
      "[250]\tvalidation_0-rmse:0.44967\tvalidation_1-rmse:0.58276\n",
      "[260]\tvalidation_0-rmse:0.44547\tvalidation_1-rmse:0.58426\n",
      "[270]\tvalidation_0-rmse:0.44113\tvalidation_1-rmse:0.58538\n",
      "[280]\tvalidation_0-rmse:0.43683\tvalidation_1-rmse:0.58486\n",
      "[290]\tvalidation_0-rmse:0.43199\tvalidation_1-rmse:0.58407\n",
      "[300]\tvalidation_0-rmse:0.42752\tvalidation_1-rmse:0.58461\n",
      "[310]\tvalidation_0-rmse:0.42284\tvalidation_1-rmse:0.58548\n",
      "[320]\tvalidation_0-rmse:0.41792\tvalidation_1-rmse:0.58493\n",
      "[330]\tvalidation_0-rmse:0.41373\tvalidation_1-rmse:0.58440\n",
      "[340]\tvalidation_0-rmse:0.40921\tvalidation_1-rmse:0.58370\n",
      "[350]\tvalidation_0-rmse:0.40483\tvalidation_1-rmse:0.58367\n",
      "[360]\tvalidation_0-rmse:0.40072\tvalidation_1-rmse:0.58387\n",
      "[370]\tvalidation_0-rmse:0.39682\tvalidation_1-rmse:0.58510\n",
      "[380]\tvalidation_0-rmse:0.39246\tvalidation_1-rmse:0.58463\n",
      "[390]\tvalidation_0-rmse:0.38863\tvalidation_1-rmse:0.58431\n",
      "[400]\tvalidation_0-rmse:0.38463\tvalidation_1-rmse:0.58429\n",
      "[410]\tvalidation_0-rmse:0.38081\tvalidation_1-rmse:0.58413\n",
      "[420]\tvalidation_0-rmse:0.37719\tvalidation_1-rmse:0.58401\n",
      "[430]\tvalidation_0-rmse:0.37338\tvalidation_1-rmse:0.58435\n",
      "[440]\tvalidation_0-rmse:0.37005\tvalidation_1-rmse:0.58420\n",
      "[450]\tvalidation_0-rmse:0.36662\tvalidation_1-rmse:0.58442\n",
      "[460]\tvalidation_0-rmse:0.36286\tvalidation_1-rmse:0.58545\n",
      "[470]\tvalidation_0-rmse:0.35900\tvalidation_1-rmse:0.58593\n",
      "[480]\tvalidation_0-rmse:0.35601\tvalidation_1-rmse:0.58573\n",
      "[490]\tvalidation_0-rmse:0.35277\tvalidation_1-rmse:0.58569\n",
      "[500]\tvalidation_0-rmse:0.34910\tvalidation_1-rmse:0.58599\n",
      "[510]\tvalidation_0-rmse:0.34571\tvalidation_1-rmse:0.58581\n",
      "[520]\tvalidation_0-rmse:0.34233\tvalidation_1-rmse:0.58655\n",
      "[530]\tvalidation_0-rmse:0.33895\tvalidation_1-rmse:0.58634\n",
      "[540]\tvalidation_0-rmse:0.33582\tvalidation_1-rmse:0.58680\n",
      "[550]\tvalidation_0-rmse:0.33292\tvalidation_1-rmse:0.58656\n",
      "[560]\tvalidation_0-rmse:0.32947\tvalidation_1-rmse:0.58595\n",
      "[570]\tvalidation_0-rmse:0.32618\tvalidation_1-rmse:0.58629\n",
      "[580]\tvalidation_0-rmse:0.32329\tvalidation_1-rmse:0.58626\n",
      "[590]\tvalidation_0-rmse:0.32002\tvalidation_1-rmse:0.58601\n",
      "[600]\tvalidation_0-rmse:0.31713\tvalidation_1-rmse:0.58701\n",
      "[610]\tvalidation_0-rmse:0.31430\tvalidation_1-rmse:0.58722\n",
      "[620]\tvalidation_0-rmse:0.31152\tvalidation_1-rmse:0.58753\n",
      "[629]\tvalidation_0-rmse:0.30904\tvalidation_1-rmse:0.58731\n",
      "\n",
      "Fold_6 Training\n",
      "[0]\tvalidation_0-rmse:1.01039\tvalidation_1-rmse:1.00092\n",
      "[10]\tvalidation_0-rmse:0.87869\tvalidation_1-rmse:0.87358\n",
      "[20]\tvalidation_0-rmse:0.78445\tvalidation_1-rmse:0.78184\n",
      "[30]\tvalidation_0-rmse:0.71668\tvalidation_1-rmse:0.71690\n",
      "[40]\tvalidation_0-rmse:0.66879\tvalidation_1-rmse:0.67561\n",
      "[50]\tvalidation_0-rmse:0.63232\tvalidation_1-rmse:0.64530\n",
      "[60]\tvalidation_0-rmse:0.60552\tvalidation_1-rmse:0.62378\n",
      "[70]\tvalidation_0-rmse:0.58580\tvalidation_1-rmse:0.61002\n",
      "[80]\tvalidation_0-rmse:0.56961\tvalidation_1-rmse:0.60117\n",
      "[90]\tvalidation_0-rmse:0.55571\tvalidation_1-rmse:0.59619\n",
      "[100]\tvalidation_0-rmse:0.54478\tvalidation_1-rmse:0.59077\n",
      "[110]\tvalidation_0-rmse:0.53511\tvalidation_1-rmse:0.58767\n",
      "[120]\tvalidation_0-rmse:0.52600\tvalidation_1-rmse:0.58517\n",
      "[130]\tvalidation_0-rmse:0.51845\tvalidation_1-rmse:0.58329\n",
      "[140]\tvalidation_0-rmse:0.51132\tvalidation_1-rmse:0.58222\n",
      "[150]\tvalidation_0-rmse:0.50506\tvalidation_1-rmse:0.58278\n",
      "[160]\tvalidation_0-rmse:0.49876\tvalidation_1-rmse:0.58324\n",
      "[170]\tvalidation_0-rmse:0.49251\tvalidation_1-rmse:0.58330\n",
      "[180]\tvalidation_0-rmse:0.48627\tvalidation_1-rmse:0.58327\n",
      "[190]\tvalidation_0-rmse:0.48119\tvalidation_1-rmse:0.58341\n",
      "[200]\tvalidation_0-rmse:0.47584\tvalidation_1-rmse:0.58362\n",
      "[210]\tvalidation_0-rmse:0.47079\tvalidation_1-rmse:0.58435\n",
      "[220]\tvalidation_0-rmse:0.46570\tvalidation_1-rmse:0.58573\n",
      "[230]\tvalidation_0-rmse:0.46037\tvalidation_1-rmse:0.58575\n",
      "[240]\tvalidation_0-rmse:0.45523\tvalidation_1-rmse:0.58610\n",
      "[250]\tvalidation_0-rmse:0.45025\tvalidation_1-rmse:0.58619\n",
      "[260]\tvalidation_0-rmse:0.44554\tvalidation_1-rmse:0.58771\n",
      "[270]\tvalidation_0-rmse:0.44131\tvalidation_1-rmse:0.58826\n",
      "[280]\tvalidation_0-rmse:0.43727\tvalidation_1-rmse:0.58787\n",
      "[290]\tvalidation_0-rmse:0.43245\tvalidation_1-rmse:0.58868\n",
      "[300]\tvalidation_0-rmse:0.42822\tvalidation_1-rmse:0.58913\n",
      "[310]\tvalidation_0-rmse:0.42349\tvalidation_1-rmse:0.58982\n",
      "[320]\tvalidation_0-rmse:0.41879\tvalidation_1-rmse:0.59041\n",
      "[330]\tvalidation_0-rmse:0.41463\tvalidation_1-rmse:0.59055\n",
      "[340]\tvalidation_0-rmse:0.41028\tvalidation_1-rmse:0.59043\n",
      "[350]\tvalidation_0-rmse:0.40633\tvalidation_1-rmse:0.59045\n",
      "[360]\tvalidation_0-rmse:0.40269\tvalidation_1-rmse:0.59039\n",
      "[370]\tvalidation_0-rmse:0.39839\tvalidation_1-rmse:0.59092\n",
      "[380]\tvalidation_0-rmse:0.39476\tvalidation_1-rmse:0.59098\n",
      "[390]\tvalidation_0-rmse:0.39117\tvalidation_1-rmse:0.59109\n",
      "[400]\tvalidation_0-rmse:0.38768\tvalidation_1-rmse:0.59020\n",
      "[410]\tvalidation_0-rmse:0.38410\tvalidation_1-rmse:0.59116\n",
      "[420]\tvalidation_0-rmse:0.38064\tvalidation_1-rmse:0.59186\n",
      "[430]\tvalidation_0-rmse:0.37709\tvalidation_1-rmse:0.59199\n",
      "[440]\tvalidation_0-rmse:0.37389\tvalidation_1-rmse:0.59149\n",
      "[450]\tvalidation_0-rmse:0.37063\tvalidation_1-rmse:0.59146\n",
      "[460]\tvalidation_0-rmse:0.36721\tvalidation_1-rmse:0.59198\n",
      "[470]\tvalidation_0-rmse:0.36380\tvalidation_1-rmse:0.59211\n",
      "[480]\tvalidation_0-rmse:0.36000\tvalidation_1-rmse:0.59129\n",
      "[490]\tvalidation_0-rmse:0.35640\tvalidation_1-rmse:0.59105\n",
      "[500]\tvalidation_0-rmse:0.35299\tvalidation_1-rmse:0.59234\n",
      "[510]\tvalidation_0-rmse:0.34960\tvalidation_1-rmse:0.59082\n",
      "[520]\tvalidation_0-rmse:0.34626\tvalidation_1-rmse:0.59017\n",
      "[530]\tvalidation_0-rmse:0.34294\tvalidation_1-rmse:0.59052\n",
      "[540]\tvalidation_0-rmse:0.33914\tvalidation_1-rmse:0.59059\n",
      "[541]\tvalidation_0-rmse:0.33886\tvalidation_1-rmse:0.59056\n",
      "\n",
      "Fold_7 Training\n",
      "[0]\tvalidation_0-rmse:1.00836\tvalidation_1-rmse:1.01753\n",
      "[10]\tvalidation_0-rmse:0.87818\tvalidation_1-rmse:0.89541\n",
      "[20]\tvalidation_0-rmse:0.78561\tvalidation_1-rmse:0.80921\n",
      "[30]\tvalidation_0-rmse:0.71637\tvalidation_1-rmse:0.74686\n",
      "[40]\tvalidation_0-rmse:0.66725\tvalidation_1-rmse:0.70444\n",
      "[50]\tvalidation_0-rmse:0.63047\tvalidation_1-rmse:0.67559\n",
      "[60]\tvalidation_0-rmse:0.60288\tvalidation_1-rmse:0.65616\n",
      "[70]\tvalidation_0-rmse:0.58234\tvalidation_1-rmse:0.64162\n",
      "[80]\tvalidation_0-rmse:0.56575\tvalidation_1-rmse:0.63046\n",
      "[90]\tvalidation_0-rmse:0.55220\tvalidation_1-rmse:0.62150\n",
      "[100]\tvalidation_0-rmse:0.54106\tvalidation_1-rmse:0.61581\n",
      "[110]\tvalidation_0-rmse:0.53186\tvalidation_1-rmse:0.61253\n",
      "[120]\tvalidation_0-rmse:0.52399\tvalidation_1-rmse:0.60910\n",
      "[130]\tvalidation_0-rmse:0.51652\tvalidation_1-rmse:0.60647\n",
      "[140]\tvalidation_0-rmse:0.51000\tvalidation_1-rmse:0.60451\n",
      "[150]\tvalidation_0-rmse:0.50384\tvalidation_1-rmse:0.60243\n",
      "[160]\tvalidation_0-rmse:0.49763\tvalidation_1-rmse:0.60063\n",
      "[170]\tvalidation_0-rmse:0.49206\tvalidation_1-rmse:0.59875\n",
      "[180]\tvalidation_0-rmse:0.48655\tvalidation_1-rmse:0.59726\n",
      "[190]\tvalidation_0-rmse:0.48112\tvalidation_1-rmse:0.59584\n",
      "[200]\tvalidation_0-rmse:0.47582\tvalidation_1-rmse:0.59592\n",
      "[210]\tvalidation_0-rmse:0.47088\tvalidation_1-rmse:0.59511\n",
      "[220]\tvalidation_0-rmse:0.46579\tvalidation_1-rmse:0.59506\n",
      "[230]\tvalidation_0-rmse:0.46063\tvalidation_1-rmse:0.59503\n",
      "[240]\tvalidation_0-rmse:0.45607\tvalidation_1-rmse:0.59366\n",
      "[250]\tvalidation_0-rmse:0.45107\tvalidation_1-rmse:0.59297\n",
      "[260]\tvalidation_0-rmse:0.44656\tvalidation_1-rmse:0.59265\n",
      "[270]\tvalidation_0-rmse:0.44204\tvalidation_1-rmse:0.59096\n",
      "[280]\tvalidation_0-rmse:0.43698\tvalidation_1-rmse:0.59087\n",
      "[290]\tvalidation_0-rmse:0.43294\tvalidation_1-rmse:0.59046\n",
      "[300]\tvalidation_0-rmse:0.42830\tvalidation_1-rmse:0.58950\n",
      "[310]\tvalidation_0-rmse:0.42385\tvalidation_1-rmse:0.58898\n",
      "[320]\tvalidation_0-rmse:0.41955\tvalidation_1-rmse:0.58842\n",
      "[330]\tvalidation_0-rmse:0.41529\tvalidation_1-rmse:0.58748\n",
      "[340]\tvalidation_0-rmse:0.41131\tvalidation_1-rmse:0.58724\n",
      "[350]\tvalidation_0-rmse:0.40747\tvalidation_1-rmse:0.58722\n",
      "[360]\tvalidation_0-rmse:0.40279\tvalidation_1-rmse:0.58745\n",
      "[370]\tvalidation_0-rmse:0.39905\tvalidation_1-rmse:0.58739\n",
      "[380]\tvalidation_0-rmse:0.39508\tvalidation_1-rmse:0.58644\n",
      "[390]\tvalidation_0-rmse:0.39143\tvalidation_1-rmse:0.58687\n",
      "[400]\tvalidation_0-rmse:0.38797\tvalidation_1-rmse:0.58722\n",
      "[410]\tvalidation_0-rmse:0.38432\tvalidation_1-rmse:0.58672\n",
      "[420]\tvalidation_0-rmse:0.38045\tvalidation_1-rmse:0.58758\n",
      "[430]\tvalidation_0-rmse:0.37637\tvalidation_1-rmse:0.58703\n",
      "[440]\tvalidation_0-rmse:0.37251\tvalidation_1-rmse:0.58745\n",
      "[450]\tvalidation_0-rmse:0.36909\tvalidation_1-rmse:0.58767\n",
      "[460]\tvalidation_0-rmse:0.36611\tvalidation_1-rmse:0.58804\n",
      "[470]\tvalidation_0-rmse:0.36206\tvalidation_1-rmse:0.58790\n",
      "[480]\tvalidation_0-rmse:0.35839\tvalidation_1-rmse:0.58854\n",
      "[490]\tvalidation_0-rmse:0.35513\tvalidation_1-rmse:0.58916\n",
      "[500]\tvalidation_0-rmse:0.35153\tvalidation_1-rmse:0.58877\n",
      "[510]\tvalidation_0-rmse:0.34833\tvalidation_1-rmse:0.58831\n",
      "[520]\tvalidation_0-rmse:0.34508\tvalidation_1-rmse:0.58843\n",
      "[530]\tvalidation_0-rmse:0.34169\tvalidation_1-rmse:0.58851\n",
      "[540]\tvalidation_0-rmse:0.33860\tvalidation_1-rmse:0.58887\n",
      "[550]\tvalidation_0-rmse:0.33506\tvalidation_1-rmse:0.58940\n",
      "[560]\tvalidation_0-rmse:0.33197\tvalidation_1-rmse:0.58918\n",
      "[570]\tvalidation_0-rmse:0.32872\tvalidation_1-rmse:0.58918\n",
      "[580]\tvalidation_0-rmse:0.32589\tvalidation_1-rmse:0.58947\n",
      "[590]\tvalidation_0-rmse:0.32286\tvalidation_1-rmse:0.58841\n",
      "[600]\tvalidation_0-rmse:0.31981\tvalidation_1-rmse:0.58793\n",
      "[610]\tvalidation_0-rmse:0.31703\tvalidation_1-rmse:0.58774\n",
      "[620]\tvalidation_0-rmse:0.31410\tvalidation_1-rmse:0.58821\n",
      "[630]\tvalidation_0-rmse:0.31099\tvalidation_1-rmse:0.58806\n",
      "[640]\tvalidation_0-rmse:0.30784\tvalidation_1-rmse:0.58780\n",
      "[650]\tvalidation_0-rmse:0.30469\tvalidation_1-rmse:0.58777\n",
      "[660]\tvalidation_0-rmse:0.30177\tvalidation_1-rmse:0.58792\n",
      "[670]\tvalidation_0-rmse:0.29908\tvalidation_1-rmse:0.58754\n",
      "[680]\tvalidation_0-rmse:0.29664\tvalidation_1-rmse:0.58807\n",
      "[690]\tvalidation_0-rmse:0.29373\tvalidation_1-rmse:0.58844\n",
      "[700]\tvalidation_0-rmse:0.29120\tvalidation_1-rmse:0.58799\n",
      "[710]\tvalidation_0-rmse:0.28864\tvalidation_1-rmse:0.58759\n",
      "[720]\tvalidation_0-rmse:0.28556\tvalidation_1-rmse:0.58772\n",
      "[730]\tvalidation_0-rmse:0.28311\tvalidation_1-rmse:0.58776\n",
      "[740]\tvalidation_0-rmse:0.28021\tvalidation_1-rmse:0.58796\n",
      "[750]\tvalidation_0-rmse:0.27765\tvalidation_1-rmse:0.58761\n",
      "[760]\tvalidation_0-rmse:0.27505\tvalidation_1-rmse:0.58739\n",
      "[770]\tvalidation_0-rmse:0.27273\tvalidation_1-rmse:0.58758\n",
      "[778]\tvalidation_0-rmse:0.27081\tvalidation_1-rmse:0.58726\n",
      "\n",
      "Fold_8 Training\n",
      "[0]\tvalidation_0-rmse:1.00773\tvalidation_1-rmse:1.01630\n",
      "[10]\tvalidation_0-rmse:0.87694\tvalidation_1-rmse:0.89245\n",
      "[20]\tvalidation_0-rmse:0.78267\tvalidation_1-rmse:0.80929\n",
      "[30]\tvalidation_0-rmse:0.71407\tvalidation_1-rmse:0.75311\n",
      "[40]\tvalidation_0-rmse:0.66571\tvalidation_1-rmse:0.71318\n",
      "[50]\tvalidation_0-rmse:0.62885\tvalidation_1-rmse:0.68674\n",
      "[60]\tvalidation_0-rmse:0.60190\tvalidation_1-rmse:0.67087\n",
      "[70]\tvalidation_0-rmse:0.58178\tvalidation_1-rmse:0.65995\n",
      "[80]\tvalidation_0-rmse:0.56555\tvalidation_1-rmse:0.65188\n",
      "[90]\tvalidation_0-rmse:0.55215\tvalidation_1-rmse:0.64571\n",
      "[100]\tvalidation_0-rmse:0.54184\tvalidation_1-rmse:0.64372\n",
      "[110]\tvalidation_0-rmse:0.53184\tvalidation_1-rmse:0.64160\n",
      "[120]\tvalidation_0-rmse:0.52319\tvalidation_1-rmse:0.63862\n",
      "[130]\tvalidation_0-rmse:0.51578\tvalidation_1-rmse:0.63754\n",
      "[140]\tvalidation_0-rmse:0.50888\tvalidation_1-rmse:0.63703\n",
      "[150]\tvalidation_0-rmse:0.50174\tvalidation_1-rmse:0.63513\n",
      "[160]\tvalidation_0-rmse:0.49629\tvalidation_1-rmse:0.63274\n",
      "[170]\tvalidation_0-rmse:0.49035\tvalidation_1-rmse:0.63170\n",
      "[180]\tvalidation_0-rmse:0.48457\tvalidation_1-rmse:0.63099\n",
      "[190]\tvalidation_0-rmse:0.47886\tvalidation_1-rmse:0.63106\n",
      "[200]\tvalidation_0-rmse:0.47312\tvalidation_1-rmse:0.63139\n",
      "[210]\tvalidation_0-rmse:0.46813\tvalidation_1-rmse:0.63081\n",
      "[220]\tvalidation_0-rmse:0.46322\tvalidation_1-rmse:0.63135\n",
      "[230]\tvalidation_0-rmse:0.45818\tvalidation_1-rmse:0.63145\n",
      "[240]\tvalidation_0-rmse:0.45294\tvalidation_1-rmse:0.62966\n",
      "[250]\tvalidation_0-rmse:0.44817\tvalidation_1-rmse:0.62928\n",
      "[260]\tvalidation_0-rmse:0.44355\tvalidation_1-rmse:0.62974\n",
      "[270]\tvalidation_0-rmse:0.43842\tvalidation_1-rmse:0.63029\n",
      "[280]\tvalidation_0-rmse:0.43453\tvalidation_1-rmse:0.62942\n",
      "[290]\tvalidation_0-rmse:0.43039\tvalidation_1-rmse:0.62920\n",
      "[300]\tvalidation_0-rmse:0.42609\tvalidation_1-rmse:0.62900\n",
      "[310]\tvalidation_0-rmse:0.42152\tvalidation_1-rmse:0.62988\n",
      "[320]\tvalidation_0-rmse:0.41674\tvalidation_1-rmse:0.62999\n",
      "[330]\tvalidation_0-rmse:0.41278\tvalidation_1-rmse:0.62987\n",
      "[340]\tvalidation_0-rmse:0.40885\tvalidation_1-rmse:0.62952\n",
      "[350]\tvalidation_0-rmse:0.40499\tvalidation_1-rmse:0.63001\n",
      "[360]\tvalidation_0-rmse:0.40075\tvalidation_1-rmse:0.62960\n",
      "[370]\tvalidation_0-rmse:0.39656\tvalidation_1-rmse:0.62969\n",
      "[380]\tvalidation_0-rmse:0.39268\tvalidation_1-rmse:0.62986\n",
      "[390]\tvalidation_0-rmse:0.38894\tvalidation_1-rmse:0.63033\n",
      "[400]\tvalidation_0-rmse:0.38448\tvalidation_1-rmse:0.63043\n",
      "[410]\tvalidation_0-rmse:0.38068\tvalidation_1-rmse:0.63087\n",
      "[420]\tvalidation_0-rmse:0.37693\tvalidation_1-rmse:0.63092\n",
      "[430]\tvalidation_0-rmse:0.37258\tvalidation_1-rmse:0.63147\n",
      "[440]\tvalidation_0-rmse:0.36904\tvalidation_1-rmse:0.63193\n",
      "[450]\tvalidation_0-rmse:0.36512\tvalidation_1-rmse:0.63261\n",
      "[460]\tvalidation_0-rmse:0.36145\tvalidation_1-rmse:0.63201\n",
      "[470]\tvalidation_0-rmse:0.35808\tvalidation_1-rmse:0.63114\n",
      "[480]\tvalidation_0-rmse:0.35460\tvalidation_1-rmse:0.63174\n",
      "[490]\tvalidation_0-rmse:0.35096\tvalidation_1-rmse:0.63174\n",
      "[500]\tvalidation_0-rmse:0.34762\tvalidation_1-rmse:0.63199\n",
      "[510]\tvalidation_0-rmse:0.34421\tvalidation_1-rmse:0.63186\n",
      "[520]\tvalidation_0-rmse:0.34027\tvalidation_1-rmse:0.63215\n",
      "[530]\tvalidation_0-rmse:0.33661\tvalidation_1-rmse:0.63181\n",
      "[540]\tvalidation_0-rmse:0.33323\tvalidation_1-rmse:0.63214\n",
      "[550]\tvalidation_0-rmse:0.33025\tvalidation_1-rmse:0.63197\n",
      "[560]\tvalidation_0-rmse:0.32708\tvalidation_1-rmse:0.63228\n",
      "[570]\tvalidation_0-rmse:0.32392\tvalidation_1-rmse:0.63174\n",
      "[580]\tvalidation_0-rmse:0.32095\tvalidation_1-rmse:0.63183\n",
      "[590]\tvalidation_0-rmse:0.31793\tvalidation_1-rmse:0.63158\n",
      "[600]\tvalidation_0-rmse:0.31474\tvalidation_1-rmse:0.63157\n",
      "[610]\tvalidation_0-rmse:0.31125\tvalidation_1-rmse:0.63138\n",
      "[620]\tvalidation_0-rmse:0.30853\tvalidation_1-rmse:0.63162\n",
      "[630]\tvalidation_0-rmse:0.30569\tvalidation_1-rmse:0.63187\n",
      "[640]\tvalidation_0-rmse:0.30244\tvalidation_1-rmse:0.63142\n",
      "[650]\tvalidation_0-rmse:0.29920\tvalidation_1-rmse:0.63215\n",
      "[660]\tvalidation_0-rmse:0.29648\tvalidation_1-rmse:0.63316\n",
      "[670]\tvalidation_0-rmse:0.29353\tvalidation_1-rmse:0.63273\n",
      "[680]\tvalidation_0-rmse:0.29076\tvalidation_1-rmse:0.63259\n",
      "[690]\tvalidation_0-rmse:0.28818\tvalidation_1-rmse:0.63183\n",
      "[700]\tvalidation_0-rmse:0.28532\tvalidation_1-rmse:0.63131\n",
      "[702]\tvalidation_0-rmse:0.28474\tvalidation_1-rmse:0.63151\n",
      "\n",
      "Fold_9 Training\n",
      "[0]\tvalidation_0-rmse:1.00879\tvalidation_1-rmse:1.01766\n",
      "[10]\tvalidation_0-rmse:0.87805\tvalidation_1-rmse:0.89851\n",
      "[20]\tvalidation_0-rmse:0.78324\tvalidation_1-rmse:0.81532\n",
      "[30]\tvalidation_0-rmse:0.71339\tvalidation_1-rmse:0.75658\n",
      "[40]\tvalidation_0-rmse:0.66428\tvalidation_1-rmse:0.72006\n",
      "[50]\tvalidation_0-rmse:0.62712\tvalidation_1-rmse:0.69466\n",
      "[60]\tvalidation_0-rmse:0.59990\tvalidation_1-rmse:0.67746\n",
      "[70]\tvalidation_0-rmse:0.58061\tvalidation_1-rmse:0.66589\n",
      "[80]\tvalidation_0-rmse:0.56405\tvalidation_1-rmse:0.65728\n",
      "[90]\tvalidation_0-rmse:0.55100\tvalidation_1-rmse:0.65057\n",
      "[100]\tvalidation_0-rmse:0.54015\tvalidation_1-rmse:0.64546\n",
      "[110]\tvalidation_0-rmse:0.53047\tvalidation_1-rmse:0.64138\n",
      "[120]\tvalidation_0-rmse:0.52179\tvalidation_1-rmse:0.63944\n",
      "[130]\tvalidation_0-rmse:0.51430\tvalidation_1-rmse:0.63766\n",
      "[140]\tvalidation_0-rmse:0.50751\tvalidation_1-rmse:0.63595\n",
      "[150]\tvalidation_0-rmse:0.50147\tvalidation_1-rmse:0.63533\n",
      "[160]\tvalidation_0-rmse:0.49497\tvalidation_1-rmse:0.63468\n",
      "[170]\tvalidation_0-rmse:0.48974\tvalidation_1-rmse:0.63563\n",
      "[180]\tvalidation_0-rmse:0.48416\tvalidation_1-rmse:0.63461\n",
      "[190]\tvalidation_0-rmse:0.47891\tvalidation_1-rmse:0.63413\n",
      "[200]\tvalidation_0-rmse:0.47312\tvalidation_1-rmse:0.63321\n",
      "[210]\tvalidation_0-rmse:0.46781\tvalidation_1-rmse:0.63416\n",
      "[220]\tvalidation_0-rmse:0.46226\tvalidation_1-rmse:0.63393\n",
      "[230]\tvalidation_0-rmse:0.45733\tvalidation_1-rmse:0.63322\n",
      "[240]\tvalidation_0-rmse:0.45300\tvalidation_1-rmse:0.63210\n",
      "[250]\tvalidation_0-rmse:0.44833\tvalidation_1-rmse:0.63241\n",
      "[260]\tvalidation_0-rmse:0.44365\tvalidation_1-rmse:0.63254\n",
      "[270]\tvalidation_0-rmse:0.43854\tvalidation_1-rmse:0.63164\n",
      "[280]\tvalidation_0-rmse:0.43380\tvalidation_1-rmse:0.63147\n",
      "[290]\tvalidation_0-rmse:0.42914\tvalidation_1-rmse:0.63045\n",
      "[300]\tvalidation_0-rmse:0.42484\tvalidation_1-rmse:0.63021\n",
      "[310]\tvalidation_0-rmse:0.42073\tvalidation_1-rmse:0.62947\n",
      "[320]\tvalidation_0-rmse:0.41636\tvalidation_1-rmse:0.62915\n",
      "[330]\tvalidation_0-rmse:0.41263\tvalidation_1-rmse:0.62906\n",
      "[340]\tvalidation_0-rmse:0.40826\tvalidation_1-rmse:0.62887\n",
      "[350]\tvalidation_0-rmse:0.40432\tvalidation_1-rmse:0.62917\n",
      "[360]\tvalidation_0-rmse:0.39976\tvalidation_1-rmse:0.62874\n",
      "[370]\tvalidation_0-rmse:0.39545\tvalidation_1-rmse:0.62882\n",
      "[380]\tvalidation_0-rmse:0.39167\tvalidation_1-rmse:0.62895\n",
      "[390]\tvalidation_0-rmse:0.38748\tvalidation_1-rmse:0.62929\n",
      "[400]\tvalidation_0-rmse:0.38396\tvalidation_1-rmse:0.62839\n",
      "[410]\tvalidation_0-rmse:0.38017\tvalidation_1-rmse:0.62786\n",
      "[420]\tvalidation_0-rmse:0.37649\tvalidation_1-rmse:0.62742\n",
      "[430]\tvalidation_0-rmse:0.37268\tvalidation_1-rmse:0.62773\n",
      "[440]\tvalidation_0-rmse:0.36913\tvalidation_1-rmse:0.62801\n",
      "[450]\tvalidation_0-rmse:0.36525\tvalidation_1-rmse:0.62802\n",
      "[460]\tvalidation_0-rmse:0.36133\tvalidation_1-rmse:0.62822\n",
      "[470]\tvalidation_0-rmse:0.35793\tvalidation_1-rmse:0.62819\n",
      "[480]\tvalidation_0-rmse:0.35440\tvalidation_1-rmse:0.62870\n",
      "[490]\tvalidation_0-rmse:0.35096\tvalidation_1-rmse:0.62882\n",
      "[500]\tvalidation_0-rmse:0.34744\tvalidation_1-rmse:0.62907\n",
      "[510]\tvalidation_0-rmse:0.34431\tvalidation_1-rmse:0.62991\n",
      "[520]\tvalidation_0-rmse:0.34115\tvalidation_1-rmse:0.62969\n",
      "[530]\tvalidation_0-rmse:0.33800\tvalidation_1-rmse:0.62984\n",
      "[540]\tvalidation_0-rmse:0.33457\tvalidation_1-rmse:0.63071\n",
      "[550]\tvalidation_0-rmse:0.33141\tvalidation_1-rmse:0.63146\n",
      "[560]\tvalidation_0-rmse:0.32816\tvalidation_1-rmse:0.63181\n",
      "[570]\tvalidation_0-rmse:0.32498\tvalidation_1-rmse:0.63199\n",
      "[580]\tvalidation_0-rmse:0.32210\tvalidation_1-rmse:0.63171\n",
      "[590]\tvalidation_0-rmse:0.31918\tvalidation_1-rmse:0.63281\n",
      "[600]\tvalidation_0-rmse:0.31642\tvalidation_1-rmse:0.63258\n",
      "[610]\tvalidation_0-rmse:0.31304\tvalidation_1-rmse:0.63257\n",
      "[620]\tvalidation_0-rmse:0.31011\tvalidation_1-rmse:0.63313\n",
      "[630]\tvalidation_0-rmse:0.30732\tvalidation_1-rmse:0.63307\n",
      "[640]\tvalidation_0-rmse:0.30430\tvalidation_1-rmse:0.63373\n",
      "[650]\tvalidation_0-rmse:0.30117\tvalidation_1-rmse:0.63434\n",
      "[660]\tvalidation_0-rmse:0.29838\tvalidation_1-rmse:0.63455\n",
      "[670]\tvalidation_0-rmse:0.29545\tvalidation_1-rmse:0.63453\n",
      "[680]\tvalidation_0-rmse:0.29241\tvalidation_1-rmse:0.63478\n",
      "[690]\tvalidation_0-rmse:0.28968\tvalidation_1-rmse:0.63508\n",
      "[700]\tvalidation_0-rmse:0.28676\tvalidation_1-rmse:0.63515\n",
      "[710]\tvalidation_0-rmse:0.28405\tvalidation_1-rmse:0.63492\n",
      "[720]\tvalidation_0-rmse:0.28137\tvalidation_1-rmse:0.63521\n",
      "[730]\tvalidation_0-rmse:0.27907\tvalidation_1-rmse:0.63526\n",
      "[740]\tvalidation_0-rmse:0.27665\tvalidation_1-rmse:0.63502\n",
      "[750]\tvalidation_0-rmse:0.27438\tvalidation_1-rmse:0.63537\n",
      "[760]\tvalidation_0-rmse:0.27183\tvalidation_1-rmse:0.63566\n",
      "[770]\tvalidation_0-rmse:0.26903\tvalidation_1-rmse:0.63585\n",
      "[780]\tvalidation_0-rmse:0.26662\tvalidation_1-rmse:0.63593\n",
      "[790]\tvalidation_0-rmse:0.26420\tvalidation_1-rmse:0.63583\n",
      "[800]\tvalidation_0-rmse:0.26172\tvalidation_1-rmse:0.63544\n",
      "[810]\tvalidation_0-rmse:0.25962\tvalidation_1-rmse:0.63525\n",
      "[819]\tvalidation_0-rmse:0.25728\tvalidation_1-rmse:0.63562\n",
      "\n",
      "Fold_10 Training\n",
      "[0]\tvalidation_0-rmse:1.00791\tvalidation_1-rmse:1.01945\n",
      "[10]\tvalidation_0-rmse:0.87532\tvalidation_1-rmse:0.91402\n",
      "[20]\tvalidation_0-rmse:0.77953\tvalidation_1-rmse:0.83925\n",
      "[30]\tvalidation_0-rmse:0.71019\tvalidation_1-rmse:0.78875\n",
      "[40]\tvalidation_0-rmse:0.66049\tvalidation_1-rmse:0.75648\n",
      "[50]\tvalidation_0-rmse:0.62503\tvalidation_1-rmse:0.73354\n",
      "[60]\tvalidation_0-rmse:0.59773\tvalidation_1-rmse:0.71725\n",
      "[70]\tvalidation_0-rmse:0.57719\tvalidation_1-rmse:0.70654\n",
      "[80]\tvalidation_0-rmse:0.56059\tvalidation_1-rmse:0.69999\n",
      "[90]\tvalidation_0-rmse:0.54658\tvalidation_1-rmse:0.69463\n",
      "[100]\tvalidation_0-rmse:0.53476\tvalidation_1-rmse:0.69010\n",
      "[110]\tvalidation_0-rmse:0.52491\tvalidation_1-rmse:0.68730\n",
      "[120]\tvalidation_0-rmse:0.51589\tvalidation_1-rmse:0.68613\n",
      "[130]\tvalidation_0-rmse:0.50765\tvalidation_1-rmse:0.68291\n",
      "[140]\tvalidation_0-rmse:0.50090\tvalidation_1-rmse:0.68069\n",
      "[150]\tvalidation_0-rmse:0.49483\tvalidation_1-rmse:0.68088\n",
      "[160]\tvalidation_0-rmse:0.48805\tvalidation_1-rmse:0.68124\n",
      "[170]\tvalidation_0-rmse:0.48200\tvalidation_1-rmse:0.68043\n",
      "[180]\tvalidation_0-rmse:0.47626\tvalidation_1-rmse:0.68194\n",
      "[190]\tvalidation_0-rmse:0.47105\tvalidation_1-rmse:0.68156\n",
      "[200]\tvalidation_0-rmse:0.46665\tvalidation_1-rmse:0.68214\n",
      "[210]\tvalidation_0-rmse:0.46071\tvalidation_1-rmse:0.68175\n",
      "[220]\tvalidation_0-rmse:0.45557\tvalidation_1-rmse:0.68221\n",
      "[230]\tvalidation_0-rmse:0.45109\tvalidation_1-rmse:0.68343\n",
      "[240]\tvalidation_0-rmse:0.44595\tvalidation_1-rmse:0.68248\n",
      "[250]\tvalidation_0-rmse:0.44134\tvalidation_1-rmse:0.68181\n",
      "[260]\tvalidation_0-rmse:0.43636\tvalidation_1-rmse:0.68068\n",
      "[270]\tvalidation_0-rmse:0.43260\tvalidation_1-rmse:0.68012\n",
      "[280]\tvalidation_0-rmse:0.42813\tvalidation_1-rmse:0.67947\n",
      "[290]\tvalidation_0-rmse:0.42439\tvalidation_1-rmse:0.68076\n",
      "[300]\tvalidation_0-rmse:0.41967\tvalidation_1-rmse:0.68129\n",
      "[310]\tvalidation_0-rmse:0.41607\tvalidation_1-rmse:0.68103\n",
      "[320]\tvalidation_0-rmse:0.41207\tvalidation_1-rmse:0.68074\n",
      "[330]\tvalidation_0-rmse:0.40803\tvalidation_1-rmse:0.68050\n",
      "[340]\tvalidation_0-rmse:0.40375\tvalidation_1-rmse:0.68090\n",
      "[350]\tvalidation_0-rmse:0.39985\tvalidation_1-rmse:0.68156\n",
      "[360]\tvalidation_0-rmse:0.39608\tvalidation_1-rmse:0.68109\n",
      "[370]\tvalidation_0-rmse:0.39206\tvalidation_1-rmse:0.68078\n",
      "[380]\tvalidation_0-rmse:0.38821\tvalidation_1-rmse:0.68097\n",
      "[390]\tvalidation_0-rmse:0.38422\tvalidation_1-rmse:0.68133\n",
      "[400]\tvalidation_0-rmse:0.38051\tvalidation_1-rmse:0.68141\n",
      "[410]\tvalidation_0-rmse:0.37664\tvalidation_1-rmse:0.68108\n",
      "[420]\tvalidation_0-rmse:0.37268\tvalidation_1-rmse:0.68099\n",
      "[430]\tvalidation_0-rmse:0.36901\tvalidation_1-rmse:0.68139\n",
      "[440]\tvalidation_0-rmse:0.36536\tvalidation_1-rmse:0.68058\n",
      "[450]\tvalidation_0-rmse:0.36160\tvalidation_1-rmse:0.68071\n",
      "[460]\tvalidation_0-rmse:0.35834\tvalidation_1-rmse:0.68119\n",
      "[470]\tvalidation_0-rmse:0.35506\tvalidation_1-rmse:0.68078\n",
      "[480]\tvalidation_0-rmse:0.35139\tvalidation_1-rmse:0.68110\n",
      "[490]\tvalidation_0-rmse:0.34773\tvalidation_1-rmse:0.68194\n",
      "[500]\tvalidation_0-rmse:0.34455\tvalidation_1-rmse:0.68314\n",
      "[510]\tvalidation_0-rmse:0.34089\tvalidation_1-rmse:0.68422\n",
      "[520]\tvalidation_0-rmse:0.33777\tvalidation_1-rmse:0.68549\n",
      "[530]\tvalidation_0-rmse:0.33478\tvalidation_1-rmse:0.68474\n",
      "[540]\tvalidation_0-rmse:0.33173\tvalidation_1-rmse:0.68513\n",
      "[550]\tvalidation_0-rmse:0.32853\tvalidation_1-rmse:0.68465\n",
      "[560]\tvalidation_0-rmse:0.32491\tvalidation_1-rmse:0.68474\n",
      "[570]\tvalidation_0-rmse:0.32161\tvalidation_1-rmse:0.68591\n",
      "[580]\tvalidation_0-rmse:0.31814\tvalidation_1-rmse:0.68565\n",
      "[590]\tvalidation_0-rmse:0.31516\tvalidation_1-rmse:0.68573\n",
      "[600]\tvalidation_0-rmse:0.31277\tvalidation_1-rmse:0.68628\n",
      "[610]\tvalidation_0-rmse:0.30986\tvalidation_1-rmse:0.68693\n",
      "[620]\tvalidation_0-rmse:0.30702\tvalidation_1-rmse:0.68739\n",
      "[630]\tvalidation_0-rmse:0.30390\tvalidation_1-rmse:0.68813\n",
      "[640]\tvalidation_0-rmse:0.30096\tvalidation_1-rmse:0.68896\n",
      "[650]\tvalidation_0-rmse:0.29840\tvalidation_1-rmse:0.68913\n",
      "[660]\tvalidation_0-rmse:0.29569\tvalidation_1-rmse:0.68938\n",
      "[670]\tvalidation_0-rmse:0.29267\tvalidation_1-rmse:0.69010\n",
      "[676]\tvalidation_0-rmse:0.29101\tvalidation_1-rmse:0.69017\n"
     ]
    }
   ],
   "source": [
    "xgb_oof = []  \n",
    "df_importance_list_xgb = []  \n",
    "ycol = 'score'\n",
    "feature_names = list(filter(lambda x: x not in [ycol, 'id'], train_feats.columns))\n",
    "\n",
    "for i, (train_index, valid_index) in enumerate(skf.split(x, y.astype(str))):\n",
    "    train_x, train_y, valid_x, valid_y = train_valid_split(x, y, train_index, valid_index)\n",
    "    \n",
    "    print('\\nFold_{} Training'.format(i+1))\n",
    "    xgbr.fit(train_x, \n",
    "              train_y,\n",
    "              eval_set=[(train_x, train_y), (valid_x, valid_y)],\n",
    "              early_stopping_rounds=400,\n",
    "              verbose=10)\n",
    "    xgbr_pred = xgbr.predict(valid_x)\n",
    "    \n",
    "    df_xgb_oof = train_feats.iloc[valid_index][['id', ycol]].copy()\n",
    "    df_xgb_oof['pred'] = xgbr_pred\n",
    "    xgb_oof.append(df_xgb_oof)\n",
    "    \n",
    "    xgb_preds = xgbr.predict(testin_x)\n",
    "    df_importance_xgb = pd.DataFrame({\n",
    "        'column': feature_names,\n",
    "        'importance': xgbr.feature_importances_,\n",
    "    })\n",
    "    df_importance_list_xgb.append(df_importance_xgb)\n",
    "\n",
    "df_importance_xgb = pd.concat(df_importance_list_xgb)\n",
    "df_importance_xgb = df_importance_xgb.groupby(['column'])['importance'].agg(\n",
    "    'mean').sort_values(ascending=False).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c36f3436",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-01-08T05:12:08.007880Z",
     "iopub.status.busy": "2024-01-08T05:12:08.007471Z",
     "iopub.status.idle": "2024-01-08T05:14:30.300624Z",
     "shell.execute_reply": "2024-01-08T05:14:30.299105Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 142.391868,
     "end_time": "2024-01-08T05:14:30.303248",
     "exception": false,
     "start_time": "2024-01-08T05:12:07.911380",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold_1 Training\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.8151102699226822e-06, reg_alpha=0.5087856916700971 will be ignored. Current value: lambda_l1=1.8151102699226822e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8410863683391213, subsample=0.5411528279742139 will be ignored. Current value: bagging_fraction=0.8410863683391213\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.017602890537921387, reg_lambda=0.2405984837342317 will be ignored. Current value: lambda_l2=0.017602890537921387\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.8151102699226822e-06, reg_alpha=0.5087856916700971 will be ignored. Current value: lambda_l1=1.8151102699226822e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8410863683391213, subsample=0.5411528279742139 will be ignored. Current value: bagging_fraction=0.8410863683391213\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.017602890537921387, reg_lambda=0.2405984837342317 will be ignored. Current value: lambda_l2=0.017602890537921387\n",
      "[LightGBM] [Info] Total Bins 86881\n",
      "[LightGBM] [Info] Number of data points in the train set: 2223, number of used features: 398\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.8151102699226822e-06, reg_alpha=0.5087856916700971 will be ignored. Current value: lambda_l1=1.8151102699226822e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8410863683391213, subsample=0.5411528279742139 will be ignored. Current value: bagging_fraction=0.8410863683391213\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.017602890537921387, reg_lambda=0.2405984837342317 will be ignored. Current value: lambda_l2=0.017602890537921387\n",
      "[LightGBM] [Info] Start training from score 3.710976\n",
      "[10]\ttraining's rmse: 0.929748\tvalid_1's rmse: 0.94261\n",
      "[20]\ttraining's rmse: 0.852879\tvalid_1's rmse: 0.870942\n",
      "[30]\ttraining's rmse: 0.790783\tvalid_1's rmse: 0.813414\n",
      "[40]\ttraining's rmse: 0.739501\tvalid_1's rmse: 0.76667\n",
      "[50]\ttraining's rmse: 0.697762\tvalid_1's rmse: 0.729205\n",
      "[60]\ttraining's rmse: 0.663776\tvalid_1's rmse: 0.697687\n",
      "[70]\ttraining's rmse: 0.635938\tvalid_1's rmse: 0.673727\n",
      "[80]\ttraining's rmse: 0.612001\tvalid_1's rmse: 0.655508\n",
      "[90]\ttraining's rmse: 0.592646\tvalid_1's rmse: 0.641934\n",
      "[100]\ttraining's rmse: 0.576151\tvalid_1's rmse: 0.631156\n",
      "[110]\ttraining's rmse: 0.562293\tvalid_1's rmse: 0.622034\n",
      "[120]\ttraining's rmse: 0.549926\tvalid_1's rmse: 0.613795\n",
      "[130]\ttraining's rmse: 0.538579\tvalid_1's rmse: 0.607248\n",
      "[140]\ttraining's rmse: 0.528672\tvalid_1's rmse: 0.602414\n",
      "[150]\ttraining's rmse: 0.51947\tvalid_1's rmse: 0.597554\n",
      "[160]\ttraining's rmse: 0.511219\tvalid_1's rmse: 0.594936\n",
      "[170]\ttraining's rmse: 0.503205\tvalid_1's rmse: 0.591637\n",
      "[180]\ttraining's rmse: 0.495852\tvalid_1's rmse: 0.590781\n",
      "[190]\ttraining's rmse: 0.488754\tvalid_1's rmse: 0.588849\n",
      "[200]\ttraining's rmse: 0.482037\tvalid_1's rmse: 0.58777\n",
      "[210]\ttraining's rmse: 0.475411\tvalid_1's rmse: 0.587549\n",
      "[220]\ttraining's rmse: 0.469146\tvalid_1's rmse: 0.586291\n",
      "[230]\ttraining's rmse: 0.463234\tvalid_1's rmse: 0.585893\n",
      "[240]\ttraining's rmse: 0.457328\tvalid_1's rmse: 0.585393\n",
      "[250]\ttraining's rmse: 0.45161\tvalid_1's rmse: 0.585437\n",
      "[260]\ttraining's rmse: 0.446109\tvalid_1's rmse: 0.585426\n",
      "[270]\ttraining's rmse: 0.440849\tvalid_1's rmse: 0.585314\n",
      "[280]\ttraining's rmse: 0.435752\tvalid_1's rmse: 0.585916\n",
      "[290]\ttraining's rmse: 0.430565\tvalid_1's rmse: 0.585146\n",
      "[300]\ttraining's rmse: 0.425729\tvalid_1's rmse: 0.584943\n",
      "[310]\ttraining's rmse: 0.42101\tvalid_1's rmse: 0.585475\n",
      "[320]\ttraining's rmse: 0.416239\tvalid_1's rmse: 0.585777\n",
      "[330]\ttraining's rmse: 0.411762\tvalid_1's rmse: 0.586189\n",
      "[340]\ttraining's rmse: 0.407045\tvalid_1's rmse: 0.58673\n",
      "[350]\ttraining's rmse: 0.402712\tvalid_1's rmse: 0.586505\n",
      "[360]\ttraining's rmse: 0.398522\tvalid_1's rmse: 0.58692\n",
      "[370]\ttraining's rmse: 0.394158\tvalid_1's rmse: 0.587163\n",
      "[380]\ttraining's rmse: 0.390092\tvalid_1's rmse: 0.587926\n",
      "[390]\ttraining's rmse: 0.386014\tvalid_1's rmse: 0.588281\n",
      "[400]\ttraining's rmse: 0.382233\tvalid_1's rmse: 0.58847\n",
      "[410]\ttraining's rmse: 0.37839\tvalid_1's rmse: 0.589114\n",
      "[420]\ttraining's rmse: 0.374628\tvalid_1's rmse: 0.589757\n",
      "[430]\ttraining's rmse: 0.370903\tvalid_1's rmse: 0.589573\n",
      "[440]\ttraining's rmse: 0.367031\tvalid_1's rmse: 0.58927\n",
      "[450]\ttraining's rmse: 0.363307\tvalid_1's rmse: 0.589635\n",
      "[460]\ttraining's rmse: 0.359709\tvalid_1's rmse: 0.589686\n",
      "[470]\ttraining's rmse: 0.356347\tvalid_1's rmse: 0.589332\n",
      "[480]\ttraining's rmse: 0.352973\tvalid_1's rmse: 0.588208\n",
      "[490]\ttraining's rmse: 0.349479\tvalid_1's rmse: 0.588223\n",
      "[500]\ttraining's rmse: 0.346197\tvalid_1's rmse: 0.588185\n",
      "[510]\ttraining's rmse: 0.342842\tvalid_1's rmse: 0.588081\n",
      "[520]\ttraining's rmse: 0.33937\tvalid_1's rmse: 0.58803\n",
      "[530]\ttraining's rmse: 0.336036\tvalid_1's rmse: 0.588188\n",
      "[540]\ttraining's rmse: 0.332784\tvalid_1's rmse: 0.588285\n",
      "[550]\ttraining's rmse: 0.329528\tvalid_1's rmse: 0.588321\n",
      "[560]\ttraining's rmse: 0.326389\tvalid_1's rmse: 0.58818\n",
      "[570]\ttraining's rmse: 0.32317\tvalid_1's rmse: 0.587958\n",
      "[580]\ttraining's rmse: 0.320227\tvalid_1's rmse: 0.588526\n",
      "[590]\ttraining's rmse: 0.317486\tvalid_1's rmse: 0.589219\n",
      "[600]\ttraining's rmse: 0.314626\tvalid_1's rmse: 0.588928\n",
      "[610]\ttraining's rmse: 0.311631\tvalid_1's rmse: 0.589255\n",
      "[620]\ttraining's rmse: 0.30868\tvalid_1's rmse: 0.589214\n",
      "[630]\ttraining's rmse: 0.305613\tvalid_1's rmse: 0.589224\n",
      "[640]\ttraining's rmse: 0.302625\tvalid_1's rmse: 0.589717\n",
      "[650]\ttraining's rmse: 0.299787\tvalid_1's rmse: 0.589942\n",
      "[660]\ttraining's rmse: 0.296834\tvalid_1's rmse: 0.589849\n",
      "[670]\ttraining's rmse: 0.294017\tvalid_1's rmse: 0.589764\n",
      "[680]\ttraining's rmse: 0.291301\tvalid_1's rmse: 0.589588\n",
      "[690]\ttraining's rmse: 0.28832\tvalid_1's rmse: 0.589973\n",
      "[700]\ttraining's rmse: 0.285788\tvalid_1's rmse: 0.5902\n",
      "\n",
      "Fold_2 Training\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.8151102699226822e-06, reg_alpha=0.5087856916700971 will be ignored. Current value: lambda_l1=1.8151102699226822e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8410863683391213, subsample=0.5411528279742139 will be ignored. Current value: bagging_fraction=0.8410863683391213\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.017602890537921387, reg_lambda=0.2405984837342317 will be ignored. Current value: lambda_l2=0.017602890537921387\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.8151102699226822e-06, reg_alpha=0.5087856916700971 will be ignored. Current value: lambda_l1=1.8151102699226822e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8410863683391213, subsample=0.5411528279742139 will be ignored. Current value: bagging_fraction=0.8410863683391213\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.017602890537921387, reg_lambda=0.2405984837342317 will be ignored. Current value: lambda_l2=0.017602890537921387\n",
      "[LightGBM] [Info] Total Bins 86886\n",
      "[LightGBM] [Info] Number of data points in the train set: 2224, number of used features: 398\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.8151102699226822e-06, reg_alpha=0.5087856916700971 will be ignored. Current value: lambda_l1=1.8151102699226822e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8410863683391213, subsample=0.5411528279742139 will be ignored. Current value: bagging_fraction=0.8410863683391213\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.017602890537921387, reg_lambda=0.2405984837342317 will be ignored. Current value: lambda_l2=0.017602890537921387\n",
      "[LightGBM] [Info] Start training from score 3.711556\n",
      "[10]\ttraining's rmse: 0.930507\tvalid_1's rmse: 0.930573\n",
      "[20]\ttraining's rmse: 0.85262\tvalid_1's rmse: 0.859211\n",
      "[30]\ttraining's rmse: 0.789092\tvalid_1's rmse: 0.801371\n",
      "[40]\ttraining's rmse: 0.737638\tvalid_1's rmse: 0.757623\n",
      "[50]\ttraining's rmse: 0.695312\tvalid_1's rmse: 0.722256\n",
      "[60]\ttraining's rmse: 0.660511\tvalid_1's rmse: 0.696106\n",
      "[70]\ttraining's rmse: 0.632221\tvalid_1's rmse: 0.676762\n",
      "[80]\ttraining's rmse: 0.608525\tvalid_1's rmse: 0.659907\n",
      "[90]\ttraining's rmse: 0.589182\tvalid_1's rmse: 0.647803\n",
      "[100]\ttraining's rmse: 0.572774\tvalid_1's rmse: 0.638896\n",
      "[110]\ttraining's rmse: 0.558786\tvalid_1's rmse: 0.631138\n",
      "[120]\ttraining's rmse: 0.54614\tvalid_1's rmse: 0.625167\n",
      "[130]\ttraining's rmse: 0.535008\tvalid_1's rmse: 0.62065\n",
      "[140]\ttraining's rmse: 0.525094\tvalid_1's rmse: 0.618018\n",
      "[150]\ttraining's rmse: 0.516147\tvalid_1's rmse: 0.614528\n",
      "[160]\ttraining's rmse: 0.507628\tvalid_1's rmse: 0.612374\n",
      "[170]\ttraining's rmse: 0.499745\tvalid_1's rmse: 0.608673\n",
      "[180]\ttraining's rmse: 0.492559\tvalid_1's rmse: 0.606659\n",
      "[190]\ttraining's rmse: 0.485804\tvalid_1's rmse: 0.604632\n",
      "[200]\ttraining's rmse: 0.478969\tvalid_1's rmse: 0.603839\n",
      "[210]\ttraining's rmse: 0.472644\tvalid_1's rmse: 0.603507\n",
      "[220]\ttraining's rmse: 0.466423\tvalid_1's rmse: 0.602406\n",
      "[230]\ttraining's rmse: 0.460426\tvalid_1's rmse: 0.60207\n",
      "[240]\ttraining's rmse: 0.454958\tvalid_1's rmse: 0.601782\n",
      "[250]\ttraining's rmse: 0.449599\tvalid_1's rmse: 0.601705\n",
      "[260]\ttraining's rmse: 0.444147\tvalid_1's rmse: 0.601781\n",
      "[270]\ttraining's rmse: 0.438934\tvalid_1's rmse: 0.600938\n",
      "[280]\ttraining's rmse: 0.433747\tvalid_1's rmse: 0.601787\n",
      "[290]\ttraining's rmse: 0.428781\tvalid_1's rmse: 0.601753\n",
      "[300]\ttraining's rmse: 0.424004\tvalid_1's rmse: 0.601932\n",
      "[310]\ttraining's rmse: 0.419037\tvalid_1's rmse: 0.601726\n",
      "[320]\ttraining's rmse: 0.414308\tvalid_1's rmse: 0.602034\n",
      "[330]\ttraining's rmse: 0.409929\tvalid_1's rmse: 0.601646\n",
      "[340]\ttraining's rmse: 0.405499\tvalid_1's rmse: 0.600954\n",
      "[350]\ttraining's rmse: 0.40099\tvalid_1's rmse: 0.600557\n",
      "[360]\ttraining's rmse: 0.396533\tvalid_1's rmse: 0.600709\n",
      "[370]\ttraining's rmse: 0.39233\tvalid_1's rmse: 0.600854\n",
      "[380]\ttraining's rmse: 0.388125\tvalid_1's rmse: 0.601916\n",
      "[390]\ttraining's rmse: 0.384167\tvalid_1's rmse: 0.601249\n",
      "[400]\ttraining's rmse: 0.380131\tvalid_1's rmse: 0.601416\n",
      "[410]\ttraining's rmse: 0.376127\tvalid_1's rmse: 0.60162\n",
      "[420]\ttraining's rmse: 0.372282\tvalid_1's rmse: 0.601713\n",
      "[430]\ttraining's rmse: 0.368673\tvalid_1's rmse: 0.602297\n",
      "[440]\ttraining's rmse: 0.364794\tvalid_1's rmse: 0.602461\n",
      "[450]\ttraining's rmse: 0.36133\tvalid_1's rmse: 0.602141\n",
      "[460]\ttraining's rmse: 0.35763\tvalid_1's rmse: 0.602002\n",
      "[470]\ttraining's rmse: 0.353962\tvalid_1's rmse: 0.601927\n",
      "[480]\ttraining's rmse: 0.3502\tvalid_1's rmse: 0.602735\n",
      "[490]\ttraining's rmse: 0.346791\tvalid_1's rmse: 0.603027\n",
      "[500]\ttraining's rmse: 0.343425\tvalid_1's rmse: 0.602837\n",
      "[510]\ttraining's rmse: 0.339752\tvalid_1's rmse: 0.603092\n",
      "[520]\ttraining's rmse: 0.33633\tvalid_1's rmse: 0.603031\n",
      "[530]\ttraining's rmse: 0.332924\tvalid_1's rmse: 0.603233\n",
      "[540]\ttraining's rmse: 0.329541\tvalid_1's rmse: 0.603149\n",
      "[550]\ttraining's rmse: 0.326151\tvalid_1's rmse: 0.603156\n",
      "[560]\ttraining's rmse: 0.323037\tvalid_1's rmse: 0.603123\n",
      "[570]\ttraining's rmse: 0.319748\tvalid_1's rmse: 0.603178\n",
      "[580]\ttraining's rmse: 0.316504\tvalid_1's rmse: 0.602894\n",
      "[590]\ttraining's rmse: 0.313427\tvalid_1's rmse: 0.603015\n",
      "[600]\ttraining's rmse: 0.310432\tvalid_1's rmse: 0.602867\n",
      "[610]\ttraining's rmse: 0.307452\tvalid_1's rmse: 0.602824\n",
      "[620]\ttraining's rmse: 0.304611\tvalid_1's rmse: 0.603316\n",
      "[630]\ttraining's rmse: 0.301636\tvalid_1's rmse: 0.603161\n",
      "[640]\ttraining's rmse: 0.298767\tvalid_1's rmse: 0.603384\n",
      "[650]\ttraining's rmse: 0.295798\tvalid_1's rmse: 0.603542\n",
      "[660]\ttraining's rmse: 0.292922\tvalid_1's rmse: 0.604062\n",
      "[670]\ttraining's rmse: 0.290151\tvalid_1's rmse: 0.604534\n",
      "[680]\ttraining's rmse: 0.287449\tvalid_1's rmse: 0.604755\n",
      "[690]\ttraining's rmse: 0.284648\tvalid_1's rmse: 0.60501\n",
      "[700]\ttraining's rmse: 0.282027\tvalid_1's rmse: 0.605131\n",
      "[710]\ttraining's rmse: 0.279383\tvalid_1's rmse: 0.605039\n",
      "[720]\ttraining's rmse: 0.276868\tvalid_1's rmse: 0.604878\n",
      "[730]\ttraining's rmse: 0.274415\tvalid_1's rmse: 0.6047\n",
      "[740]\ttraining's rmse: 0.271954\tvalid_1's rmse: 0.604499\n",
      "[750]\ttraining's rmse: 0.269411\tvalid_1's rmse: 0.604844\n",
      "\n",
      "Fold_3 Training\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.8151102699226822e-06, reg_alpha=0.5087856916700971 will be ignored. Current value: lambda_l1=1.8151102699226822e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8410863683391213, subsample=0.5411528279742139 will be ignored. Current value: bagging_fraction=0.8410863683391213\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.017602890537921387, reg_lambda=0.2405984837342317 will be ignored. Current value: lambda_l2=0.017602890537921387\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.8151102699226822e-06, reg_alpha=0.5087856916700971 will be ignored. Current value: lambda_l1=1.8151102699226822e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8410863683391213, subsample=0.5411528279742139 will be ignored. Current value: bagging_fraction=0.8410863683391213\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.017602890537921387, reg_lambda=0.2405984837342317 will be ignored. Current value: lambda_l2=0.017602890537921387\n",
      "[LightGBM] [Info] Total Bins 86912\n",
      "[LightGBM] [Info] Number of data points in the train set: 2224, number of used features: 398\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.8151102699226822e-06, reg_alpha=0.5087856916700971 will be ignored. Current value: lambda_l1=1.8151102699226822e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8410863683391213, subsample=0.5411528279742139 will be ignored. Current value: bagging_fraction=0.8410863683391213\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.017602890537921387, reg_lambda=0.2405984837342317 will be ignored. Current value: lambda_l2=0.017602890537921387\n",
      "[LightGBM] [Info] Start training from score 3.711556\n",
      "[10]\ttraining's rmse: 0.930724\tvalid_1's rmse: 0.93053\n",
      "[20]\ttraining's rmse: 0.853234\tvalid_1's rmse: 0.856448\n",
      "[30]\ttraining's rmse: 0.789463\tvalid_1's rmse: 0.798021\n",
      "[40]\ttraining's rmse: 0.737863\tvalid_1's rmse: 0.753676\n",
      "[50]\ttraining's rmse: 0.696012\tvalid_1's rmse: 0.71927\n",
      "[60]\ttraining's rmse: 0.661626\tvalid_1's rmse: 0.694309\n",
      "[70]\ttraining's rmse: 0.633957\tvalid_1's rmse: 0.673533\n",
      "[80]\ttraining's rmse: 0.610588\tvalid_1's rmse: 0.656093\n",
      "[90]\ttraining's rmse: 0.590773\tvalid_1's rmse: 0.642496\n",
      "[100]\ttraining's rmse: 0.574011\tvalid_1's rmse: 0.633845\n",
      "[110]\ttraining's rmse: 0.559983\tvalid_1's rmse: 0.627808\n",
      "[120]\ttraining's rmse: 0.547936\tvalid_1's rmse: 0.621339\n",
      "[130]\ttraining's rmse: 0.536842\tvalid_1's rmse: 0.61833\n",
      "[140]\ttraining's rmse: 0.526961\tvalid_1's rmse: 0.614487\n",
      "[150]\ttraining's rmse: 0.517473\tvalid_1's rmse: 0.611608\n",
      "[160]\ttraining's rmse: 0.509047\tvalid_1's rmse: 0.609515\n",
      "[170]\ttraining's rmse: 0.50088\tvalid_1's rmse: 0.608591\n",
      "[180]\ttraining's rmse: 0.493492\tvalid_1's rmse: 0.608487\n",
      "[190]\ttraining's rmse: 0.486321\tvalid_1's rmse: 0.608286\n",
      "[200]\ttraining's rmse: 0.479624\tvalid_1's rmse: 0.606359\n",
      "[210]\ttraining's rmse: 0.473307\tvalid_1's rmse: 0.605064\n",
      "[220]\ttraining's rmse: 0.467069\tvalid_1's rmse: 0.605115\n",
      "[230]\ttraining's rmse: 0.461057\tvalid_1's rmse: 0.605644\n",
      "[240]\ttraining's rmse: 0.455181\tvalid_1's rmse: 0.605481\n",
      "[250]\ttraining's rmse: 0.449566\tvalid_1's rmse: 0.605782\n",
      "[260]\ttraining's rmse: 0.44404\tvalid_1's rmse: 0.605723\n",
      "[270]\ttraining's rmse: 0.438576\tvalid_1's rmse: 0.605412\n",
      "[280]\ttraining's rmse: 0.433526\tvalid_1's rmse: 0.604745\n",
      "[290]\ttraining's rmse: 0.428742\tvalid_1's rmse: 0.60442\n",
      "[300]\ttraining's rmse: 0.424039\tvalid_1's rmse: 0.604199\n",
      "[310]\ttraining's rmse: 0.419217\tvalid_1's rmse: 0.604222\n",
      "[320]\ttraining's rmse: 0.414541\tvalid_1's rmse: 0.60432\n",
      "[330]\ttraining's rmse: 0.410179\tvalid_1's rmse: 0.604052\n",
      "[340]\ttraining's rmse: 0.405821\tvalid_1's rmse: 0.603696\n",
      "[350]\ttraining's rmse: 0.401126\tvalid_1's rmse: 0.603276\n",
      "[360]\ttraining's rmse: 0.396809\tvalid_1's rmse: 0.603262\n",
      "[370]\ttraining's rmse: 0.392555\tvalid_1's rmse: 0.604143\n",
      "[380]\ttraining's rmse: 0.388336\tvalid_1's rmse: 0.603677\n",
      "[390]\ttraining's rmse: 0.384089\tvalid_1's rmse: 0.604867\n",
      "[400]\ttraining's rmse: 0.38016\tvalid_1's rmse: 0.604474\n",
      "[410]\ttraining's rmse: 0.376365\tvalid_1's rmse: 0.604577\n",
      "[420]\ttraining's rmse: 0.372707\tvalid_1's rmse: 0.604675\n",
      "[430]\ttraining's rmse: 0.368706\tvalid_1's rmse: 0.604911\n",
      "[440]\ttraining's rmse: 0.364898\tvalid_1's rmse: 0.605198\n",
      "[450]\ttraining's rmse: 0.361327\tvalid_1's rmse: 0.604727\n",
      "[460]\ttraining's rmse: 0.357601\tvalid_1's rmse: 0.604439\n",
      "[470]\ttraining's rmse: 0.354319\tvalid_1's rmse: 0.60472\n",
      "[480]\ttraining's rmse: 0.350886\tvalid_1's rmse: 0.604319\n",
      "[490]\ttraining's rmse: 0.347573\tvalid_1's rmse: 0.603935\n",
      "[500]\ttraining's rmse: 0.344356\tvalid_1's rmse: 0.604321\n",
      "[510]\ttraining's rmse: 0.341002\tvalid_1's rmse: 0.604634\n",
      "[520]\ttraining's rmse: 0.337792\tvalid_1's rmse: 0.604602\n",
      "[530]\ttraining's rmse: 0.334728\tvalid_1's rmse: 0.604544\n",
      "[540]\ttraining's rmse: 0.331803\tvalid_1's rmse: 0.605133\n",
      "[550]\ttraining's rmse: 0.328341\tvalid_1's rmse: 0.605665\n",
      "[560]\ttraining's rmse: 0.32521\tvalid_1's rmse: 0.605361\n",
      "[570]\ttraining's rmse: 0.321963\tvalid_1's rmse: 0.606134\n",
      "[580]\ttraining's rmse: 0.319054\tvalid_1's rmse: 0.605922\n",
      "[590]\ttraining's rmse: 0.315697\tvalid_1's rmse: 0.606763\n",
      "[600]\ttraining's rmse: 0.312611\tvalid_1's rmse: 0.606498\n",
      "[610]\ttraining's rmse: 0.309737\tvalid_1's rmse: 0.606585\n",
      "[620]\ttraining's rmse: 0.306648\tvalid_1's rmse: 0.607169\n",
      "[630]\ttraining's rmse: 0.303876\tvalid_1's rmse: 0.607148\n",
      "[640]\ttraining's rmse: 0.300928\tvalid_1's rmse: 0.606756\n",
      "[650]\ttraining's rmse: 0.29804\tvalid_1's rmse: 0.60641\n",
      "[660]\ttraining's rmse: 0.295419\tvalid_1's rmse: 0.606357\n",
      "[670]\ttraining's rmse: 0.292725\tvalid_1's rmse: 0.606183\n",
      "[680]\ttraining's rmse: 0.290139\tvalid_1's rmse: 0.606012\n",
      "[690]\ttraining's rmse: 0.287701\tvalid_1's rmse: 0.605605\n",
      "[700]\ttraining's rmse: 0.284995\tvalid_1's rmse: 0.60564\n",
      "[710]\ttraining's rmse: 0.282376\tvalid_1's rmse: 0.605994\n",
      "[720]\ttraining's rmse: 0.279617\tvalid_1's rmse: 0.606367\n",
      "[730]\ttraining's rmse: 0.276944\tvalid_1's rmse: 0.606468\n",
      "[740]\ttraining's rmse: 0.274373\tvalid_1's rmse: 0.60641\n",
      "[750]\ttraining's rmse: 0.271804\tvalid_1's rmse: 0.60635\n",
      "\n",
      "Fold_4 Training\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.8151102699226822e-06, reg_alpha=0.5087856916700971 will be ignored. Current value: lambda_l1=1.8151102699226822e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8410863683391213, subsample=0.5411528279742139 will be ignored. Current value: bagging_fraction=0.8410863683391213\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.017602890537921387, reg_lambda=0.2405984837342317 will be ignored. Current value: lambda_l2=0.017602890537921387\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.8151102699226822e-06, reg_alpha=0.5087856916700971 will be ignored. Current value: lambda_l1=1.8151102699226822e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8410863683391213, subsample=0.5411528279742139 will be ignored. Current value: bagging_fraction=0.8410863683391213\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.017602890537921387, reg_lambda=0.2405984837342317 will be ignored. Current value: lambda_l2=0.017602890537921387\n",
      "[LightGBM] [Info] Total Bins 86903\n",
      "[LightGBM] [Info] Number of data points in the train set: 2224, number of used features: 398\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.8151102699226822e-06, reg_alpha=0.5087856916700971 will be ignored. Current value: lambda_l1=1.8151102699226822e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8410863683391213, subsample=0.5411528279742139 will be ignored. Current value: bagging_fraction=0.8410863683391213\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.017602890537921387, reg_lambda=0.2405984837342317 will be ignored. Current value: lambda_l2=0.017602890537921387\n",
      "[LightGBM] [Info] Start training from score 3.711556\n",
      "[10]\ttraining's rmse: 0.931574\tvalid_1's rmse: 0.92584\n",
      "[20]\ttraining's rmse: 0.854572\tvalid_1's rmse: 0.856079\n",
      "[30]\ttraining's rmse: 0.790843\tvalid_1's rmse: 0.800847\n",
      "[40]\ttraining's rmse: 0.739743\tvalid_1's rmse: 0.758881\n",
      "[50]\ttraining's rmse: 0.697323\tvalid_1's rmse: 0.725309\n",
      "[60]\ttraining's rmse: 0.663395\tvalid_1's rmse: 0.699215\n",
      "[70]\ttraining's rmse: 0.635846\tvalid_1's rmse: 0.678392\n",
      "[80]\ttraining's rmse: 0.611784\tvalid_1's rmse: 0.66261\n",
      "[90]\ttraining's rmse: 0.591992\tvalid_1's rmse: 0.652218\n",
      "[100]\ttraining's rmse: 0.575517\tvalid_1's rmse: 0.643169\n",
      "[110]\ttraining's rmse: 0.561034\tvalid_1's rmse: 0.635551\n",
      "[120]\ttraining's rmse: 0.548769\tvalid_1's rmse: 0.630028\n",
      "[130]\ttraining's rmse: 0.537697\tvalid_1's rmse: 0.62553\n",
      "[140]\ttraining's rmse: 0.527932\tvalid_1's rmse: 0.621758\n",
      "[150]\ttraining's rmse: 0.518756\tvalid_1's rmse: 0.617916\n",
      "[160]\ttraining's rmse: 0.510396\tvalid_1's rmse: 0.616587\n",
      "[170]\ttraining's rmse: 0.502565\tvalid_1's rmse: 0.614311\n",
      "[180]\ttraining's rmse: 0.49507\tvalid_1's rmse: 0.612271\n",
      "[190]\ttraining's rmse: 0.488045\tvalid_1's rmse: 0.610567\n",
      "[200]\ttraining's rmse: 0.481438\tvalid_1's rmse: 0.608945\n",
      "[210]\ttraining's rmse: 0.475019\tvalid_1's rmse: 0.607631\n",
      "[220]\ttraining's rmse: 0.468826\tvalid_1's rmse: 0.607462\n",
      "[230]\ttraining's rmse: 0.462943\tvalid_1's rmse: 0.607481\n",
      "[240]\ttraining's rmse: 0.457321\tvalid_1's rmse: 0.607236\n",
      "[250]\ttraining's rmse: 0.451632\tvalid_1's rmse: 0.606923\n",
      "[260]\ttraining's rmse: 0.446274\tvalid_1's rmse: 0.606258\n",
      "[270]\ttraining's rmse: 0.440998\tvalid_1's rmse: 0.606522\n",
      "[280]\ttraining's rmse: 0.43597\tvalid_1's rmse: 0.606658\n",
      "[290]\ttraining's rmse: 0.430834\tvalid_1's rmse: 0.607613\n",
      "[300]\ttraining's rmse: 0.426086\tvalid_1's rmse: 0.60746\n",
      "[310]\ttraining's rmse: 0.421268\tvalid_1's rmse: 0.607352\n",
      "[320]\ttraining's rmse: 0.416439\tvalid_1's rmse: 0.60758\n",
      "[330]\ttraining's rmse: 0.412016\tvalid_1's rmse: 0.606844\n",
      "[340]\ttraining's rmse: 0.4076\tvalid_1's rmse: 0.6076\n",
      "[350]\ttraining's rmse: 0.403172\tvalid_1's rmse: 0.607235\n",
      "[360]\ttraining's rmse: 0.398834\tvalid_1's rmse: 0.60762\n",
      "[370]\ttraining's rmse: 0.394553\tvalid_1's rmse: 0.608229\n",
      "[380]\ttraining's rmse: 0.390585\tvalid_1's rmse: 0.608418\n",
      "[390]\ttraining's rmse: 0.386443\tvalid_1's rmse: 0.607941\n",
      "[400]\ttraining's rmse: 0.382435\tvalid_1's rmse: 0.608205\n",
      "[410]\ttraining's rmse: 0.378535\tvalid_1's rmse: 0.608419\n",
      "[420]\ttraining's rmse: 0.374363\tvalid_1's rmse: 0.608748\n",
      "[430]\ttraining's rmse: 0.370597\tvalid_1's rmse: 0.609074\n",
      "[440]\ttraining's rmse: 0.366714\tvalid_1's rmse: 0.609136\n",
      "[450]\ttraining's rmse: 0.363047\tvalid_1's rmse: 0.609075\n",
      "[460]\ttraining's rmse: 0.359423\tvalid_1's rmse: 0.608943\n",
      "[470]\ttraining's rmse: 0.355717\tvalid_1's rmse: 0.6085\n",
      "[480]\ttraining's rmse: 0.352269\tvalid_1's rmse: 0.608525\n",
      "[490]\ttraining's rmse: 0.348892\tvalid_1's rmse: 0.608527\n",
      "[500]\ttraining's rmse: 0.345315\tvalid_1's rmse: 0.609026\n",
      "[510]\ttraining's rmse: 0.341982\tvalid_1's rmse: 0.608555\n",
      "[520]\ttraining's rmse: 0.338657\tvalid_1's rmse: 0.608353\n",
      "[530]\ttraining's rmse: 0.335247\tvalid_1's rmse: 0.608493\n",
      "[540]\ttraining's rmse: 0.331876\tvalid_1's rmse: 0.608347\n",
      "[550]\ttraining's rmse: 0.328728\tvalid_1's rmse: 0.608781\n",
      "[560]\ttraining's rmse: 0.325472\tvalid_1's rmse: 0.608522\n",
      "[570]\ttraining's rmse: 0.322301\tvalid_1's rmse: 0.609156\n",
      "[580]\ttraining's rmse: 0.319201\tvalid_1's rmse: 0.609585\n",
      "[590]\ttraining's rmse: 0.316281\tvalid_1's rmse: 0.60991\n",
      "[600]\ttraining's rmse: 0.313165\tvalid_1's rmse: 0.609832\n",
      "[610]\ttraining's rmse: 0.310154\tvalid_1's rmse: 0.609631\n",
      "[620]\ttraining's rmse: 0.307308\tvalid_1's rmse: 0.609888\n",
      "[630]\ttraining's rmse: 0.304287\tvalid_1's rmse: 0.609834\n",
      "[640]\ttraining's rmse: 0.301404\tvalid_1's rmse: 0.609539\n",
      "[650]\ttraining's rmse: 0.298469\tvalid_1's rmse: 0.609672\n",
      "[660]\ttraining's rmse: 0.295582\tvalid_1's rmse: 0.609224\n",
      "\n",
      "Fold_5 Training\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.8151102699226822e-06, reg_alpha=0.5087856916700971 will be ignored. Current value: lambda_l1=1.8151102699226822e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8410863683391213, subsample=0.5411528279742139 will be ignored. Current value: bagging_fraction=0.8410863683391213\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.017602890537921387, reg_lambda=0.2405984837342317 will be ignored. Current value: lambda_l2=0.017602890537921387\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.8151102699226822e-06, reg_alpha=0.5087856916700971 will be ignored. Current value: lambda_l1=1.8151102699226822e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8410863683391213, subsample=0.5411528279742139 will be ignored. Current value: bagging_fraction=0.8410863683391213\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.017602890537921387, reg_lambda=0.2405984837342317 will be ignored. Current value: lambda_l2=0.017602890537921387\n",
      "[LightGBM] [Info] Total Bins 86890\n",
      "[LightGBM] [Info] Number of data points in the train set: 2224, number of used features: 398\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.8151102699226822e-06, reg_alpha=0.5087856916700971 will be ignored. Current value: lambda_l1=1.8151102699226822e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8410863683391213, subsample=0.5411528279742139 will be ignored. Current value: bagging_fraction=0.8410863683391213\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.017602890537921387, reg_lambda=0.2405984837342317 will be ignored. Current value: lambda_l2=0.017602890537921387\n",
      "[LightGBM] [Info] Start training from score 3.712230\n",
      "[10]\ttraining's rmse: 0.931677\tvalid_1's rmse: 0.925313\n",
      "[20]\ttraining's rmse: 0.854592\tvalid_1's rmse: 0.846208\n",
      "[30]\ttraining's rmse: 0.79104\tvalid_1's rmse: 0.785619\n",
      "[40]\ttraining's rmse: 0.739204\tvalid_1's rmse: 0.736907\n",
      "[50]\ttraining's rmse: 0.697561\tvalid_1's rmse: 0.698895\n",
      "[60]\ttraining's rmse: 0.663807\tvalid_1's rmse: 0.667943\n",
      "[70]\ttraining's rmse: 0.635469\tvalid_1's rmse: 0.646948\n",
      "[80]\ttraining's rmse: 0.612583\tvalid_1's rmse: 0.630545\n",
      "[90]\ttraining's rmse: 0.592968\tvalid_1's rmse: 0.617611\n",
      "[100]\ttraining's rmse: 0.576033\tvalid_1's rmse: 0.606697\n",
      "[110]\ttraining's rmse: 0.561959\tvalid_1's rmse: 0.600286\n",
      "[120]\ttraining's rmse: 0.54949\tvalid_1's rmse: 0.594389\n",
      "[130]\ttraining's rmse: 0.538156\tvalid_1's rmse: 0.5898\n",
      "[140]\ttraining's rmse: 0.528214\tvalid_1's rmse: 0.586864\n",
      "[150]\ttraining's rmse: 0.519481\tvalid_1's rmse: 0.584603\n",
      "[160]\ttraining's rmse: 0.511054\tvalid_1's rmse: 0.58253\n",
      "[170]\ttraining's rmse: 0.503084\tvalid_1's rmse: 0.580427\n",
      "[180]\ttraining's rmse: 0.495459\tvalid_1's rmse: 0.579298\n",
      "[190]\ttraining's rmse: 0.48842\tvalid_1's rmse: 0.577574\n",
      "[200]\ttraining's rmse: 0.481491\tvalid_1's rmse: 0.577614\n",
      "[210]\ttraining's rmse: 0.475168\tvalid_1's rmse: 0.576938\n",
      "[220]\ttraining's rmse: 0.468999\tvalid_1's rmse: 0.576827\n",
      "[230]\ttraining's rmse: 0.463251\tvalid_1's rmse: 0.576495\n",
      "[240]\ttraining's rmse: 0.457326\tvalid_1's rmse: 0.576959\n",
      "[250]\ttraining's rmse: 0.451753\tvalid_1's rmse: 0.577217\n",
      "[260]\ttraining's rmse: 0.446518\tvalid_1's rmse: 0.576898\n",
      "[270]\ttraining's rmse: 0.441136\tvalid_1's rmse: 0.576886\n",
      "[280]\ttraining's rmse: 0.436173\tvalid_1's rmse: 0.576849\n",
      "[290]\ttraining's rmse: 0.4312\tvalid_1's rmse: 0.576548\n",
      "[300]\ttraining's rmse: 0.426225\tvalid_1's rmse: 0.576589\n",
      "[310]\ttraining's rmse: 0.421649\tvalid_1's rmse: 0.576712\n",
      "[320]\ttraining's rmse: 0.417137\tvalid_1's rmse: 0.576955\n",
      "[330]\ttraining's rmse: 0.412748\tvalid_1's rmse: 0.57685\n",
      "[340]\ttraining's rmse: 0.408114\tvalid_1's rmse: 0.576444\n",
      "[350]\ttraining's rmse: 0.403792\tvalid_1's rmse: 0.576401\n",
      "[360]\ttraining's rmse: 0.399314\tvalid_1's rmse: 0.57669\n",
      "[370]\ttraining's rmse: 0.395326\tvalid_1's rmse: 0.576795\n",
      "[380]\ttraining's rmse: 0.391107\tvalid_1's rmse: 0.576409\n",
      "[390]\ttraining's rmse: 0.387108\tvalid_1's rmse: 0.576391\n",
      "[400]\ttraining's rmse: 0.383191\tvalid_1's rmse: 0.576738\n",
      "[410]\ttraining's rmse: 0.379339\tvalid_1's rmse: 0.576081\n",
      "[420]\ttraining's rmse: 0.375266\tvalid_1's rmse: 0.575812\n",
      "[430]\ttraining's rmse: 0.371372\tvalid_1's rmse: 0.575718\n",
      "[440]\ttraining's rmse: 0.367841\tvalid_1's rmse: 0.575749\n",
      "[450]\ttraining's rmse: 0.364237\tvalid_1's rmse: 0.575429\n",
      "[460]\ttraining's rmse: 0.360427\tvalid_1's rmse: 0.575407\n",
      "[470]\ttraining's rmse: 0.356841\tvalid_1's rmse: 0.575875\n",
      "[480]\ttraining's rmse: 0.353132\tvalid_1's rmse: 0.575897\n",
      "[490]\ttraining's rmse: 0.349702\tvalid_1's rmse: 0.576066\n",
      "[500]\ttraining's rmse: 0.346279\tvalid_1's rmse: 0.576271\n",
      "[510]\ttraining's rmse: 0.342883\tvalid_1's rmse: 0.57694\n",
      "[520]\ttraining's rmse: 0.339413\tvalid_1's rmse: 0.57657\n",
      "[530]\ttraining's rmse: 0.336113\tvalid_1's rmse: 0.576265\n",
      "[540]\ttraining's rmse: 0.333119\tvalid_1's rmse: 0.576571\n",
      "[550]\ttraining's rmse: 0.329976\tvalid_1's rmse: 0.576497\n",
      "[560]\ttraining's rmse: 0.326656\tvalid_1's rmse: 0.576275\n",
      "[570]\ttraining's rmse: 0.323598\tvalid_1's rmse: 0.57633\n",
      "[580]\ttraining's rmse: 0.320649\tvalid_1's rmse: 0.576402\n",
      "[590]\ttraining's rmse: 0.317565\tvalid_1's rmse: 0.576137\n",
      "[600]\ttraining's rmse: 0.314628\tvalid_1's rmse: 0.576062\n",
      "[610]\ttraining's rmse: 0.311592\tvalid_1's rmse: 0.575721\n",
      "[620]\ttraining's rmse: 0.308665\tvalid_1's rmse: 0.576108\n",
      "[630]\ttraining's rmse: 0.305856\tvalid_1's rmse: 0.576101\n",
      "[640]\ttraining's rmse: 0.302885\tvalid_1's rmse: 0.576375\n",
      "[650]\ttraining's rmse: 0.300121\tvalid_1's rmse: 0.576033\n",
      "[660]\ttraining's rmse: 0.297211\tvalid_1's rmse: 0.575997\n",
      "[670]\ttraining's rmse: 0.294351\tvalid_1's rmse: 0.575863\n",
      "[680]\ttraining's rmse: 0.291686\tvalid_1's rmse: 0.575847\n",
      "[690]\ttraining's rmse: 0.289116\tvalid_1's rmse: 0.575937\n",
      "[700]\ttraining's rmse: 0.286435\tvalid_1's rmse: 0.57582\n",
      "[710]\ttraining's rmse: 0.283553\tvalid_1's rmse: 0.576164\n",
      "[720]\ttraining's rmse: 0.280756\tvalid_1's rmse: 0.576823\n",
      "[730]\ttraining's rmse: 0.27822\tvalid_1's rmse: 0.576909\n",
      "[740]\ttraining's rmse: 0.275621\tvalid_1's rmse: 0.577056\n",
      "[750]\ttraining's rmse: 0.273062\tvalid_1's rmse: 0.577054\n",
      "[760]\ttraining's rmse: 0.27039\tvalid_1's rmse: 0.577471\n",
      "[770]\ttraining's rmse: 0.267908\tvalid_1's rmse: 0.577286\n",
      "[780]\ttraining's rmse: 0.26529\tvalid_1's rmse: 0.57711\n",
      "[790]\ttraining's rmse: 0.262646\tvalid_1's rmse: 0.576871\n",
      "[800]\ttraining's rmse: 0.25998\tvalid_1's rmse: 0.577249\n",
      "[810]\ttraining's rmse: 0.257457\tvalid_1's rmse: 0.577602\n",
      "[820]\ttraining's rmse: 0.255164\tvalid_1's rmse: 0.57752\n",
      "[830]\ttraining's rmse: 0.25284\tvalid_1's rmse: 0.577292\n",
      "[840]\ttraining's rmse: 0.250367\tvalid_1's rmse: 0.577274\n",
      "[850]\ttraining's rmse: 0.248062\tvalid_1's rmse: 0.577229\n",
      "\n",
      "Fold_6 Training\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.8151102699226822e-06, reg_alpha=0.5087856916700971 will be ignored. Current value: lambda_l1=1.8151102699226822e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8410863683391213, subsample=0.5411528279742139 will be ignored. Current value: bagging_fraction=0.8410863683391213\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.017602890537921387, reg_lambda=0.2405984837342317 will be ignored. Current value: lambda_l2=0.017602890537921387\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.8151102699226822e-06, reg_alpha=0.5087856916700971 will be ignored. Current value: lambda_l1=1.8151102699226822e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8410863683391213, subsample=0.5411528279742139 will be ignored. Current value: bagging_fraction=0.8410863683391213\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.017602890537921387, reg_lambda=0.2405984837342317 will be ignored. Current value: lambda_l2=0.017602890537921387\n",
      "[LightGBM] [Info] Total Bins 86874\n",
      "[LightGBM] [Info] Number of data points in the train set: 2224, number of used features: 398\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.8151102699226822e-06, reg_alpha=0.5087856916700971 will be ignored. Current value: lambda_l1=1.8151102699226822e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8410863683391213, subsample=0.5411528279742139 will be ignored. Current value: bagging_fraction=0.8410863683391213\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.017602890537921387, reg_lambda=0.2405984837342317 will be ignored. Current value: lambda_l2=0.017602890537921387\n",
      "[LightGBM] [Info] Start training from score 3.711331\n",
      "[10]\ttraining's rmse: 0.931856\tvalid_1's rmse: 0.92308\n",
      "[20]\ttraining's rmse: 0.854656\tvalid_1's rmse: 0.847907\n",
      "[30]\ttraining's rmse: 0.791962\tvalid_1's rmse: 0.78847\n",
      "[40]\ttraining's rmse: 0.740557\tvalid_1's rmse: 0.740543\n",
      "[50]\ttraining's rmse: 0.698729\tvalid_1's rmse: 0.704159\n",
      "[60]\ttraining's rmse: 0.66468\tvalid_1's rmse: 0.675239\n",
      "[70]\ttraining's rmse: 0.636368\tvalid_1's rmse: 0.654079\n",
      "[80]\ttraining's rmse: 0.61289\tvalid_1's rmse: 0.637435\n",
      "[90]\ttraining's rmse: 0.593187\tvalid_1's rmse: 0.624756\n",
      "[100]\ttraining's rmse: 0.576128\tvalid_1's rmse: 0.615396\n",
      "[110]\ttraining's rmse: 0.561621\tvalid_1's rmse: 0.60827\n",
      "[120]\ttraining's rmse: 0.54906\tvalid_1's rmse: 0.602833\n",
      "[130]\ttraining's rmse: 0.537722\tvalid_1's rmse: 0.599133\n",
      "[140]\ttraining's rmse: 0.527708\tvalid_1's rmse: 0.59609\n",
      "[150]\ttraining's rmse: 0.518285\tvalid_1's rmse: 0.594567\n",
      "[160]\ttraining's rmse: 0.509491\tvalid_1's rmse: 0.593326\n",
      "[170]\ttraining's rmse: 0.501551\tvalid_1's rmse: 0.593543\n",
      "[180]\ttraining's rmse: 0.493734\tvalid_1's rmse: 0.592701\n",
      "[190]\ttraining's rmse: 0.486544\tvalid_1's rmse: 0.592311\n",
      "[200]\ttraining's rmse: 0.479797\tvalid_1's rmse: 0.591626\n",
      "[210]\ttraining's rmse: 0.473353\tvalid_1's rmse: 0.591051\n",
      "[220]\ttraining's rmse: 0.467085\tvalid_1's rmse: 0.59136\n",
      "[230]\ttraining's rmse: 0.460966\tvalid_1's rmse: 0.590917\n",
      "[240]\ttraining's rmse: 0.455508\tvalid_1's rmse: 0.591914\n",
      "[250]\ttraining's rmse: 0.449876\tvalid_1's rmse: 0.593022\n",
      "[260]\ttraining's rmse: 0.444417\tvalid_1's rmse: 0.593826\n",
      "[270]\ttraining's rmse: 0.438854\tvalid_1's rmse: 0.594267\n",
      "[280]\ttraining's rmse: 0.433876\tvalid_1's rmse: 0.595549\n",
      "[290]\ttraining's rmse: 0.428772\tvalid_1's rmse: 0.59626\n",
      "[300]\ttraining's rmse: 0.423972\tvalid_1's rmse: 0.597149\n",
      "[310]\ttraining's rmse: 0.418883\tvalid_1's rmse: 0.597061\n",
      "[320]\ttraining's rmse: 0.414089\tvalid_1's rmse: 0.597596\n",
      "[330]\ttraining's rmse: 0.409607\tvalid_1's rmse: 0.598611\n",
      "[340]\ttraining's rmse: 0.405282\tvalid_1's rmse: 0.598652\n",
      "[350]\ttraining's rmse: 0.401118\tvalid_1's rmse: 0.599271\n",
      "[360]\ttraining's rmse: 0.396748\tvalid_1's rmse: 0.600192\n",
      "[370]\ttraining's rmse: 0.392381\tvalid_1's rmse: 0.600028\n",
      "[380]\ttraining's rmse: 0.388296\tvalid_1's rmse: 0.600396\n",
      "[390]\ttraining's rmse: 0.3842\tvalid_1's rmse: 0.600879\n",
      "[400]\ttraining's rmse: 0.380117\tvalid_1's rmse: 0.601394\n",
      "[410]\ttraining's rmse: 0.376381\tvalid_1's rmse: 0.601557\n",
      "[420]\ttraining's rmse: 0.372508\tvalid_1's rmse: 0.60161\n",
      "[430]\ttraining's rmse: 0.368727\tvalid_1's rmse: 0.601239\n",
      "[440]\ttraining's rmse: 0.364968\tvalid_1's rmse: 0.601195\n",
      "[450]\ttraining's rmse: 0.361375\tvalid_1's rmse: 0.60098\n",
      "[460]\ttraining's rmse: 0.357584\tvalid_1's rmse: 0.601509\n",
      "[470]\ttraining's rmse: 0.35417\tvalid_1's rmse: 0.602214\n",
      "[480]\ttraining's rmse: 0.350611\tvalid_1's rmse: 0.60175\n",
      "[490]\ttraining's rmse: 0.347131\tvalid_1's rmse: 0.601788\n",
      "[500]\ttraining's rmse: 0.343537\tvalid_1's rmse: 0.601499\n",
      "[510]\ttraining's rmse: 0.340031\tvalid_1's rmse: 0.601749\n",
      "[520]\ttraining's rmse: 0.336459\tvalid_1's rmse: 0.601916\n",
      "[530]\ttraining's rmse: 0.333195\tvalid_1's rmse: 0.601731\n",
      "[540]\ttraining's rmse: 0.329794\tvalid_1's rmse: 0.602322\n",
      "[550]\ttraining's rmse: 0.326467\tvalid_1's rmse: 0.602365\n",
      "[560]\ttraining's rmse: 0.323531\tvalid_1's rmse: 0.601968\n",
      "[570]\ttraining's rmse: 0.320687\tvalid_1's rmse: 0.602066\n",
      "[580]\ttraining's rmse: 0.31758\tvalid_1's rmse: 0.602337\n",
      "[590]\ttraining's rmse: 0.31457\tvalid_1's rmse: 0.603038\n",
      "[600]\ttraining's rmse: 0.311475\tvalid_1's rmse: 0.603267\n",
      "[610]\ttraining's rmse: 0.308538\tvalid_1's rmse: 0.60398\n",
      "[620]\ttraining's rmse: 0.305758\tvalid_1's rmse: 0.603458\n",
      "\n",
      "Fold_7 Training\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.8151102699226822e-06, reg_alpha=0.5087856916700971 will be ignored. Current value: lambda_l1=1.8151102699226822e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8410863683391213, subsample=0.5411528279742139 will be ignored. Current value: bagging_fraction=0.8410863683391213\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.017602890537921387, reg_lambda=0.2405984837342317 will be ignored. Current value: lambda_l2=0.017602890537921387\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.8151102699226822e-06, reg_alpha=0.5087856916700971 will be ignored. Current value: lambda_l1=1.8151102699226822e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8410863683391213, subsample=0.5411528279742139 will be ignored. Current value: bagging_fraction=0.8410863683391213\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.017602890537921387, reg_lambda=0.2405984837342317 will be ignored. Current value: lambda_l2=0.017602890537921387\n",
      "[LightGBM] [Info] Total Bins 86918\n",
      "[LightGBM] [Info] Number of data points in the train set: 2224, number of used features: 398\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.8151102699226822e-06, reg_alpha=0.5087856916700971 will be ignored. Current value: lambda_l1=1.8151102699226822e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8410863683391213, subsample=0.5411528279742139 will be ignored. Current value: bagging_fraction=0.8410863683391213\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.017602890537921387, reg_lambda=0.2405984837342317 will be ignored. Current value: lambda_l2=0.017602890537921387\n",
      "[LightGBM] [Info] Start training from score 3.710207\n",
      "[10]\ttraining's rmse: 0.929425\tvalid_1's rmse: 0.945166\n",
      "[20]\ttraining's rmse: 0.851685\tvalid_1's rmse: 0.874304\n",
      "[30]\ttraining's rmse: 0.788761\tvalid_1's rmse: 0.818517\n",
      "[40]\ttraining's rmse: 0.737695\tvalid_1's rmse: 0.774456\n",
      "[50]\ttraining's rmse: 0.695924\tvalid_1's rmse: 0.741793\n",
      "[60]\ttraining's rmse: 0.662047\tvalid_1's rmse: 0.714865\n",
      "[70]\ttraining's rmse: 0.633656\tvalid_1's rmse: 0.69274\n",
      "[80]\ttraining's rmse: 0.610536\tvalid_1's rmse: 0.675701\n",
      "[90]\ttraining's rmse: 0.590782\tvalid_1's rmse: 0.661388\n",
      "[100]\ttraining's rmse: 0.574341\tvalid_1's rmse: 0.651323\n",
      "[110]\ttraining's rmse: 0.559897\tvalid_1's rmse: 0.643332\n",
      "[120]\ttraining's rmse: 0.547688\tvalid_1's rmse: 0.637671\n",
      "[130]\ttraining's rmse: 0.536608\tvalid_1's rmse: 0.633314\n",
      "[140]\ttraining's rmse: 0.526793\tvalid_1's rmse: 0.630133\n",
      "[150]\ttraining's rmse: 0.517746\tvalid_1's rmse: 0.627276\n",
      "[160]\ttraining's rmse: 0.509101\tvalid_1's rmse: 0.623985\n",
      "[170]\ttraining's rmse: 0.501383\tvalid_1's rmse: 0.62205\n",
      "[180]\ttraining's rmse: 0.493993\tvalid_1's rmse: 0.619645\n",
      "[190]\ttraining's rmse: 0.487163\tvalid_1's rmse: 0.619315\n",
      "[200]\ttraining's rmse: 0.480268\tvalid_1's rmse: 0.616968\n",
      "[210]\ttraining's rmse: 0.474102\tvalid_1's rmse: 0.615173\n",
      "[220]\ttraining's rmse: 0.467996\tvalid_1's rmse: 0.614027\n",
      "[230]\ttraining's rmse: 0.46223\tvalid_1's rmse: 0.61421\n",
      "[240]\ttraining's rmse: 0.456607\tvalid_1's rmse: 0.613504\n",
      "[250]\ttraining's rmse: 0.451172\tvalid_1's rmse: 0.612051\n",
      "[260]\ttraining's rmse: 0.445718\tvalid_1's rmse: 0.610566\n",
      "[270]\ttraining's rmse: 0.440637\tvalid_1's rmse: 0.610218\n",
      "[280]\ttraining's rmse: 0.435372\tvalid_1's rmse: 0.611186\n",
      "[290]\ttraining's rmse: 0.430628\tvalid_1's rmse: 0.609931\n",
      "[300]\ttraining's rmse: 0.4261\tvalid_1's rmse: 0.610025\n",
      "[310]\ttraining's rmse: 0.421296\tvalid_1's rmse: 0.609423\n",
      "[320]\ttraining's rmse: 0.416423\tvalid_1's rmse: 0.608613\n",
      "[330]\ttraining's rmse: 0.41184\tvalid_1's rmse: 0.609147\n",
      "[340]\ttraining's rmse: 0.407645\tvalid_1's rmse: 0.609038\n",
      "[350]\ttraining's rmse: 0.403485\tvalid_1's rmse: 0.608348\n",
      "[360]\ttraining's rmse: 0.399414\tvalid_1's rmse: 0.608538\n",
      "[370]\ttraining's rmse: 0.395339\tvalid_1's rmse: 0.608021\n",
      "[380]\ttraining's rmse: 0.391011\tvalid_1's rmse: 0.606863\n",
      "[390]\ttraining's rmse: 0.387317\tvalid_1's rmse: 0.606045\n",
      "[400]\ttraining's rmse: 0.383179\tvalid_1's rmse: 0.605464\n",
      "[410]\ttraining's rmse: 0.379568\tvalid_1's rmse: 0.604927\n",
      "[420]\ttraining's rmse: 0.375832\tvalid_1's rmse: 0.60467\n",
      "[430]\ttraining's rmse: 0.371966\tvalid_1's rmse: 0.604028\n",
      "[440]\ttraining's rmse: 0.368199\tvalid_1's rmse: 0.604188\n",
      "[450]\ttraining's rmse: 0.364575\tvalid_1's rmse: 0.604688\n",
      "[460]\ttraining's rmse: 0.361079\tvalid_1's rmse: 0.605087\n",
      "[470]\ttraining's rmse: 0.357527\tvalid_1's rmse: 0.604887\n",
      "[480]\ttraining's rmse: 0.353938\tvalid_1's rmse: 0.604632\n",
      "[490]\ttraining's rmse: 0.350541\tvalid_1's rmse: 0.604853\n",
      "[500]\ttraining's rmse: 0.347224\tvalid_1's rmse: 0.604709\n",
      "[510]\ttraining's rmse: 0.343766\tvalid_1's rmse: 0.604686\n",
      "[520]\ttraining's rmse: 0.340418\tvalid_1's rmse: 0.604932\n",
      "[530]\ttraining's rmse: 0.337059\tvalid_1's rmse: 0.605223\n",
      "[540]\ttraining's rmse: 0.333881\tvalid_1's rmse: 0.604681\n",
      "[550]\ttraining's rmse: 0.330632\tvalid_1's rmse: 0.605108\n",
      "[560]\ttraining's rmse: 0.327537\tvalid_1's rmse: 0.604908\n",
      "[570]\ttraining's rmse: 0.324378\tvalid_1's rmse: 0.604275\n",
      "[580]\ttraining's rmse: 0.321437\tvalid_1's rmse: 0.603592\n",
      "[590]\ttraining's rmse: 0.318505\tvalid_1's rmse: 0.604038\n",
      "[600]\ttraining's rmse: 0.315326\tvalid_1's rmse: 0.6038\n",
      "[610]\ttraining's rmse: 0.31247\tvalid_1's rmse: 0.604047\n",
      "[620]\ttraining's rmse: 0.309485\tvalid_1's rmse: 0.604319\n",
      "[630]\ttraining's rmse: 0.306628\tvalid_1's rmse: 0.604296\n",
      "[640]\ttraining's rmse: 0.303605\tvalid_1's rmse: 0.603941\n",
      "[650]\ttraining's rmse: 0.300812\tvalid_1's rmse: 0.603678\n",
      "[660]\ttraining's rmse: 0.298127\tvalid_1's rmse: 0.603449\n",
      "[670]\ttraining's rmse: 0.295404\tvalid_1's rmse: 0.603308\n",
      "[680]\ttraining's rmse: 0.292666\tvalid_1's rmse: 0.603244\n",
      "[690]\ttraining's rmse: 0.290111\tvalid_1's rmse: 0.603209\n",
      "[700]\ttraining's rmse: 0.287317\tvalid_1's rmse: 0.603215\n",
      "[710]\ttraining's rmse: 0.284417\tvalid_1's rmse: 0.603312\n",
      "[720]\ttraining's rmse: 0.281772\tvalid_1's rmse: 0.603381\n",
      "[730]\ttraining's rmse: 0.279193\tvalid_1's rmse: 0.603161\n",
      "[740]\ttraining's rmse: 0.276792\tvalid_1's rmse: 0.602597\n",
      "[750]\ttraining's rmse: 0.274082\tvalid_1's rmse: 0.602578\n",
      "[760]\ttraining's rmse: 0.271606\tvalid_1's rmse: 0.602713\n",
      "[770]\ttraining's rmse: 0.269227\tvalid_1's rmse: 0.602105\n",
      "[780]\ttraining's rmse: 0.266756\tvalid_1's rmse: 0.60148\n",
      "[790]\ttraining's rmse: 0.264201\tvalid_1's rmse: 0.600951\n",
      "[800]\ttraining's rmse: 0.261684\tvalid_1's rmse: 0.601377\n",
      "[810]\ttraining's rmse: 0.259112\tvalid_1's rmse: 0.60105\n",
      "[820]\ttraining's rmse: 0.256725\tvalid_1's rmse: 0.601321\n",
      "[830]\ttraining's rmse: 0.254365\tvalid_1's rmse: 0.601167\n",
      "[840]\ttraining's rmse: 0.251957\tvalid_1's rmse: 0.601615\n",
      "[850]\ttraining's rmse: 0.249619\tvalid_1's rmse: 0.601414\n",
      "[860]\ttraining's rmse: 0.247423\tvalid_1's rmse: 0.601273\n",
      "[870]\ttraining's rmse: 0.245191\tvalid_1's rmse: 0.601086\n",
      "[880]\ttraining's rmse: 0.243039\tvalid_1's rmse: 0.600615\n",
      "[890]\ttraining's rmse: 0.240997\tvalid_1's rmse: 0.600421\n",
      "[900]\ttraining's rmse: 0.23882\tvalid_1's rmse: 0.599924\n",
      "[910]\ttraining's rmse: 0.236595\tvalid_1's rmse: 0.600168\n",
      "[920]\ttraining's rmse: 0.234398\tvalid_1's rmse: 0.599817\n",
      "[930]\ttraining's rmse: 0.232239\tvalid_1's rmse: 0.599825\n",
      "[940]\ttraining's rmse: 0.230118\tvalid_1's rmse: 0.600081\n",
      "[950]\ttraining's rmse: 0.227997\tvalid_1's rmse: 0.599955\n",
      "[960]\ttraining's rmse: 0.226145\tvalid_1's rmse: 0.599993\n",
      "[970]\ttraining's rmse: 0.224282\tvalid_1's rmse: 0.599907\n",
      "[980]\ttraining's rmse: 0.22216\tvalid_1's rmse: 0.599854\n",
      "[990]\ttraining's rmse: 0.22011\tvalid_1's rmse: 0.599847\n",
      "[1000]\ttraining's rmse: 0.21805\tvalid_1's rmse: 0.600294\n",
      "[1010]\ttraining's rmse: 0.216119\tvalid_1's rmse: 0.59985\n",
      "[1020]\ttraining's rmse: 0.214134\tvalid_1's rmse: 0.600121\n",
      "\n",
      "Fold_8 Training\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.8151102699226822e-06, reg_alpha=0.5087856916700971 will be ignored. Current value: lambda_l1=1.8151102699226822e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8410863683391213, subsample=0.5411528279742139 will be ignored. Current value: bagging_fraction=0.8410863683391213\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.017602890537921387, reg_lambda=0.2405984837342317 will be ignored. Current value: lambda_l2=0.017602890537921387\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.8151102699226822e-06, reg_alpha=0.5087856916700971 will be ignored. Current value: lambda_l1=1.8151102699226822e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8410863683391213, subsample=0.5411528279742139 will be ignored. Current value: bagging_fraction=0.8410863683391213\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.017602890537921387, reg_lambda=0.2405984837342317 will be ignored. Current value: lambda_l2=0.017602890537921387\n",
      "[LightGBM] [Info] Total Bins 86887\n",
      "[LightGBM] [Info] Number of data points in the train set: 2224, number of used features: 398\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.8151102699226822e-06, reg_alpha=0.5087856916700971 will be ignored. Current value: lambda_l1=1.8151102699226822e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8410863683391213, subsample=0.5411528279742139 will be ignored. Current value: bagging_fraction=0.8410863683391213\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.017602890537921387, reg_lambda=0.2405984837342317 will be ignored. Current value: lambda_l2=0.017602890537921387\n",
      "[LightGBM] [Info] Start training from score 3.710207\n",
      "[10]\ttraining's rmse: 0.928248\tvalid_1's rmse: 0.944777\n",
      "[20]\ttraining's rmse: 0.850389\tvalid_1's rmse: 0.874814\n",
      "[30]\ttraining's rmse: 0.787691\tvalid_1's rmse: 0.819653\n",
      "[40]\ttraining's rmse: 0.736828\tvalid_1's rmse: 0.776724\n",
      "[50]\ttraining's rmse: 0.694715\tvalid_1's rmse: 0.743475\n",
      "[60]\ttraining's rmse: 0.660532\tvalid_1's rmse: 0.716689\n",
      "[70]\ttraining's rmse: 0.632781\tvalid_1's rmse: 0.69692\n",
      "[80]\ttraining's rmse: 0.609093\tvalid_1's rmse: 0.68049\n",
      "[90]\ttraining's rmse: 0.589641\tvalid_1's rmse: 0.666525\n",
      "[100]\ttraining's rmse: 0.573098\tvalid_1's rmse: 0.657579\n",
      "[110]\ttraining's rmse: 0.558504\tvalid_1's rmse: 0.650379\n",
      "[120]\ttraining's rmse: 0.545824\tvalid_1's rmse: 0.642887\n",
      "[130]\ttraining's rmse: 0.53538\tvalid_1's rmse: 0.638803\n",
      "[140]\ttraining's rmse: 0.525763\tvalid_1's rmse: 0.634831\n",
      "[150]\ttraining's rmse: 0.516876\tvalid_1's rmse: 0.632167\n",
      "[160]\ttraining's rmse: 0.508452\tvalid_1's rmse: 0.628981\n",
      "[170]\ttraining's rmse: 0.500669\tvalid_1's rmse: 0.626374\n",
      "[180]\ttraining's rmse: 0.493256\tvalid_1's rmse: 0.624212\n",
      "[190]\ttraining's rmse: 0.486324\tvalid_1's rmse: 0.622263\n",
      "[200]\ttraining's rmse: 0.479434\tvalid_1's rmse: 0.620835\n",
      "[210]\ttraining's rmse: 0.472855\tvalid_1's rmse: 0.620041\n",
      "[220]\ttraining's rmse: 0.466773\tvalid_1's rmse: 0.620124\n",
      "[230]\ttraining's rmse: 0.460948\tvalid_1's rmse: 0.619656\n",
      "[240]\ttraining's rmse: 0.454961\tvalid_1's rmse: 0.618269\n",
      "[250]\ttraining's rmse: 0.449405\tvalid_1's rmse: 0.617656\n",
      "[260]\ttraining's rmse: 0.444159\tvalid_1's rmse: 0.617039\n",
      "[270]\ttraining's rmse: 0.439002\tvalid_1's rmse: 0.617007\n",
      "[280]\ttraining's rmse: 0.433869\tvalid_1's rmse: 0.617089\n",
      "[290]\ttraining's rmse: 0.428814\tvalid_1's rmse: 0.6174\n",
      "[300]\ttraining's rmse: 0.423715\tvalid_1's rmse: 0.617139\n",
      "[310]\ttraining's rmse: 0.418853\tvalid_1's rmse: 0.617228\n",
      "[320]\ttraining's rmse: 0.414249\tvalid_1's rmse: 0.616889\n",
      "[330]\ttraining's rmse: 0.409401\tvalid_1's rmse: 0.617632\n",
      "[340]\ttraining's rmse: 0.404702\tvalid_1's rmse: 0.618255\n",
      "[350]\ttraining's rmse: 0.400625\tvalid_1's rmse: 0.617782\n",
      "[360]\ttraining's rmse: 0.396578\tvalid_1's rmse: 0.617695\n",
      "[370]\ttraining's rmse: 0.392454\tvalid_1's rmse: 0.617166\n",
      "[380]\ttraining's rmse: 0.388311\tvalid_1's rmse: 0.617001\n",
      "[390]\ttraining's rmse: 0.384314\tvalid_1's rmse: 0.616982\n",
      "[400]\ttraining's rmse: 0.38022\tvalid_1's rmse: 0.616657\n",
      "[410]\ttraining's rmse: 0.376409\tvalid_1's rmse: 0.616917\n",
      "[420]\ttraining's rmse: 0.372425\tvalid_1's rmse: 0.617054\n",
      "[430]\ttraining's rmse: 0.368572\tvalid_1's rmse: 0.617021\n",
      "[440]\ttraining's rmse: 0.36504\tvalid_1's rmse: 0.616635\n",
      "[450]\ttraining's rmse: 0.361593\tvalid_1's rmse: 0.615973\n",
      "[460]\ttraining's rmse: 0.357952\tvalid_1's rmse: 0.616158\n",
      "[470]\ttraining's rmse: 0.354113\tvalid_1's rmse: 0.615535\n",
      "[480]\ttraining's rmse: 0.350613\tvalid_1's rmse: 0.615568\n",
      "[490]\ttraining's rmse: 0.347199\tvalid_1's rmse: 0.614672\n",
      "[500]\ttraining's rmse: 0.34392\tvalid_1's rmse: 0.614319\n",
      "[510]\ttraining's rmse: 0.340405\tvalid_1's rmse: 0.61457\n",
      "[520]\ttraining's rmse: 0.336947\tvalid_1's rmse: 0.614545\n",
      "[530]\ttraining's rmse: 0.333632\tvalid_1's rmse: 0.614678\n",
      "[540]\ttraining's rmse: 0.330406\tvalid_1's rmse: 0.614495\n",
      "[550]\ttraining's rmse: 0.327348\tvalid_1's rmse: 0.614418\n",
      "[560]\ttraining's rmse: 0.324261\tvalid_1's rmse: 0.614285\n",
      "[570]\ttraining's rmse: 0.321187\tvalid_1's rmse: 0.613837\n",
      "[580]\ttraining's rmse: 0.318152\tvalid_1's rmse: 0.613665\n",
      "[590]\ttraining's rmse: 0.315156\tvalid_1's rmse: 0.613797\n",
      "[600]\ttraining's rmse: 0.312068\tvalid_1's rmse: 0.613888\n",
      "[610]\ttraining's rmse: 0.309194\tvalid_1's rmse: 0.613686\n",
      "[620]\ttraining's rmse: 0.306244\tvalid_1's rmse: 0.613662\n",
      "[630]\ttraining's rmse: 0.30319\tvalid_1's rmse: 0.613627\n",
      "[640]\ttraining's rmse: 0.300251\tvalid_1's rmse: 0.613257\n",
      "[650]\ttraining's rmse: 0.297291\tvalid_1's rmse: 0.613092\n",
      "[660]\ttraining's rmse: 0.294536\tvalid_1's rmse: 0.613386\n",
      "[670]\ttraining's rmse: 0.291732\tvalid_1's rmse: 0.612916\n",
      "[680]\ttraining's rmse: 0.289148\tvalid_1's rmse: 0.613023\n",
      "[690]\ttraining's rmse: 0.286511\tvalid_1's rmse: 0.612714\n",
      "[700]\ttraining's rmse: 0.283925\tvalid_1's rmse: 0.613078\n",
      "[710]\ttraining's rmse: 0.281207\tvalid_1's rmse: 0.612856\n",
      "[720]\ttraining's rmse: 0.278397\tvalid_1's rmse: 0.612411\n",
      "[730]\ttraining's rmse: 0.275731\tvalid_1's rmse: 0.612413\n",
      "[740]\ttraining's rmse: 0.273016\tvalid_1's rmse: 0.612907\n",
      "[750]\ttraining's rmse: 0.270355\tvalid_1's rmse: 0.612931\n",
      "[760]\ttraining's rmse: 0.267655\tvalid_1's rmse: 0.613211\n",
      "[770]\ttraining's rmse: 0.265038\tvalid_1's rmse: 0.613347\n",
      "[780]\ttraining's rmse: 0.262501\tvalid_1's rmse: 0.613664\n",
      "[790]\ttraining's rmse: 0.259995\tvalid_1's rmse: 0.613671\n",
      "[800]\ttraining's rmse: 0.257433\tvalid_1's rmse: 0.61371\n",
      "[810]\ttraining's rmse: 0.255007\tvalid_1's rmse: 0.613413\n",
      "[820]\ttraining's rmse: 0.252574\tvalid_1's rmse: 0.613394\n",
      "[830]\ttraining's rmse: 0.250078\tvalid_1's rmse: 0.614008\n",
      "[840]\ttraining's rmse: 0.247798\tvalid_1's rmse: 0.614061\n",
      "[850]\ttraining's rmse: 0.245506\tvalid_1's rmse: 0.614451\n",
      "[860]\ttraining's rmse: 0.243493\tvalid_1's rmse: 0.614768\n",
      "[870]\ttraining's rmse: 0.241083\tvalid_1's rmse: 0.61463\n",
      "[880]\ttraining's rmse: 0.238731\tvalid_1's rmse: 0.614771\n",
      "[890]\ttraining's rmse: 0.236465\tvalid_1's rmse: 0.614557\n",
      "[900]\ttraining's rmse: 0.234246\tvalid_1's rmse: 0.614834\n",
      "[910]\ttraining's rmse: 0.232\tvalid_1's rmse: 0.614831\n",
      "[920]\ttraining's rmse: 0.229765\tvalid_1's rmse: 0.615019\n",
      "[930]\ttraining's rmse: 0.22789\tvalid_1's rmse: 0.61497\n",
      "[940]\ttraining's rmse: 0.225798\tvalid_1's rmse: 0.61485\n",
      "[950]\ttraining's rmse: 0.223652\tvalid_1's rmse: 0.615497\n",
      "[960]\ttraining's rmse: 0.221583\tvalid_1's rmse: 0.614903\n",
      "[970]\ttraining's rmse: 0.21951\tvalid_1's rmse: 0.614863\n",
      "[980]\ttraining's rmse: 0.217484\tvalid_1's rmse: 0.615186\n",
      "[990]\ttraining's rmse: 0.215504\tvalid_1's rmse: 0.615437\n",
      "[1000]\ttraining's rmse: 0.213672\tvalid_1's rmse: 0.615861\n",
      "[1010]\ttraining's rmse: 0.21154\tvalid_1's rmse: 0.615912\n",
      "[1020]\ttraining's rmse: 0.209718\tvalid_1's rmse: 0.615731\n",
      "\n",
      "Fold_9 Training\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.8151102699226822e-06, reg_alpha=0.5087856916700971 will be ignored. Current value: lambda_l1=1.8151102699226822e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8410863683391213, subsample=0.5411528279742139 will be ignored. Current value: bagging_fraction=0.8410863683391213\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.017602890537921387, reg_lambda=0.2405984837342317 will be ignored. Current value: lambda_l2=0.017602890537921387\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.8151102699226822e-06, reg_alpha=0.5087856916700971 will be ignored. Current value: lambda_l1=1.8151102699226822e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8410863683391213, subsample=0.5411528279742139 will be ignored. Current value: bagging_fraction=0.8410863683391213\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.017602890537921387, reg_lambda=0.2405984837342317 will be ignored. Current value: lambda_l2=0.017602890537921387\n",
      "[LightGBM] [Info] Total Bins 86874\n",
      "[LightGBM] [Info] Number of data points in the train set: 2224, number of used features: 398\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.8151102699226822e-06, reg_alpha=0.5087856916700971 will be ignored. Current value: lambda_l1=1.8151102699226822e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8410863683391213, subsample=0.5411528279742139 will be ignored. Current value: bagging_fraction=0.8410863683391213\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.017602890537921387, reg_lambda=0.2405984837342317 will be ignored. Current value: lambda_l2=0.017602890537921387\n",
      "[LightGBM] [Info] Start training from score 3.712005\n",
      "[10]\ttraining's rmse: 0.928164\tvalid_1's rmse: 0.9459\n",
      "[20]\ttraining's rmse: 0.850494\tvalid_1's rmse: 0.877071\n",
      "[30]\ttraining's rmse: 0.78672\tvalid_1's rmse: 0.822123\n",
      "[40]\ttraining's rmse: 0.734768\tvalid_1's rmse: 0.779476\n",
      "[50]\ttraining's rmse: 0.693329\tvalid_1's rmse: 0.746548\n",
      "[60]\ttraining's rmse: 0.659619\tvalid_1's rmse: 0.722632\n",
      "[70]\ttraining's rmse: 0.6317\tvalid_1's rmse: 0.702804\n",
      "[80]\ttraining's rmse: 0.608499\tvalid_1's rmse: 0.687343\n",
      "[90]\ttraining's rmse: 0.589061\tvalid_1's rmse: 0.674885\n",
      "[100]\ttraining's rmse: 0.572589\tvalid_1's rmse: 0.666045\n",
      "[110]\ttraining's rmse: 0.558084\tvalid_1's rmse: 0.659153\n",
      "[120]\ttraining's rmse: 0.54584\tvalid_1's rmse: 0.653531\n",
      "[130]\ttraining's rmse: 0.534622\tvalid_1's rmse: 0.64989\n",
      "[140]\ttraining's rmse: 0.52472\tvalid_1's rmse: 0.646082\n",
      "[150]\ttraining's rmse: 0.515883\tvalid_1's rmse: 0.643851\n",
      "[160]\ttraining's rmse: 0.507478\tvalid_1's rmse: 0.642736\n",
      "[170]\ttraining's rmse: 0.499864\tvalid_1's rmse: 0.641556\n",
      "[180]\ttraining's rmse: 0.492328\tvalid_1's rmse: 0.640283\n",
      "[190]\ttraining's rmse: 0.485433\tvalid_1's rmse: 0.639232\n",
      "[200]\ttraining's rmse: 0.478964\tvalid_1's rmse: 0.638488\n",
      "[210]\ttraining's rmse: 0.472541\tvalid_1's rmse: 0.639066\n",
      "[220]\ttraining's rmse: 0.466452\tvalid_1's rmse: 0.638303\n",
      "[230]\ttraining's rmse: 0.461018\tvalid_1's rmse: 0.637717\n",
      "[240]\ttraining's rmse: 0.455517\tvalid_1's rmse: 0.637689\n",
      "[250]\ttraining's rmse: 0.450173\tvalid_1's rmse: 0.638126\n",
      "[260]\ttraining's rmse: 0.445138\tvalid_1's rmse: 0.638156\n",
      "[270]\ttraining's rmse: 0.439896\tvalid_1's rmse: 0.638656\n",
      "[280]\ttraining's rmse: 0.434868\tvalid_1's rmse: 0.639291\n",
      "[290]\ttraining's rmse: 0.429991\tvalid_1's rmse: 0.639425\n",
      "[300]\ttraining's rmse: 0.424955\tvalid_1's rmse: 0.639491\n",
      "[310]\ttraining's rmse: 0.420315\tvalid_1's rmse: 0.639854\n",
      "[320]\ttraining's rmse: 0.415891\tvalid_1's rmse: 0.640542\n",
      "[330]\ttraining's rmse: 0.411359\tvalid_1's rmse: 0.639958\n",
      "[340]\ttraining's rmse: 0.406949\tvalid_1's rmse: 0.639216\n",
      "[350]\ttraining's rmse: 0.402586\tvalid_1's rmse: 0.638736\n",
      "[360]\ttraining's rmse: 0.398443\tvalid_1's rmse: 0.638581\n",
      "[370]\ttraining's rmse: 0.394254\tvalid_1's rmse: 0.638643\n",
      "[380]\ttraining's rmse: 0.390144\tvalid_1's rmse: 0.638676\n",
      "[390]\ttraining's rmse: 0.386322\tvalid_1's rmse: 0.638287\n",
      "[400]\ttraining's rmse: 0.382505\tvalid_1's rmse: 0.639495\n",
      "[410]\ttraining's rmse: 0.378744\tvalid_1's rmse: 0.639153\n",
      "[420]\ttraining's rmse: 0.3748\tvalid_1's rmse: 0.63903\n",
      "[430]\ttraining's rmse: 0.370888\tvalid_1's rmse: 0.638339\n",
      "[440]\ttraining's rmse: 0.367149\tvalid_1's rmse: 0.638088\n",
      "[450]\ttraining's rmse: 0.363515\tvalid_1's rmse: 0.638057\n",
      "[460]\ttraining's rmse: 0.360009\tvalid_1's rmse: 0.638062\n",
      "[470]\ttraining's rmse: 0.356556\tvalid_1's rmse: 0.637754\n",
      "[480]\ttraining's rmse: 0.353067\tvalid_1's rmse: 0.638015\n",
      "[490]\ttraining's rmse: 0.349573\tvalid_1's rmse: 0.63779\n",
      "[500]\ttraining's rmse: 0.345942\tvalid_1's rmse: 0.638033\n",
      "[510]\ttraining's rmse: 0.342493\tvalid_1's rmse: 0.637695\n",
      "[520]\ttraining's rmse: 0.33909\tvalid_1's rmse: 0.637274\n",
      "[530]\ttraining's rmse: 0.335799\tvalid_1's rmse: 0.637355\n",
      "[540]\ttraining's rmse: 0.332525\tvalid_1's rmse: 0.637935\n",
      "[550]\ttraining's rmse: 0.329237\tvalid_1's rmse: 0.637883\n",
      "[560]\ttraining's rmse: 0.326001\tvalid_1's rmse: 0.638043\n",
      "[570]\ttraining's rmse: 0.323107\tvalid_1's rmse: 0.638183\n",
      "[580]\ttraining's rmse: 0.31996\tvalid_1's rmse: 0.637908\n",
      "[590]\ttraining's rmse: 0.316659\tvalid_1's rmse: 0.637055\n",
      "[600]\ttraining's rmse: 0.313701\tvalid_1's rmse: 0.636879\n",
      "[610]\ttraining's rmse: 0.310828\tvalid_1's rmse: 0.637028\n",
      "[620]\ttraining's rmse: 0.307941\tvalid_1's rmse: 0.637205\n",
      "[630]\ttraining's rmse: 0.305072\tvalid_1's rmse: 0.637392\n",
      "[640]\ttraining's rmse: 0.302106\tvalid_1's rmse: 0.637365\n",
      "[650]\ttraining's rmse: 0.299376\tvalid_1's rmse: 0.637129\n",
      "[660]\ttraining's rmse: 0.296531\tvalid_1's rmse: 0.637757\n",
      "[670]\ttraining's rmse: 0.293864\tvalid_1's rmse: 0.637725\n",
      "[680]\ttraining's rmse: 0.291284\tvalid_1's rmse: 0.637349\n",
      "[690]\ttraining's rmse: 0.288418\tvalid_1's rmse: 0.637185\n",
      "[700]\ttraining's rmse: 0.285629\tvalid_1's rmse: 0.637286\n",
      "[710]\ttraining's rmse: 0.283155\tvalid_1's rmse: 0.637359\n",
      "[720]\ttraining's rmse: 0.28062\tvalid_1's rmse: 0.637676\n",
      "[730]\ttraining's rmse: 0.277953\tvalid_1's rmse: 0.637488\n",
      "[740]\ttraining's rmse: 0.275344\tvalid_1's rmse: 0.637098\n",
      "[750]\ttraining's rmse: 0.272686\tvalid_1's rmse: 0.63721\n",
      "[760]\ttraining's rmse: 0.270141\tvalid_1's rmse: 0.637062\n",
      "[770]\ttraining's rmse: 0.267786\tvalid_1's rmse: 0.636919\n",
      "[780]\ttraining's rmse: 0.265188\tvalid_1's rmse: 0.636588\n",
      "[790]\ttraining's rmse: 0.262792\tvalid_1's rmse: 0.636785\n",
      "[800]\ttraining's rmse: 0.260338\tvalid_1's rmse: 0.637182\n",
      "[810]\ttraining's rmse: 0.257942\tvalid_1's rmse: 0.636929\n",
      "[820]\ttraining's rmse: 0.255494\tvalid_1's rmse: 0.637123\n",
      "[830]\ttraining's rmse: 0.253227\tvalid_1's rmse: 0.636563\n",
      "[840]\ttraining's rmse: 0.251047\tvalid_1's rmse: 0.636364\n",
      "[850]\ttraining's rmse: 0.248819\tvalid_1's rmse: 0.6363\n",
      "[860]\ttraining's rmse: 0.246652\tvalid_1's rmse: 0.636463\n",
      "[870]\ttraining's rmse: 0.244352\tvalid_1's rmse: 0.636229\n",
      "[880]\ttraining's rmse: 0.242241\tvalid_1's rmse: 0.636024\n",
      "[890]\ttraining's rmse: 0.239995\tvalid_1's rmse: 0.635671\n",
      "[900]\ttraining's rmse: 0.237937\tvalid_1's rmse: 0.635841\n",
      "[910]\ttraining's rmse: 0.235933\tvalid_1's rmse: 0.635757\n",
      "[920]\ttraining's rmse: 0.233954\tvalid_1's rmse: 0.635602\n",
      "[930]\ttraining's rmse: 0.231701\tvalid_1's rmse: 0.635737\n",
      "[940]\ttraining's rmse: 0.22949\tvalid_1's rmse: 0.636239\n",
      "[950]\ttraining's rmse: 0.227483\tvalid_1's rmse: 0.636324\n",
      "[960]\ttraining's rmse: 0.225617\tvalid_1's rmse: 0.63633\n",
      "[970]\ttraining's rmse: 0.22353\tvalid_1's rmse: 0.636068\n",
      "[980]\ttraining's rmse: 0.221491\tvalid_1's rmse: 0.636207\n",
      "[990]\ttraining's rmse: 0.219379\tvalid_1's rmse: 0.636179\n",
      "[1000]\ttraining's rmse: 0.217304\tvalid_1's rmse: 0.636525\n",
      "[1010]\ttraining's rmse: 0.215008\tvalid_1's rmse: 0.636741\n",
      "[1020]\ttraining's rmse: 0.213117\tvalid_1's rmse: 0.637028\n",
      "\n",
      "Fold_10 Training\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.8151102699226822e-06, reg_alpha=0.5087856916700971 will be ignored. Current value: lambda_l1=1.8151102699226822e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8410863683391213, subsample=0.5411528279742139 will be ignored. Current value: bagging_fraction=0.8410863683391213\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.017602890537921387, reg_lambda=0.2405984837342317 will be ignored. Current value: lambda_l2=0.017602890537921387\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.8151102699226822e-06, reg_alpha=0.5087856916700971 will be ignored. Current value: lambda_l1=1.8151102699226822e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8410863683391213, subsample=0.5411528279742139 will be ignored. Current value: bagging_fraction=0.8410863683391213\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.017602890537921387, reg_lambda=0.2405984837342317 will be ignored. Current value: lambda_l2=0.017602890537921387\n",
      "[LightGBM] [Info] Total Bins 86877\n",
      "[LightGBM] [Info] Number of data points in the train set: 2224, number of used features: 398\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.8151102699226822e-06, reg_alpha=0.5087856916700971 will be ignored. Current value: lambda_l1=1.8151102699226822e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8410863683391213, subsample=0.5411528279742139 will be ignored. Current value: bagging_fraction=0.8410863683391213\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.017602890537921387, reg_lambda=0.2405984837342317 will be ignored. Current value: lambda_l2=0.017602890537921387\n",
      "[LightGBM] [Info] Start training from score 3.710881\n",
      "[10]\ttraining's rmse: 0.927533\tvalid_1's rmse: 0.952608\n",
      "[20]\ttraining's rmse: 0.84931\tvalid_1's rmse: 0.889498\n",
      "[30]\ttraining's rmse: 0.785196\tvalid_1's rmse: 0.84096\n",
      "[40]\ttraining's rmse: 0.73322\tvalid_1's rmse: 0.804137\n",
      "[50]\ttraining's rmse: 0.690583\tvalid_1's rmse: 0.775106\n",
      "[60]\ttraining's rmse: 0.656028\tvalid_1's rmse: 0.751544\n",
      "[70]\ttraining's rmse: 0.62752\tvalid_1's rmse: 0.734751\n",
      "[80]\ttraining's rmse: 0.604151\tvalid_1's rmse: 0.722416\n",
      "[90]\ttraining's rmse: 0.584397\tvalid_1's rmse: 0.713054\n",
      "[100]\ttraining's rmse: 0.56773\tvalid_1's rmse: 0.705872\n",
      "[110]\ttraining's rmse: 0.553679\tvalid_1's rmse: 0.69886\n",
      "[120]\ttraining's rmse: 0.541116\tvalid_1's rmse: 0.693666\n",
      "[130]\ttraining's rmse: 0.529741\tvalid_1's rmse: 0.689378\n",
      "[140]\ttraining's rmse: 0.519659\tvalid_1's rmse: 0.686311\n",
      "[150]\ttraining's rmse: 0.510605\tvalid_1's rmse: 0.684118\n",
      "[160]\ttraining's rmse: 0.502255\tvalid_1's rmse: 0.682065\n",
      "[170]\ttraining's rmse: 0.494498\tvalid_1's rmse: 0.680583\n",
      "[180]\ttraining's rmse: 0.487162\tvalid_1's rmse: 0.678998\n",
      "[190]\ttraining's rmse: 0.479995\tvalid_1's rmse: 0.678026\n",
      "[200]\ttraining's rmse: 0.473464\tvalid_1's rmse: 0.676496\n",
      "[210]\ttraining's rmse: 0.467045\tvalid_1's rmse: 0.676554\n",
      "[220]\ttraining's rmse: 0.460925\tvalid_1's rmse: 0.676859\n",
      "[230]\ttraining's rmse: 0.455057\tvalid_1's rmse: 0.676664\n",
      "[240]\ttraining's rmse: 0.449384\tvalid_1's rmse: 0.676946\n",
      "[250]\ttraining's rmse: 0.443764\tvalid_1's rmse: 0.676981\n",
      "[260]\ttraining's rmse: 0.438681\tvalid_1's rmse: 0.677265\n",
      "[270]\ttraining's rmse: 0.433644\tvalid_1's rmse: 0.677593\n",
      "[280]\ttraining's rmse: 0.428782\tvalid_1's rmse: 0.676878\n",
      "[290]\ttraining's rmse: 0.423718\tvalid_1's rmse: 0.677418\n",
      "[300]\ttraining's rmse: 0.418876\tvalid_1's rmse: 0.678214\n",
      "[310]\ttraining's rmse: 0.413967\tvalid_1's rmse: 0.678207\n",
      "[320]\ttraining's rmse: 0.409227\tvalid_1's rmse: 0.677928\n",
      "[330]\ttraining's rmse: 0.404738\tvalid_1's rmse: 0.677628\n",
      "[340]\ttraining's rmse: 0.400211\tvalid_1's rmse: 0.677971\n",
      "[350]\ttraining's rmse: 0.395872\tvalid_1's rmse: 0.677521\n",
      "[360]\ttraining's rmse: 0.391667\tvalid_1's rmse: 0.678251\n",
      "[370]\ttraining's rmse: 0.387407\tvalid_1's rmse: 0.678405\n",
      "[380]\ttraining's rmse: 0.383369\tvalid_1's rmse: 0.67908\n",
      "[390]\ttraining's rmse: 0.379515\tvalid_1's rmse: 0.679294\n",
      "[400]\ttraining's rmse: 0.375498\tvalid_1's rmse: 0.678703\n",
      "[410]\ttraining's rmse: 0.371651\tvalid_1's rmse: 0.678662\n",
      "[420]\ttraining's rmse: 0.367806\tvalid_1's rmse: 0.679413\n",
      "[430]\ttraining's rmse: 0.364114\tvalid_1's rmse: 0.679496\n",
      "[440]\ttraining's rmse: 0.360467\tvalid_1's rmse: 0.679456\n",
      "[450]\ttraining's rmse: 0.356755\tvalid_1's rmse: 0.680116\n",
      "[460]\ttraining's rmse: 0.353323\tvalid_1's rmse: 0.681038\n",
      "[470]\ttraining's rmse: 0.349835\tvalid_1's rmse: 0.68128\n",
      "[480]\ttraining's rmse: 0.346298\tvalid_1's rmse: 0.681382\n",
      "[490]\ttraining's rmse: 0.342738\tvalid_1's rmse: 0.681975\n",
      "[500]\ttraining's rmse: 0.339596\tvalid_1's rmse: 0.681954\n",
      "[510]\ttraining's rmse: 0.336218\tvalid_1's rmse: 0.681867\n",
      "[520]\ttraining's rmse: 0.332745\tvalid_1's rmse: 0.68194\n",
      "[530]\ttraining's rmse: 0.329265\tvalid_1's rmse: 0.681864\n",
      "[540]\ttraining's rmse: 0.325908\tvalid_1's rmse: 0.682348\n",
      "[550]\ttraining's rmse: 0.32306\tvalid_1's rmse: 0.682262\n",
      "[560]\ttraining's rmse: 0.319776\tvalid_1's rmse: 0.682319\n",
      "[570]\ttraining's rmse: 0.316555\tvalid_1's rmse: 0.682593\n",
      "[580]\ttraining's rmse: 0.313676\tvalid_1's rmse: 0.682139\n",
      "[590]\ttraining's rmse: 0.31061\tvalid_1's rmse: 0.682151\n",
      "[600]\ttraining's rmse: 0.307608\tvalid_1's rmse: 0.682605\n"
     ]
    }
   ],
   "source": [
    "lgb_oof = []  \n",
    "df_importance_list_lgb = []  \n",
    "ycol = 'score'\n",
    "feature_names = list(filter(lambda x: x not in [ycol, 'id'], train_feats.columns))\n",
    "\n",
    "for i, (train_index, valid_index) in enumerate(skf.split(x, y.astype(str))):\n",
    "    train_x, train_y, valid_x, valid_y = train_valid_split(x, y, train_index, valid_index)\n",
    "    \n",
    "    print('\\nFold_{} Training'.format(i+1))\n",
    "    lgbmr.fit(train_x, \n",
    "              train_y,\n",
    "              eval_metric='rmse',\n",
    "              eval_set=[(train_x, train_y), (valid_x, valid_y)],\n",
    "              early_stopping_rounds=400,\n",
    "              verbose=10)\n",
    "    \n",
    "    lgbmr_pred = lgbmr.predict(valid_x)\n",
    "    \n",
    "    df_lgb_oof = train_feats.iloc[valid_index][['id', ycol]].copy()  \n",
    "    df_lgb_oof['pred'] = lgbmr_pred\n",
    "    lgb_oof.append(df_lgb_oof)  \n",
    "    pred_test_lgb = lgbmr.predict(testin_x)\n",
    "    \n",
    "    df_importance_lgb = pd.DataFrame({\n",
    "        'column': feature_names,\n",
    "        'importance': lgbmr.feature_importances_,\n",
    "    })\n",
    "    \n",
    "    df_importance_list_lgb.append(df_importance_lgb)\n",
    "\n",
    "df_importance_lgb = pd.concat(df_importance_list_lgb)\n",
    "df_importance_lgb = df_importance_lgb.groupby(['column'])['importance'].agg(\n",
    "    'mean').sort_values(ascending=False).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "85860d8c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T05:14:30.579762Z",
     "iopub.status.busy": "2024-01-08T05:14:30.579322Z",
     "iopub.status.idle": "2024-01-08T09:06:01.200283Z",
     "shell.execute_reply": "2024-01-08T09:06:01.198341Z"
    },
    "papermill": {
     "duration": 13890.766583,
     "end_time": "2024-01-08T09:06:01.206035",
     "exception": false,
     "start_time": "2024-01-08T05:14:30.439452",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold_1 Training (Stacking)\n",
      "\n",
      "Fold_2 Training (Stacking)\n",
      "\n",
      "Fold_3 Training (Stacking)\n",
      "\n",
      "Fold_4 Training (Stacking)\n",
      "\n",
      "Fold_5 Training (Stacking)\n",
      "\n",
      "Fold_6 Training (Stacking)\n"
     ]
    }
   ],
   "source": [
    "stack_oof = []\n",
    "df_importance_list_stack = []\n",
    "\n",
    "ycol = 'score'\n",
    "feature_names = list(filter(lambda x: x not in [ycol, 'id'], train_feats.columns))\n",
    "\n",
    "skf1 = StratifiedKFold(n_splits=6, random_state=random_state, shuffle=True)\n",
    "\n",
    "# stack_gen.fit(x,y)\n",
    "# pred_test_stack = stack_gen.predict(testin_x)\n",
    "\n",
    "for i, (train_index, valid_index) in enumerate(skf1.split(x, y.astype(str))):\n",
    "    train_x, train_y, valid_x, valid_y = train_valid_split(x, y, train_index, valid_index)\n",
    "    \n",
    "    print('\\nFold_{} Training (Stacking)'.format(i+1))\n",
    "    stack_gen.fit(train_x, train_y)\n",
    "    stack_gen_pred = stack_gen.predict(valid_x)\n",
    "    \n",
    "    df_stack_oof = train_feats.iloc[valid_index][['id', ycol]].copy()\n",
    "    df_stack_oof['pred'] = stack_gen_pred\n",
    "    stack_oof.append(df_stack_oof)\n",
    "    pred_test_stack = stack_gen.predict(testin_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ad711c08",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T09:06:01.822824Z",
     "iopub.status.busy": "2024-01-08T09:06:01.821884Z",
     "iopub.status.idle": "2024-01-08T09:06:01.839292Z",
     "shell.execute_reply": "2024-01-08T09:06:01.838127Z"
    },
    "papermill": {
     "duration": 0.160383,
     "end_time": "2024-01-08T09:06:01.841962",
     "exception": false,
     "start_time": "2024-01-08T09:06:01.681579",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb rmse: 0.6098904186645924\n",
      "lgb rmse: 0.6095817394643686\n",
      "stack rmse: 0.609468539705985\n"
     ]
    }
   ],
   "source": [
    "df_xgb_oof = pd.concat(xgb_oof)\n",
    "rmse = mean_squared_error(df_xgb_oof[ycol], df_xgb_oof['pred'], squared=False)\n",
    "print('xgb rmse:', rmse)\n",
    "\n",
    "df_lgb_oof = pd.concat(lgb_oof)\n",
    "rmse = mean_squared_error(df_lgb_oof[ycol], df_lgb_oof['pred'], squared=False)\n",
    "print('lgb rmse:', rmse)\n",
    "\n",
    "df_stack_oof = pd.concat(stack_oof)\n",
    "rmse = mean_squared_error(df_stack_oof[ycol], df_stack_oof['pred'], squared=False)\n",
    "print('stack rmse:', rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f6a893fc",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-01-08T09:06:02.126262Z",
     "iopub.status.busy": "2024-01-08T09:06:02.125373Z",
     "iopub.status.idle": "2024-01-08T09:08:28.047403Z",
     "shell.execute_reply": "2024-01-08T09:08:28.046454Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 146.216486,
     "end_time": "2024-01-08T09:08:28.198336",
     "exception": false,
     "start_time": "2024-01-08T09:06:01.981850",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current RMSE: 1.1876888060430648\n",
      "Current RMSE: 1.1875364201864274\n",
      "Current RMSE: 1.1873726614533784\n",
      "Current RMSE: 1.1872099799480302\n",
      "Current RMSE: 1.1870483761132755\n",
      "Current RMSE: 1.1868878503893134\n",
      "Current RMSE: 1.186728403213644\n",
      "Current RMSE: 1.1865700350210617\n",
      "Current RMSE: 1.186412746243651\n",
      "Current RMSE: 1.1862565373107785\n",
      "Current RMSE: 1.186101408649089\n",
      "Current RMSE: 1.1859473606825002\n",
      "Current RMSE: 1.1857943938321944\n",
      "Current RMSE: 1.185642508516616\n",
      "Current RMSE: 1.1854917051514637\n",
      "Current RMSE: 1.1853419841496862\n",
      "Current RMSE: 1.1851933459214763\n",
      "Current RMSE: 1.1850457908742649\n",
      "Current RMSE: 1.1848993194127166\n",
      "Current RMSE: 1.1847539319387232\n",
      "Current RMSE: 1.184609628851399\n",
      "Current RMSE: 1.1844664105470755\n",
      "Current RMSE: 1.184324277419295\n",
      "Current RMSE: 1.1841832298588073\n",
      "Current RMSE: 1.1840432682535622\n",
      "Current RMSE: 1.1839043929887059\n",
      "Current RMSE: 1.183766604446575\n",
      "Current RMSE: 1.1836299030066921\n",
      "Current RMSE: 1.1834942890457594\n",
      "Current RMSE: 1.1833597629376547\n",
      "Current RMSE: 1.183226325053426\n",
      "Current RMSE: 1.1830939757612868\n",
      "Current RMSE: 1.1829627154266107\n",
      "Current RMSE: 1.1828325444119259\n",
      "Current RMSE: 1.1827034630769118\n",
      "Current RMSE: 1.182575471778393\n",
      "Current RMSE: 1.1824485708703343\n",
      "Current RMSE: 1.1823227607038367\n",
      "Current RMSE: 1.1821980416271323\n",
      "Current RMSE: 1.1820744139855794\n",
      "Current RMSE: 1.1819518781216576\n",
      "Current RMSE: 1.1818304343749637\n",
      "Current RMSE: 1.181710083082207\n",
      "Current RMSE: 1.1815908245772035\n",
      "Current RMSE: 1.1814726591908737\n",
      "Current RMSE: 1.1813555872512358\n",
      "Current RMSE: 1.1812396090834019\n",
      "Current RMSE: 1.1811247250095747\n",
      "Current RMSE: 1.1810109353490414\n",
      "Current RMSE: 1.1808982404181703\n",
      "Current RMSE: 1.1807866405304062\n",
      "Current RMSE: 1.1806761359962663\n",
      "Current RMSE: 1.1805667271233353\n",
      "Current RMSE: 1.1804584142162622\n",
      "Current RMSE: 1.180351197576755\n",
      "Current RMSE: 1.1802450775035778\n",
      "Current RMSE: 1.1801400542925453\n",
      "Current RMSE: 1.18003612823652\n",
      "Current RMSE: 1.1799332996254066\n",
      "Current RMSE: 1.1798315687461502\n",
      "Current RMSE: 1.1797309358827306\n",
      "Current RMSE: 1.1796314013161582\n",
      "Current RMSE: 1.179532965324472\n",
      "Current RMSE: 1.1794356281827338\n",
      "Current RMSE: 1.1793393901630254\n",
      "Current RMSE: 1.1792442515344446\n",
      "Current RMSE: 1.1791502125631013\n",
      "Current RMSE: 1.179057273512114\n",
      "Current RMSE: 1.1789654346416067\n",
      "Current RMSE: 1.178874696208704\n",
      "Current RMSE: 1.1787850584675286\n",
      "Current RMSE: 1.178696521669197\n",
      "Current RMSE: 1.178609086061817\n",
      "Current RMSE: 1.1785227518904837\n",
      "Current RMSE: 1.1784375193972756\n",
      "Current RMSE: 1.1783533888212523\n",
      "Current RMSE: 1.1782703603984501\n",
      "Current RMSE: 1.178188434361879\n",
      "Current RMSE: 1.1781076109415205\n",
      "Current RMSE: 1.178027890364323\n",
      "Current RMSE: 1.1779492728541994\n",
      "Current RMSE: 1.1778717586320233\n",
      "Current RMSE: 1.177795347915627\n",
      "Current RMSE: 1.1777200409197972\n",
      "Current RMSE: 1.177645837856273\n",
      "Current RMSE: 1.1775727389337431\n",
      "Current RMSE: 1.1775007443578411\n",
      "Current RMSE: 1.1774298543311452\n",
      "Current RMSE: 1.1773600690531731\n",
      "Current RMSE: 1.1772913887203806\n",
      "Current RMSE: 1.1772238135261581\n",
      "Current RMSE: 1.1771573436608287\n",
      "Current RMSE: 1.1770919793116443\n",
      "Current RMSE: 1.1770277206627844\n",
      "Current RMSE: 1.1769645678953524\n",
      "Current RMSE: 1.1769025211873738\n",
      "Current RMSE: 1.1768415807137929\n",
      "Current RMSE: 1.1767817466464712\n",
      "Current RMSE: 1.1767230191541846\n",
      "Current RMSE: 1.1766653984026205\n",
      "Current RMSE: 1.1766088845543772\n",
      "Current RMSE: 1.176553477768959\n",
      "Current RMSE: 1.176499178202776\n",
      "Current RMSE: 1.1764459860091419\n",
      "Current RMSE: 1.17639390133827\n",
      "Current RMSE: 1.1763429243372732\n",
      "Current RMSE: 1.1762930551501605\n",
      "Current RMSE: 1.176244293917836\n",
      "Current RMSE: 1.176196640778096\n",
      "Current RMSE: 1.1761500958656275\n",
      "Current RMSE: 1.1761046593120068\n",
      "Current RMSE: 1.1760603312456963\n",
      "Current RMSE: 1.1760171117920444\n",
      "Current RMSE: 1.175975001073282\n",
      "Current RMSE: 1.1759339992085218\n",
      "Current RMSE: 1.175894106313757\n",
      "Current RMSE: 1.1758553225018582\n",
      "Current RMSE: 1.1758176478825737\n",
      "Current RMSE: 1.1757810825625263\n",
      "Current RMSE: 1.1757456266452124\n",
      "Current RMSE: 1.1757112802310008\n",
      "Current RMSE: 1.1756780434171312\n",
      "Current RMSE: 1.1756459162977122\n",
      "Current RMSE: 1.175614898963721\n",
      "Current RMSE: 1.1755849915030012\n",
      "Current RMSE: 1.1755561940002621\n",
      "Current RMSE: 1.175528506537077\n",
      "Current RMSE: 1.1755019291918831\n",
      "Current RMSE: 1.1754764620399791\n",
      "Current RMSE: 1.1754521051535245\n",
      "Current RMSE: 1.1754288586015393\n",
      "Current RMSE: 1.175406722449902\n",
      "Current RMSE: 1.1753856967613499\n",
      "Current RMSE: 1.1753657815954766\n",
      "Current RMSE: 1.1753469770087326\n",
      "Current RMSE: 1.1753292830544237\n",
      "Current RMSE: 1.1753126997827106\n",
      "Current RMSE: 1.1752972272406081\n",
      "Current RMSE: 1.175282865471984\n",
      "Current RMSE: 1.1752696145175596\n",
      "Current RMSE: 1.1752574744149076\n",
      "Current RMSE: 1.1752464451984528\n",
      "Current RMSE: 1.1752365268994713\n",
      "Current RMSE: 1.1752277195460896\n",
      "Current RMSE: 1.175220023163285\n",
      "Current RMSE: 1.1752134377728842\n",
      "Current RMSE: 1.175207963393564\n",
      "Current RMSE: 1.1752036000408503\n",
      "Current RMSE: 1.1752003477271185\n",
      "Current RMSE: 1.175198206461593\n",
      "Current RMSE: 1.1751971762503464\n",
      "Current RMSE: 1.175196741016584\n",
      "Current RMSE: 1.1751963154554141\n",
      "Current RMSE: 1.1751958995691072\n",
      "Current RMSE: 1.1751954933508948\n",
      "Current RMSE: 1.1751950968045204\n",
      "Current RMSE: 1.1751947099413882\n",
      "Current RMSE: 1.1751943327505099\n",
      "Current RMSE: 1.1751939652134156\n",
      "Current RMSE: 1.1751936073518874\n",
      "Current RMSE: 1.1751932591745062\n",
      "Current RMSE: 1.1751929206692284\n",
      "Current RMSE: 1.1751925918475479\n",
      "Current RMSE: 1.1751922727035145\n",
      "Current RMSE: 1.1751919632106198\n",
      "Current RMSE: 1.1751916633743398\n",
      "Current RMSE: 1.1751913732267287\n",
      "Current RMSE: 1.175191092739517\n",
      "Current RMSE: 1.1751908219395377\n",
      "Current RMSE: 1.1751905608333022\n",
      "Current RMSE: 1.1751903093663028\n",
      "Current RMSE: 1.1751903078175043\n",
      "Current RMSE: 1.175190067562872\n",
      "Current RMSE: 1.1751900618943478\n",
      "Current RMSE: 1.1751898354830046\n",
      "Current RMSE: 1.1751898256946776\n",
      "Current RMSE: 1.1751896130475437\n",
      "Current RMSE: 1.1751895991394479\n",
      "Current RMSE: 1.1751894003124435\n",
      "Current RMSE: 1.1751893822846462\n",
      "Current RMSE: 1.1751891972480109\n",
      "Current RMSE: 1.1751891751004357\n",
      "Current RMSE: 1.1751890038428694\n",
      "Current RMSE: 1.1751889775754991\n",
      "Current RMSE: 1.175188820017934\n",
      "Current RMSE: 1.1751887896308117\n",
      "Current RMSE: 1.1751886460215744\n",
      "Current RMSE: 1.175188611514734\n",
      "Current RMSE: 1.1751884817019422\n",
      "Current RMSE: 1.175188443075297\n",
      "Current RMSE: 1.1751883268589423\n",
      "Current RMSE: 1.1751882841124446\n",
      "Current RMSE: 1.1751881818607885\n",
      "Current RMSE: 1.175188134994601\n",
      "Current RMSE: 1.1751880464194941\n",
      "Current RMSE: 1.1751879954334892\n",
      "Current RMSE: 1.1751879205996485\n",
      "Current RMSE: 1.1751878654938563\n",
      "Current RMSE: 1.1751878046466382\n",
      "Current RMSE: 1.1751877454211457\n",
      "Current RMSE: 1.1751876981803189\n",
      "Current RMSE: 1.175187634834846\n",
      "Current RMSE: 1.175187601593883\n",
      "Current RMSE: 1.1751875341286913\n",
      "Current RMSE: 1.17518751460603\n",
      "Current RMSE: 1.1751874430211733\n",
      "Current RMSE: 1.1751874372746542\n",
      "Current RMSE: 1.175187361570046\n",
      "Current RMSE: 1.1751872896822295\n",
      "Current RMSE: 1.1751872276353081\n",
      "Current RMSE: 1.1751871751689185\n",
      "Current RMSE: 1.175187132373954\n",
      "Current RMSE: 1.175187099305789\n",
      "Current RMSE: 1.1751870759052658\n",
      "Current RMSE: 1.1751870621046652\n",
      "Blending weights: {'xgb': 0.046, 'lgb': 0.472, 'stack': 0.482}\n"
     ]
    }
   ],
   "source": [
    "xgb_oof_pred = df_xgb_oof['pred'].values\n",
    "lgb_oof_pred = df_lgb_oof['pred'].values\n",
    "stack_oof_pred = df_stack_oof['pred'].values\n",
    "\n",
    "margin = 1000\n",
    "\n",
    "current_RMSE = mean_squared_error(y, (xgb_oof_pred + lgb_oof_pred + stack_oof_pred) / 3, squared=False)\n",
    "\n",
    "best_i = 0\n",
    "best_j = 0\n",
    "\n",
    "for i in range(0, margin):\n",
    "    for j in range(0, margin - i):\n",
    "        blend_oof_pred = (i * xgb_oof_pred + j * lgb_oof_pred + (margin - i - j) * stack_oof_pred) / margin\n",
    "        \n",
    "        if mean_squared_error(y, blend_oof_pred, squared=False) < current_RMSE:\n",
    "            print(f\"Current RMSE: {current_RMSE}\")\n",
    "            current_RMSE = mean_squared_error(y, blend_oof_pred, squared=False)\n",
    "            best_i = i\n",
    "            best_j = j\n",
    "\n",
    "blending_weights = {\n",
    "    'xgb': best_i / margin,\n",
    "    'lgb': best_j / margin,\n",
    "    'stack': (margin - best_i - best_j) / margin\n",
    "}\n",
    "\n",
    "print(f\"Blending weights: {blending_weights}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c306e946",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T09:08:28.482776Z",
     "iopub.status.busy": "2024-01-08T09:08:28.482304Z",
     "iopub.status.idle": "2024-01-08T09:08:28.506063Z",
     "shell.execute_reply": "2024-01-08T09:08:28.505280Z"
    },
    "papermill": {
     "duration": 0.168561,
     "end_time": "2024-01-08T09:08:28.508257",
     "exception": false,
     "start_time": "2024-01-08T09:08:28.339696",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000aaaa</td>\n",
       "      <td>1.773148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2222bbbb</td>\n",
       "      <td>2.689286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4444cccc</td>\n",
       "      <td>2.598804</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id     score\n",
       "0  0000aaaa  1.773148\n",
       "1  2222bbbb  2.689286\n",
       "2  4444cccc  2.598804"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blended_preds = (\n",
    "    blending_weights['xgb'] * xgb_preds +\n",
    "    blending_weights['lgb'] * pred_test_lgb +\n",
    "    blending_weights['stack'] * pred_test_stack\n",
    ")\n",
    "\n",
    "blended_preds = np.clip(a=blended_preds, a_min=0.0, a_max=6.0)\n",
    "\n",
    "sub1 = pd.DataFrame({'id': test_ids, 'score': blended_preds})\n",
    "sub1.to_csv('submission.csv', index=False)\n",
    "sub1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27acb404",
   "metadata": {
    "papermill": {
     "duration": 0.142308,
     "end_time": "2024-01-08T09:08:28.793642",
     "exception": false,
     "start_time": "2024-01-08T09:08:28.651334",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# SILVER BULLET "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "37e1fccb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T09:08:29.085990Z",
     "iopub.status.busy": "2024-01-08T09:08:29.085147Z",
     "iopub.status.idle": "2024-01-08T09:08:29.090588Z",
     "shell.execute_reply": "2024-01-08T09:08:29.089625Z"
    },
    "papermill": {
     "duration": 0.156055,
     "end_time": "2024-01-08T09:08:29.093389",
     "exception": false,
     "start_time": "2024-01-08T09:08:28.937334",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DEBUG = True\n",
    "SEED = 42\n",
    "N_FOLD = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "199f0fec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T09:08:29.385102Z",
     "iopub.status.busy": "2024-01-08T09:08:29.384259Z",
     "iopub.status.idle": "2024-01-08T09:08:29.397625Z",
     "shell.execute_reply": "2024-01-08T09:08:29.396495Z"
    },
    "papermill": {
     "duration": 0.160399,
     "end_time": "2024-01-08T09:08:29.400351",
     "exception": false,
     "start_time": "2024-01-08T09:08:29.239952",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cbc427b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T09:08:29.686517Z",
     "iopub.status.busy": "2024-01-08T09:08:29.685624Z",
     "iopub.status.idle": "2024-01-08T09:08:29.729536Z",
     "shell.execute_reply": "2024-01-08T09:08:29.728330Z"
    },
    "papermill": {
     "duration": 0.190617,
     "end_time": "2024-01-08T09:08:29.732366",
     "exception": false,
     "start_time": "2024-01-08T09:08:29.541749",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_cols = ['down_time', 'up_time', 'action_time', 'cursor_position', 'word_count']\n",
    "activities = ['Input', 'Remove/Cut', 'Nonproduction', 'Replace', 'Paste']\n",
    "events = ['q', 'Space', 'Backspace', 'Shift', 'ArrowRight', 'Leftclick', 'ArrowLeft', '.', ',', 'ArrowDown', 'ArrowUp', 'Enter', 'CapsLock', \"'\", 'Delete', 'Unidentified']\n",
    "text_changes = ['q', ' ', '.', ',', '\\n', \"'\", '\"', '-', '?', ';', '=', '/', '\\\\', ':']\n",
    "\n",
    "def count_by_values(df, colname, values):\n",
    "    fts = df.select(pl.col('id').unique(maintain_order=True))\n",
    "    for i, value in enumerate(values):\n",
    "        tmp_df = df.group_by('id').agg(pl.col(colname).is_in([value]).sum().alias(f'{colname}_{i}_cnt'))\n",
    "        fts  = fts.join(tmp_df, on='id', how='left') \n",
    "    return fts\n",
    "\n",
    "def dev_feats(df):\n",
    "    \n",
    "    print(\"< Count by values features >\")\n",
    "    \n",
    "    feats = count_by_values(df, 'activity', activities)\n",
    "    feats = feats.join(count_by_values(df, 'text_change', text_changes), on='id', how='left') \n",
    "    feats = feats.join(count_by_values(df, 'down_event', events), on='id', how='left') \n",
    "    feats = feats.join(count_by_values(df, 'up_event', events), on='id', how='left') \n",
    "\n",
    "    print(\"< Input words stats features >\")\n",
    "    temp = df.filter((~pl.col('text_change').str.contains('=>')) & (pl.col('text_change') != 'NoChange'))\n",
    "    temp = temp.group_by('id').agg(pl.col('text_change').str.concat('').str.extract_all(r'q+'))\n",
    "    temp = temp.with_columns(input_word_count = pl.col('text_change').list.lengths(),\n",
    "                             input_word_length_mean = pl.col('text_change').apply(lambda x: np.mean([len(i) for i in x] if len(x) > 0 else 0)),\n",
    "                             input_word_length_max = pl.col('text_change').apply(lambda x: np.max([len(i) for i in x] if len(x) > 0 else 0)),\n",
    "                             input_word_length_std = pl.col('text_change').apply(lambda x: np.std([len(i) for i in x] if len(x) > 0 else 0)),\n",
    "                             input_word_length_median = pl.col('text_change').apply(lambda x: np.median([len(i) for i in x] if len(x) > 0 else 0)),\n",
    "                             input_word_length_skew = pl.col('text_change').apply(lambda x: skew([len(i) for i in x] if len(x) > 0 else 0)))\n",
    "    temp = temp.drop('text_change')\n",
    "    feats = feats.join(temp, on='id', how='left') \n",
    "\n",
    "    print(\"< Numerical columns features >\")\n",
    "\n",
    "    temp = df.group_by(\"id\").agg(pl.sum('action_time').suffix('_sum'), pl.mean(num_cols).suffix('_mean'), pl.std(num_cols).suffix('_std'),\n",
    "                                 pl.median(num_cols).suffix('_median'), pl.min(num_cols).suffix('_min'), pl.max(num_cols).suffix('_max'),\n",
    "                                 pl.quantile(num_cols, 0.5).suffix('_quantile'))\n",
    "    feats = feats.join(temp, on='id', how='left') \n",
    "\n",
    "\n",
    "    print(\"< Categorical columns features >\")\n",
    "    temp  = df.group_by(\"id\").agg(pl.n_unique(['activity', 'down_event', 'up_event', 'text_change']))\n",
    "    feats = feats.join(temp, on='id', how='left') \n",
    "\n",
    "    print(\"< Idle time features >\")\n",
    "    temp = df.with_columns(pl.col('up_time').shift().over('id').alias('up_time_lagged'))\n",
    "    temp = temp.with_columns((abs(pl.col('down_time') - pl.col('up_time_lagged')) / 1000).fill_null(0).alias('time_diff'))\n",
    "    temp = temp.filter(pl.col('activity').is_in(['Input', 'Remove/Cut']))\n",
    "    temp = temp.group_by(\"id\").agg(inter_key_largest_lantency = pl.max('time_diff'),\n",
    "                                   inter_key_median_lantency = pl.median('time_diff'),\n",
    "                                   mean_pause_time = pl.mean('time_diff'),\n",
    "                                   std_pause_time = pl.std('time_diff'),\n",
    "                                   total_pause_time = pl.sum('time_diff'),\n",
    "                                   pauses_half_sec = pl.col('time_diff').filter((pl.col('time_diff') > 0.5) & (pl.col('time_diff') < 1)).count(),\n",
    "                                   pauses_1_sec = pl.col('time_diff').filter((pl.col('time_diff') > 1) & (pl.col('time_diff') < 1.5)).count(),\n",
    "                                   pauses_1_half_sec = pl.col('time_diff').filter((pl.col('time_diff') > 1.5) & (pl.col('time_diff') < 2)).count(),\n",
    "                                   pauses_2_sec = pl.col('time_diff').filter((pl.col('time_diff') > 2) & (pl.col('time_diff') < 3)).count(),\n",
    "                                   pauses_3_sec = pl.col('time_diff').filter(pl.col('time_diff') > 3).count(),)\n",
    "    feats = feats.join(temp, on='id', how='left') \n",
    "    \n",
    "    print(\"< P-bursts features >\")\n",
    "    temp = df.with_columns(pl.col('up_time').shift().over('id').alias('up_time_lagged'))\n",
    "    temp = temp.with_columns((abs(pl.col('down_time') - pl.col('up_time_lagged')) / 1000).fill_null(0).alias('time_diff'))\n",
    "    temp = temp.filter(pl.col('activity').is_in(['Input', 'Remove/Cut']))\n",
    "    temp = temp.with_columns(pl.col('time_diff')<2)\n",
    "    temp = temp.with_columns(pl.when(pl.col(\"time_diff\") & pl.col(\"time_diff\").is_last()).then(pl.count()).over(pl.col(\"time_diff\").rle_id()).alias('P-bursts'))\n",
    "    temp = temp.drop_nulls()\n",
    "    temp = temp.group_by(\"id\").agg(pl.mean('P-bursts').suffix('_mean'), pl.std('P-bursts').suffix('_std'), pl.count('P-bursts').suffix('_count'),\n",
    "                                   pl.median('P-bursts').suffix('_median'), pl.max('P-bursts').suffix('_max'),\n",
    "                                   pl.first('P-bursts').suffix('_first'), pl.last('P-bursts').suffix('_last'))\n",
    "    feats = feats.join(temp, on='id', how='left') \n",
    "\n",
    "    print(\"< R-bursts features >\")\n",
    "    temp = df.filter(pl.col('activity').is_in(['Input', 'Remove/Cut']))\n",
    "    temp = temp.with_columns(pl.col('activity').is_in(['Remove/Cut']))\n",
    "    temp = temp.with_columns(pl.when(pl.col(\"activity\") & pl.col(\"activity\").is_last()).then(pl.count()).over(pl.col(\"activity\").rle_id()).alias('R-bursts'))\n",
    "    temp = temp.drop_nulls()\n",
    "    temp = temp.group_by(\"id\").agg(pl.mean('R-bursts').suffix('_mean'), pl.std('R-bursts').suffix('_std'), \n",
    "                                   pl.median('R-bursts').suffix('_median'), pl.max('R-bursts').suffix('_max'),\n",
    "                                   pl.first('R-bursts').suffix('_first'), pl.last('R-bursts').suffix('_last'))\n",
    "    feats = feats.join(temp, on='id', how='left')\n",
    "    \n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1a21fb64",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T09:08:30.031893Z",
     "iopub.status.busy": "2024-01-08T09:08:30.030571Z",
     "iopub.status.idle": "2024-01-08T09:08:30.058631Z",
     "shell.execute_reply": "2024-01-08T09:08:30.057715Z"
    },
    "papermill": {
     "duration": 0.184625,
     "end_time": "2024-01-08T09:08:30.061275",
     "exception": false,
     "start_time": "2024-01-08T09:08:29.876650",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "AGGREGATIONS = ['count', 'mean', 'min', 'max', 'first', 'last', q1, 'median', q3, 'sum']\n",
    "\n",
    "def word_feats(df):\n",
    "    essay_df = df\n",
    "    df['word'] = df['essay'].apply(lambda x: re.split(' |\\\\n|\\\\.|\\\\?|\\\\!',x))\n",
    "    df = df.explode('word')\n",
    "    df['word_len'] = df['word'].apply(lambda x: len(x))\n",
    "    df = df[df['word_len'] != 0]\n",
    "\n",
    "    word_agg_df = df[['id','word_len']].groupby(['id']).agg(AGGREGATIONS)\n",
    "    word_agg_df.columns = ['_'.join(x) for x in word_agg_df.columns]\n",
    "    word_agg_df['id'] = word_agg_df.index\n",
    "    word_agg_df = word_agg_df.reset_index(drop=True)\n",
    "    return word_agg_df\n",
    "\n",
    "def sent_feats(df):\n",
    "    df['sent'] = df['essay'].apply(lambda x: re.split('\\\\.|\\\\?|\\\\!',x))\n",
    "    df = df.explode('sent')\n",
    "    df['sent'] = df['sent'].apply(lambda x: x.replace('\\n','').strip())\n",
    "    df['sent_len'] = df['sent'].apply(lambda x: len(x))\n",
    "    df['sent_word_count'] = df['sent'].apply(lambda x: len(x.split(' ')))\n",
    "    df = df[df.sent_len!=0].reset_index(drop=True)\n",
    "\n",
    "    sent_agg_df = pd.concat([df[['id','sent_len']].groupby(['id']).agg(AGGREGATIONS), \n",
    "                             df[['id','sent_word_count']].groupby(['id']).agg(AGGREGATIONS)], axis=1)\n",
    "    sent_agg_df.columns = ['_'.join(x) for x in sent_agg_df.columns]\n",
    "    sent_agg_df['id'] = sent_agg_df.index\n",
    "    sent_agg_df = sent_agg_df.reset_index(drop=True)\n",
    "    sent_agg_df.drop(columns=[\"sent_word_count_count\"], inplace=True)\n",
    "    sent_agg_df = sent_agg_df.rename(columns={\"sent_len_count\":\"sent_count\"})\n",
    "    return sent_agg_df\n",
    "\n",
    "def parag_feats(df):\n",
    "    df['paragraph'] = df['essay'].apply(lambda x: x.split('\\n'))\n",
    "    df = df.explode('paragraph')\n",
    "    df['paragraph_len'] = df['paragraph'].apply(lambda x: len(x)) \n",
    "    df['paragraph_word_count'] = df['paragraph'].apply(lambda x: len(x.split(' ')))\n",
    "    df = df[df.paragraph_len!=0].reset_index(drop=True)\n",
    "    \n",
    "    paragraph_agg_df = pd.concat([df[['id','paragraph_len']].groupby(['id']).agg(AGGREGATIONS), \n",
    "                                  df[['id','paragraph_word_count']].groupby(['id']).agg(AGGREGATIONS)], axis=1) \n",
    "    paragraph_agg_df.columns = ['_'.join(x) for x in paragraph_agg_df.columns]\n",
    "    paragraph_agg_df['id'] = paragraph_agg_df.index\n",
    "    paragraph_agg_df = paragraph_agg_df.reset_index(drop=True)\n",
    "    paragraph_agg_df.drop(columns=[\"paragraph_word_count_count\"], inplace=True)\n",
    "    paragraph_agg_df = paragraph_agg_df.rename(columns={\"paragraph_len_count\":\"paragraph_count\"})\n",
    "    return paragraph_agg_df\n",
    "\n",
    "def product_to_keys(logs, essays):\n",
    "    essays['product_len'] = essays.essay.str.len()\n",
    "    tmp_df = logs[logs.activity.isin(['Input', 'Remove/Cut'])].groupby(['id']).agg({'activity': 'count'}).reset_index().rename(columns={'activity': 'keys_pressed'})\n",
    "    essays = essays.merge(tmp_df, on='id', how='left')\n",
    "    essays['product_to_keys'] = essays['product_len'] / essays['keys_pressed']\n",
    "    return essays[['id', 'product_to_keys']]\n",
    "\n",
    "def get_keys_pressed_per_second(logs):\n",
    "    temp_df = logs[logs['activity'].isin(['Input', 'Remove/Cut'])].groupby(['id']).agg(keys_pressed=('event_id', 'count')).reset_index()\n",
    "    temp_df_2 = logs.groupby(['id']).agg(min_down_time=('down_time', 'min'), max_up_time=('up_time', 'max')).reset_index()\n",
    "    temp_df = temp_df.merge(temp_df_2, on='id', how='left')\n",
    "    temp_df['keys_per_second'] = temp_df['keys_pressed'] / ((temp_df['max_up_time'] - temp_df['min_down_time']) / 1000)\n",
    "    return temp_df[['id', 'keys_per_second']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b001aa91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T09:08:30.350430Z",
     "iopub.status.busy": "2024-01-08T09:08:30.349616Z",
     "iopub.status.idle": "2024-01-08T09:09:44.136054Z",
     "shell.execute_reply": "2024-01-08T09:09:44.134159Z"
    },
    "papermill": {
     "duration": 74.085693,
     "end_time": "2024-01-08T09:09:44.288969",
     "exception": false,
     "start_time": "2024-01-08T09:08:30.203276",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "< Count by values features >\n",
      "< Input words stats features >\n",
      "< Numerical columns features >\n",
      "< Categorical columns features >\n",
      "< Idle time features >\n",
      "< P-bursts features >\n",
      "< R-bursts features >\n",
      "< Essay Reconstruction >\n",
      "unique_cols:['cursor_position_min']\n",
      "< Mapping >\n",
      "Number of features: 164\n",
      "< Testing Data >\n",
      "< Count by values features >\n",
      "< Input words stats features >\n",
      "< Numerical columns features >\n",
      "< Categorical columns features >\n",
      "< Idle time features >\n",
      "< P-bursts features >\n",
      "< R-bursts features >\n"
     ]
    }
   ],
   "source": [
    "train_logs    = pl.scan_csv('/kaggle/input/linking-writing-processes-to-writing-quality/train_logs.csv')\n",
    "train_feats   = dev_feats(train_logs)\n",
    "train_feats   = train_feats.collect().to_pandas()\n",
    "\n",
    "print('< Essay Reconstruction >')\n",
    "train_logs             = train_logs.collect().to_pandas()\n",
    "train_essays           = pd.read_csv('/kaggle/input/writing-quality-challenge-constructed-essays/train_essays_fast.csv')\n",
    "train_feats            = train_feats.merge(word_feats(train_essays), on='id', how='left')\n",
    "train_feats            = train_feats.merge(sent_feats(train_essays), on='id', how='left')\n",
    "train_feats            = train_feats.merge(parag_feats(train_essays), on='id', how='left')\n",
    "train_feats            = train_feats.merge(get_keys_pressed_per_second(train_logs), on='id', how='left')\n",
    "train_feats            = train_feats.merge(product_to_keys(train_logs, train_essays), on='id', how='left')\n",
    "\n",
    "keys=train_feats.keys().values\n",
    "unique_cols=[key for key in keys if train_feats[key].nunique()<2]\n",
    "print(f\"unique_cols:{unique_cols}\")\n",
    "train_feats = train_feats.drop(columns=unique_cols)\n",
    "\n",
    "print('< Mapping >')\n",
    "train_scores   = pd.read_csv('/kaggle/input/linking-writing-processes-to-writing-quality/train_scores.csv')\n",
    "data           = train_feats.merge(train_scores, on='id', how='left')\n",
    "x              = data.drop(['id', 'score'], axis=1)\n",
    "y              = data['score'].values\n",
    "\n",
    "print(f'Number of features: {len(x.columns)}')\n",
    "\n",
    "print('< Testing Data >')\n",
    "test_logs   = pl.scan_csv('/kaggle/working/test_logs.csv')\n",
    "test_feats  = dev_feats(test_logs)\n",
    "test_feats  = test_feats.collect().to_pandas()\n",
    "\n",
    "test_logs             = test_logs.collect().to_pandas()\n",
    "test_essays           = test_essays_copy\n",
    "test_feats            = test_feats.merge(word_feats(test_essays), on='id', how='left')\n",
    "test_feats            = test_feats.merge(sent_feats(test_essays), on='id', how='left')\n",
    "test_feats            = test_feats.merge(parag_feats(test_essays), on='id', how='left')\n",
    "test_feats            = test_feats.merge(get_keys_pressed_per_second(test_logs), on='id', how='left')\n",
    "test_feats            = test_feats.merge(product_to_keys(test_logs, test_essays), on='id', how='left')\n",
    "\n",
    "test_feats = test_feats.drop(columns=unique_cols)\n",
    "\n",
    "test_ids = test_feats['id'].values\n",
    "testin_x = test_feats.drop(['id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2cb9ad9d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T09:09:44.574720Z",
     "iopub.status.busy": "2024-01-08T09:09:44.574204Z",
     "iopub.status.idle": "2024-01-08T09:09:44.581725Z",
     "shell.execute_reply": "2024-01-08T09:09:44.580580Z"
    },
    "papermill": {
     "duration": 0.152632,
     "end_time": "2024-01-08T09:09:44.584304",
     "exception": false,
     "start_time": "2024-01-08T09:09:44.431672",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_feats = pd.concat([train_feats, train_scores['score']], axis=1)\n",
    "\n",
    "# generator = Sequential()\n",
    "# generator.add(Dense(128, input_shape=(100,)))\n",
    "# generator.add(LeakyReLU(alpha=0.01)) \n",
    "# generator.add(Dense(256))\n",
    "# generator.add(LeakyReLU(alpha=0.01))\n",
    "# generator.add(Dense(165)) \n",
    "\n",
    "# discriminator = Sequential()\n",
    "# discriminator.add(Dense(256, input_shape=(165,)))\n",
    "# discriminator.add(LeakyReLU(alpha=0.01))\n",
    "# discriminator.add(Dense(128))\n",
    "# discriminator.add(LeakyReLU(alpha=0.01))\n",
    "# discriminator.add(Dense(1))\n",
    "\n",
    "# gan_model = Sequential()\n",
    "# gan_model.add(generator)\n",
    "# discriminator.trainable = False\n",
    "# gan_model.add(discriminator)\n",
    "\n",
    "# discriminator.compile(loss=MeanSquaredError(), optimizer=Adam(learning_rate=0.0002, beta_1=0.5))\n",
    "# gan_model.compile(loss=MeanSquaredError(), optimizer=Adam(learning_rate=0.0002, beta_1=0.5))\n",
    "\n",
    "# epochs = 1000\n",
    "# batch_size = 128\n",
    "\n",
    "# for epoch in range(epochs):\n",
    "#     idx = np.random.randint(0, train_feats.shape[0], batch_size)\n",
    "#     real_samples = train_feats.drop(columns=['id']).iloc[idx].values\n",
    "#     fake_samples = generator.predict(np.random.rand(batch_size, 100))\n",
    "#     real_labels = real_samples \n",
    "#     fake_labels = fake_samples\n",
    "#     real_samples_tf = tf.convert_to_tensor(real_samples, dtype=tf.float32)\n",
    "#     fake_samples_tf = tf.convert_to_tensor(fake_samples, dtype=tf.float32)\n",
    "    \n",
    "    \n",
    "#     d_loss_real = discriminator.train_on_batch(real_samples_tf, real_labels)\n",
    "#     d_loss_fake = discriminator.train_on_batch(fake_samples_tf, fake_labels )\n",
    "#     d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "#     noise = np.random.rand(batch_size, 100)\n",
    "#     valid_labels = noise\n",
    "#     g_loss = gan_model.train_on_batch(noise, valid_labels)\n",
    "\n",
    "#     if epoch % 100 == 0:\n",
    "#         print(f\"Epoch {epoch}, D Loss: {d_loss}, G_Loss: {g_loss}\")\n",
    "        \n",
    "\n",
    "# generated_feats = generator.predict(np.random.rand(2471,100))\n",
    "\n",
    "# generated_ids = range(1, len(generated_feats) + 1)\n",
    "# df_generated = pd.DataFrame(generated_feats, columns=train_feats.columns[1:])\n",
    "# df_generated['id'] = [f\"{i:08d}\" for i in generated_ids]\n",
    "\n",
    "# train_feats = pd.concat([train_feats, df_generated], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "089d56fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T09:09:44.873897Z",
     "iopub.status.busy": "2024-01-08T09:09:44.873127Z",
     "iopub.status.idle": "2024-01-08T09:09:44.897528Z",
     "shell.execute_reply": "2024-01-08T09:09:44.896459Z"
    },
    "papermill": {
     "duration": 0.172007,
     "end_time": "2024-01-08T09:09:44.900236",
     "exception": false,
     "start_time": "2024-01-08T09:09:44.728229",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ModelTrainer():\n",
    "    def __init__(self, model_name, **params):\n",
    "        # Model\n",
    "        self.model_name = model_name\n",
    "        self.params = params\n",
    "        self.create_model()\n",
    "        \n",
    "        self.X = x\n",
    "        self.Y = y       \n",
    "        print(f'Number of features: {len(self.X.columns)}')\n",
    "        \n",
    "    \n",
    "    def make_pipeline(self, model):\n",
    "        return Pipeline([\n",
    "            ('remove_infs', FunctionTransformer(lambda x: np.nan_to_num(x, nan=np.nan, posinf=0, neginf=0))),\n",
    "            ('imputer', SimpleImputer(strategy='mean')),\n",
    "            ('normalizer', FunctionTransformer(lambda x: np.log1p(np.abs(x)))),\n",
    "            ('scaler', RobustScaler()),\n",
    "            ('model', model)\n",
    "        ])\n",
    "    \n",
    "    # Create the model\n",
    "    def create_model(self):\n",
    "        match model_name:\n",
    "            case \"lgbm\":\n",
    "                self.model = LGBMRegressor(**self.params)\n",
    "            case \"xgb\":\n",
    "                self.model = XGBRegressor(**self.params)\n",
    "            case \"catboost\":\n",
    "                self.model = CatBoostRegressor(**self.params)\n",
    "            case 'rfr':\n",
    "                self.model = self.make_pipeline(RandomForestRegressor(**self.params))\n",
    "            case \"svr\":\n",
    "                self.model = self.make_pipeline(SVR(**self.params))\n",
    "            case 'lasso':\n",
    "                self.model = self.make_pipeline(Lasso(**self.params))\n",
    "            case 'ridge':\n",
    "                self.model = self.make_pipeline(Ridge(**self.params))\n",
    "            case other:\n",
    "                print(\"Not implemented\")\n",
    "                sys.exit(-1)\n",
    "    \n",
    "    # Get the trained model        \n",
    "    def get_model(self):\n",
    "        return self.model\n",
    "        \n",
    "    # Train the model with 5-fold CV\n",
    "    def train_model(self):        \n",
    "        early_stopping_callback = lgb.early_stopping(200, first_metric_only=True, verbose=False)\n",
    "        verbose_callback = lgb.log_evaluation(100)        \n",
    "        # Split the training data into 5 fold\n",
    "        skf = StratifiedKFold(n_splits=N_FOLD, random_state=SEED, shuffle=True)\n",
    "        fold_rmses = []\n",
    "        for fold, (train_index, valid_index) in enumerate(skf.split(self.X, self.Y.astype(str))):\n",
    "            train_x = self.X.iloc[train_index]\n",
    "            train_y = self.Y[train_index]\n",
    "            valid_x = self.X.iloc[valid_index]\n",
    "            valid_y = self.Y[valid_index]\n",
    "            if model_name == 'lgbm':\n",
    "                # Train the model with early stop of 100 \n",
    "                self.model.fit(train_x, train_y, eval_set=[(valid_x, valid_y)],\n",
    "                          callbacks=[\n",
    "                                lgb.callback.early_stopping(stopping_rounds=100),\n",
    "                                lgb.callback.log_evaluation(period=100),\n",
    "                          ])  \n",
    "            else:\n",
    "                # Fit the model with train x and train y\n",
    "                self.model.fit(train_x, train_y)            \n",
    "            predictions = self.model.predict(valid_x)\n",
    "            rmse = mean_squared_error(y_true=valid_y, y_pred=predictions, squared=False) # Return RMSE\n",
    "            fold_rmses.append(rmse)\n",
    "        avg_rmse = np.mean(fold_rmses)\n",
    "        print(f\"Average rmse: {avg_rmse}\") \n",
    "        return avg_rmse\n",
    "    \n",
    "    # Evaluate the model with entire X data\n",
    "    def evaluation(self):\n",
    "        preds = self.predict(self.X)\n",
    "        rmse = mean_squared_error(y_true=self.Y, y_pred=preds, squared=False)\n",
    "        return rmse\n",
    "        \n",
    "    # Predict the test data. \n",
    "    def predict(self, test_x):\n",
    "        # Prediction loop\n",
    "        tests_y = np.zeros((len(test_x), N_FOLD))\n",
    "        for fold in range(N_FOLD):\n",
    "            preds = self.model.predict(test_x)\n",
    "            tests_y[:, fold] = preds\n",
    "            #print(f\"Fold = {fold} Prediction = {preds[:5]}\")\n",
    "        test_y = np.mean(tests_y, axis=1)\n",
    "        return test_y# Average the prediction of each fold model\n",
    "    \n",
    "    # Clear the memory\n",
    "    def clear_memory(self):\n",
    "        del self.model\n",
    "        libc.malloc_trim(0)\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eacd536e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T09:09:45.186390Z",
     "iopub.status.busy": "2024-01-08T09:09:45.185602Z",
     "iopub.status.idle": "2024-01-08T09:09:45.195703Z",
     "shell.execute_reply": "2024-01-08T09:09:45.194874Z"
    },
    "papermill": {
     "duration": 0.155429,
     "end_time": "2024-01-08T09:09:45.198184",
     "exception": false,
     "start_time": "2024-01-08T09:09:45.042755",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "params_dict ={}\n",
    "# CatBoostRegressor\n",
    "params_dict['catboost'] =  {\n",
    "    \"iterations\": 5000,\n",
    "    \"early_stopping_rounds\": 50,\n",
    "    \"depth\": 6,\n",
    "    \"loss_function\": \"RMSE\",\n",
    "    \"random_seed\": SEED,\n",
    "    \"silent\": True\n",
    "}\n",
    "\n",
    "## Best parameters of LGBM\n",
    "params_dict['lgbm'] = {\n",
    "    'n_estimators': 1024,\n",
    "    'learning_rate': 0.005,\n",
    "    'metric': 'rmse',\n",
    "    'random_state': SEED,\n",
    "    'force_col_wise': True,\n",
    "    'verbosity': 0,\n",
    "}\n",
    "\n",
    "# XGBRegressor\n",
    "params_dict['xgb'] = {\n",
    "    \"max_depth\": 4,\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"objective\": \"reg:squarederror\",\n",
    "    \"num_estimators\": 1000,\n",
    "    \"num_boost_round\": 1000,\n",
    "    \"eval_metric\": \"rmse\",\n",
    "    \"seed\": SEED\n",
    "}\n",
    "# svr\n",
    "params_dict['svr'] = {\n",
    "    'kernel':'rbf',\n",
    "    'C':1.0,\n",
    "    'epsilon': 0.1\n",
    "}\n",
    "# rfr \n",
    "params_dict['rfr'] = {\n",
    "    'max_depth': 6,\n",
    "    'max_features': 'sqrt',\n",
    "    'min_impurity_decrease': 0.0016295128631816343,\n",
    "    'n_estimators': 200,\n",
    "    'random_state': SEED,\n",
    "    }\n",
    "# Ridge\n",
    "params_dict['ridge'] = {\n",
    "    'alpha': 1,\n",
    "    'random_state': SEED,\n",
    "    'solver': 'auto'\n",
    "    }\n",
    "# Lasso\n",
    "params_dict['lasso'] = {\n",
    "    'alpha': 0.04198227921905038, \n",
    "    'max_iter': 2000, \n",
    "    'random_state': SEED,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "835ba47f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T09:09:45.484272Z",
     "iopub.status.busy": "2024-01-08T09:09:45.483494Z",
     "iopub.status.idle": "2024-01-08T09:09:45.499744Z",
     "shell.execute_reply": "2024-01-08T09:09:45.498509Z"
    },
    "papermill": {
     "duration": 0.161673,
     "end_time": "2024-01-08T09:09:45.502672",
     "exception": false,
     "start_time": "2024-01-08T09:09:45.340999",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_score = 1.0\n",
    "# Find the optimal learning rate\n",
    "def objective(trial, model_name):\n",
    "    global params_dict\n",
    "    # Parameters\n",
    "    params = params_dict[model_name] # Load the default parameters\n",
    "    # set the trial for tunable parameters\n",
    "    if model_name == 'xgb':\n",
    "        # Parameters for 'xgb' model\n",
    "        params['learning_rate'] = trial.suggest_loguniform('learning_rate', 1e-4, 0.5)\n",
    "        params['max_depth'] = trial.suggest_int('max_depth', 2, 64)\n",
    "    elif model_name == 'catboost':\n",
    "        params['depth'] = trial.suggest_int('depth', 2, 30)\n",
    "    elif model_name == 'svr':\n",
    "        params['epsilon'] = trial.suggest_float('epsilon', 0.01, 1)\n",
    "    elif model_name == 'ridge':\n",
    "        params['alpha'] = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
    "    elif model_name == 'lgbm':\n",
    "        params['learning_rate'] = trial.suggest_loguniform('learning_rate', 1e-4, 0.5)\n",
    "        params['reg_alpha'] = trial.suggest_loguniform('reg_alpha', 1e-3, 10.0)\n",
    "        params['reg_lambda'] = trial.suggest_loguniform('reg_lambda', 1e-3, 10.0)\n",
    "        params['colsample_bytree'] = trial.suggest_float('colsample_bytree', 0.5, 1)\n",
    "        params['subsample'] = trial.suggest_float('subsample', 0.5, 1)\n",
    "        params['num_leaves'] = trial.suggest_int('num_leaves', 8, 64)\n",
    "        params['min_child_samples'] = trial.suggest_int('min_child_samples', 1, 100)\n",
    "    # Experiment the parameters\n",
    "    trainer = ModelTrainer(model_name, **params)\n",
    "    avg_score = trainer.train_model()\n",
    "    # Save the model is the avg score > current best score\n",
    "    global best_score\n",
    "    if avg_score < best_score:\n",
    "        best_score = avg_score\n",
    "    # Clean up\n",
    "    trainer.clear_memory()\n",
    "    del trainer    \n",
    "    print(f\"Average result {avg_score} and the best score {best_score}\")\n",
    "    return avg_score\n",
    "\n",
    "def run_optuna(model_name):\n",
    "    study_name = f\"{model_name}_study\"\n",
    "    study_file_path = f\"/kaggle/working/{study_name}.db\"\n",
    "    if os.path.exists(study_file_path):\n",
    "        os.remove(study_file_path)\n",
    "    # # Create a study to find the optimal hyper-parameters    \n",
    "    study = optuna.create_study(direction=\"minimize\", study_name=study_name,\n",
    "                                storage=\"sqlite:///\" + f\"{study_file_path}\", # Storage path of the database keeping the study results\n",
    "                                load_if_exists=False)  # Resume the existing study\n",
    "    # Set up the timeout to avoid runing out of quote\n",
    "    # n_jobs =-1 is CPU bounded\n",
    "    study.optimize(lambda trial: objective(trial, model_name), \n",
    "                   n_jobs=4, n_trials=1000,\n",
    "                   show_progress_bar=True, gc_after_trial=True)\n",
    "    ## Print the best parameters    \n",
    "    best_trial = study.best_trial\n",
    "    best_params = study.best_params\n",
    "    # Print out the experiment results\n",
    "    print(f\"Best parameters: {best_params}\\n\\n\"\n",
    "          f\"Number of finished trials: {len(study.trials)}\\n\\n\"\n",
    "          f\"Best trial:{best_trial}\")    \n",
    "    return study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "370008be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T09:09:45.790172Z",
     "iopub.status.busy": "2024-01-08T09:09:45.789720Z",
     "iopub.status.idle": "2024-01-08T09:17:32.806460Z",
     "shell.execute_reply": "2024-01-08T09:17:32.805102Z"
    },
    "papermill": {
     "duration": 467.163558,
     "end_time": "2024-01-08T09:17:32.809322",
     "exception": false,
     "start_time": "2024-01-08T09:09:45.645764",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 164\n",
      "Average rmse: 0.6288597873858064\n",
      "Complete training ridge RMSE = 0.591842865049595\n",
      "Number of features: 164\n",
      "Average rmse: 0.6443191872700945\n",
      "Complete training svr RMSE = 0.5196104868817799\n",
      "Number of features: 164\n",
      "Average rmse: 0.6211000678151847\n",
      "Complete training catboost RMSE = 0.3092264620227419\n",
      "Number of features: 164\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 0.803681\n",
      "[200]\tvalid_0's rmse: 0.69716\n",
      "[300]\tvalid_0's rmse: 0.647156\n",
      "[400]\tvalid_0's rmse: 0.623434\n",
      "[500]\tvalid_0's rmse: 0.611678\n",
      "[600]\tvalid_0's rmse: 0.605905\n",
      "[700]\tvalid_0's rmse: 0.603699\n",
      "[800]\tvalid_0's rmse: 0.602694\n",
      "Early stopping, best iteration is:\n",
      "[788]\tvalid_0's rmse: 0.602495\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 0.803785\n",
      "[200]\tvalid_0's rmse: 0.693624\n",
      "[300]\tvalid_0's rmse: 0.644339\n",
      "[400]\tvalid_0's rmse: 0.620483\n",
      "[500]\tvalid_0's rmse: 0.610325\n",
      "[600]\tvalid_0's rmse: 0.604234\n",
      "[700]\tvalid_0's rmse: 0.601556\n",
      "[800]\tvalid_0's rmse: 0.600128\n",
      "[900]\tvalid_0's rmse: 0.599397\n",
      "[1000]\tvalid_0's rmse: 0.5986\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1021]\tvalid_0's rmse: 0.598342\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 0.78907\n",
      "[200]\tvalid_0's rmse: 0.679679\n",
      "[300]\tvalid_0's rmse: 0.629414\n",
      "[400]\tvalid_0's rmse: 0.607311\n",
      "[500]\tvalid_0's rmse: 0.598869\n",
      "[600]\tvalid_0's rmse: 0.593891\n",
      "[700]\tvalid_0's rmse: 0.591882\n",
      "[800]\tvalid_0's rmse: 0.590872\n",
      "[900]\tvalid_0's rmse: 0.590555\n",
      "Early stopping, best iteration is:\n",
      "[852]\tvalid_0's rmse: 0.590298\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 0.79932\n",
      "[200]\tvalid_0's rmse: 0.696249\n",
      "[300]\tvalid_0's rmse: 0.648642\n",
      "[400]\tvalid_0's rmse: 0.628293\n",
      "[500]\tvalid_0's rmse: 0.6208\n",
      "[600]\tvalid_0's rmse: 0.618089\n",
      "[700]\tvalid_0's rmse: 0.617573\n",
      "[800]\tvalid_0's rmse: 0.616888\n",
      "[900]\tvalid_0's rmse: 0.615917\n",
      "[1000]\tvalid_0's rmse: 0.61634\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[954]\tvalid_0's rmse: 0.615851\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 0.820423\n",
      "[200]\tvalid_0's rmse: 0.731293\n",
      "[300]\tvalid_0's rmse: 0.693364\n",
      "[400]\tvalid_0's rmse: 0.679174\n",
      "[500]\tvalid_0's rmse: 0.674244\n",
      "[600]\tvalid_0's rmse: 0.671486\n",
      "[700]\tvalid_0's rmse: 0.670051\n",
      "[800]\tvalid_0's rmse: 0.670208\n",
      "Early stopping, best iteration is:\n",
      "[710]\tvalid_0's rmse: 0.670036\n",
      "Average rmse: 0.6154045367357004\n",
      "Complete training lgbm RMSE = 0.44739481178873497\n",
      "Number of features: 164\n",
      "Average rmse: 0.6162859683423461\n",
      "Complete training xgb RMSE = 0.4350288405765967\n",
      "[('ridge', Pipeline(steps=[('remove_infs',\n",
      "                 FunctionTransformer(func=<function ModelTrainer.make_pipeline.<locals>.<lambda> at 0x7b6608c152d0>)),\n",
      "                ('imputer', SimpleImputer()),\n",
      "                ('normalizer',\n",
      "                 FunctionTransformer(func=<function ModelTrainer.make_pipeline.<locals>.<lambda> at 0x7b6608c149d0>)),\n",
      "                ('scaler', RobustScaler()),\n",
      "                ('model', Ridge(alpha=1, random_state=42))])), ('svr', Pipeline(steps=[('remove_infs',\n",
      "                 FunctionTransformer(func=<function ModelTrainer.make_pipeline.<locals>.<lambda> at 0x7b6608c15bd0>)),\n",
      "                ('imputer', SimpleImputer()),\n",
      "                ('normalizer',\n",
      "                 FunctionTransformer(func=<function ModelTrainer.make_pipeline.<locals>.<lambda> at 0x7b6608c15b40>)),\n",
      "                ('scaler', RobustScaler()), ('model', SVR())])), ('catboost', <catboost.core.CatBoostRegressor object at 0x7b660373ecb0>), ('lgbm', LGBMRegressor(force_col_wise=True, learning_rate=0.005, metric='rmse',\n",
      "              n_estimators=1024, random_state=42, verbosity=0)), ('xgb', XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric='rmse', feature_types=None,\n",
      "             gamma=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=4, max_leaves=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "             num_boost_round=1000, num_estimators=1000, ...))]\n"
     ]
    }
   ],
   "source": [
    "# Train the model and make the predictions\n",
    "def train_model(model_name, is_loaded=True):\n",
    "    best_params = params_dict[model_name]\n",
    "    # If is_loaded is True, load the best parameters.\n",
    "    # Otherwise, initiate an Optuna study to optimize parameters.\n",
    "    if is_loaded:  # Loaded the best parameters that are found from previous experiments\n",
    "        study_name = f\"{model_name}_study\"\n",
    "        study_file_path = f\"/kaggle/input/writing-quality-dataset/{study_name}.db\"\n",
    "        if os.path.isfile(study_file_path):\n",
    "            loaded_study = optuna.load_study(study_name=study_name,\n",
    "                                         storage=\"sqlite:///\" + f\"{study_file_path}\")\n",
    "            best_params.update(loaded_study.best_params)\n",
    "            print(f\"Best parameters: {best_params}\\n\\n\")\n",
    "    else:\n",
    "        study = run_optuna(model_name)\n",
    "        best_params.update(study.best_params)\n",
    "        # Print out the experiment results\n",
    "        print(f\"Best parameters: {best_params}\\n\\n\")\n",
    "    ## Parameters for LGBMRegressor model\n",
    "    trainer = ModelTrainer(model_name, **best_params)\n",
    "    trainer.train_model()\n",
    "    rmse = trainer.evaluation()\n",
    "    model = trainer.get_model()\n",
    "    print(f\"Complete training {model_name} RMSE = {rmse}\")\n",
    "    return model\n",
    "\n",
    "# Collect all the models\n",
    "models = []\n",
    "model_names = ['ridge', 'svr', 'catboost', 'lgbm', 'xgb'] # 5 models \n",
    "# model_names = ['lasso', 'ridge', 'rfr', 'svr', 'catboost', 'lgbm', 'xgb'] # 7 models\n",
    "preds_y = []\n",
    "tests_y = []\n",
    "for model_name in model_names:\n",
    "    is_loaded = True\n",
    "#     if 'lgbm' == model_name: # Enable optuna\n",
    "#         is_loaded = False\n",
    "    model = train_model(model_name, is_loaded)\n",
    "    models.append((model_name, model))\n",
    "print(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "01b7f207",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T09:17:33.106560Z",
     "iopub.status.busy": "2024-01-08T09:17:33.106143Z",
     "iopub.status.idle": "2024-01-08T09:17:33.114005Z",
     "shell.execute_reply": "2024-01-08T09:17:33.112938Z"
    },
    "papermill": {
     "duration": 0.159037,
     "end_time": "2024-01-08T09:17:33.116398",
     "exception": false,
     "start_time": "2024-01-08T09:17:32.957361",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_models(models, x, y):\n",
    "    # split the full train data (data_X and data_Y) into train and validation sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(x, y,\n",
    "                                                      test_size=0.2, random_state=SEED)\n",
    "    # fit and evaluate the models\n",
    "    weights = list()\n",
    "    for name, model in models:\n",
    "        # fit the model\n",
    "        model.fit(X_train, y_train)\n",
    "        # evaluate the model\n",
    "        y_preds = model.predict(X_val)\n",
    "        # Calculate the \n",
    "        rmse = mean_squared_error(y_true=y_val, y_pred=y_preds, squared=False)\n",
    "        # store the performance\n",
    "        weights.append(rmse)\n",
    "    # report model performance\n",
    "    print(f\"Weight = {weights}\")\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b1155c64",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T09:17:33.415946Z",
     "iopub.status.busy": "2024-01-08T09:17:33.415256Z",
     "iopub.status.idle": "2024-01-08T09:20:52.443689Z",
     "shell.execute_reply": "2024-01-08T09:20:52.442413Z"
    },
    "papermill": {
     "duration": 199.329076,
     "end_time": "2024-01-08T09:20:52.595372",
     "exception": false,
     "start_time": "2024-01-08T09:17:33.266296",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight = [0.561877767961382, 0.5787348739568923, 0.5442215367246644, 0.5413674268821377, 0.5367460131530352]\n",
      "[1.13043868 0.34338526 0.22959284]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    weights = evaluate_models(models, x, y)\n",
    "    # Use the weights (scores) as a weighting for the ensemble\n",
    "    ensemble = VotingRegressor(estimators=models, weights=weights)\n",
    "    ensemble.fit(x, y)\n",
    "    test_y = ensemble.predict(testin_x)\n",
    "    print(test_y)\n",
    "except Exception as e: \n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0eccbf8c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T09:20:52.895165Z",
     "iopub.status.busy": "2024-01-08T09:20:52.894704Z",
     "iopub.status.idle": "2024-01-08T09:20:52.908969Z",
     "shell.execute_reply": "2024-01-08T09:20:52.907877Z"
    },
    "papermill": {
     "duration": 0.166605,
     "end_time": "2024-01-08T09:20:52.911843",
     "exception": false,
     "start_time": "2024-01-08T09:20:52.745238",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000aaaa</td>\n",
       "      <td>1.130439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2222bbbb</td>\n",
       "      <td>0.343385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4444cccc</td>\n",
       "      <td>0.229593</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id     score\n",
       "0  0000aaaa  1.130439\n",
       "1  2222bbbb  0.343385\n",
       "2  4444cccc  0.229593"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub2= pd.DataFrame({'id': test_ids, 'score': test_y})\n",
    "sub2.to_csv('submission.csv', index=False)\n",
    "sub2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4e31e6",
   "metadata": {
    "papermill": {
     "duration": 0.150543,
     "end_time": "2024-01-08T09:20:53.211992",
     "exception": false,
     "start_time": "2024-01-08T09:20:53.061449",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# TOKENIZATION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a41dab5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T09:20:53.510046Z",
     "iopub.status.busy": "2024-01-08T09:20:53.509630Z",
     "iopub.status.idle": "2024-01-08T09:20:53.530870Z",
     "shell.execute_reply": "2024-01-08T09:20:53.529974Z"
    },
    "papermill": {
     "duration": 0.173019,
     "end_time": "2024-01-08T09:20:53.533129",
     "exception": false,
     "start_time": "2024-01-08T09:20:53.360110",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def getEssays(df):\n",
    "  \n",
    "    # 'id', 'activity', 'cursor_position', 'text_change' 열만 선택한 DataFrame 복사\n",
    "    textInputDf = df[['id', 'activity', 'cursor_position', 'text_change']].copy()\n",
    "    \n",
    "    # 'activity' 열에서 'Nonproduction'인 행을 제외\n",
    "    textInputDf = textInputDf[textInputDf.activity != 'Nonproduction']\n",
    "\n",
    "    # 각 'id'별로 발생한 활동 수를 계산하여 배열로 저장\n",
    "    valCountsArr = textInputDf['id'].value_counts(sort=False).values\n",
    "\n",
    "    lastIndex = 0\n",
    "\n",
    "    # 결과를 저장할 Pandas Series 생성\n",
    "    essaySeries = pd.Series()\n",
    "\n",
    "    for index, valCount in enumerate(valCountsArr):\n",
    "\n",
    "        currTextInput = textInputDf[['activity', 'cursor_position', 'text_change']].iloc[lastIndex : lastIndex + valCount]\n",
    "        lastIndex += valCount\n",
    "        essayText = \"\"\n",
    "\n",
    "        for Input in currTextInput.values:\n",
    "            \n",
    "            # Input[0] = activity\n",
    "            # Input[2] = cursor_position\n",
    "            # Input[3] = text_change\n",
    "            \n",
    "            if Input[0] == 'Replace':\n",
    "                # '=>' 문자열을 기준으로 text_change를 분할\n",
    "                replaceTxt = Input[2].split(' => ')\n",
    "                \n",
    "                # DONT TOUCH\n",
    "                essayText = essayText[:Input[1] - len(replaceTxt[1])] + replaceTxt[1] + essayText[Input[1] - len(replaceTxt[1]) + len(replaceTxt[0]):]\n",
    "                continue\n",
    "\n",
    "                \n",
    "            # If activity = Paste    \n",
    "            if Input[0] == 'Paste':\n",
    "                # DONT TOUCH\n",
    "                essayText = essayText[:Input[1] - len(Input[2])] + Input[2] + essayText[Input[1] - len(Input[2]):]\n",
    "                continue\n",
    "\n",
    "                \n",
    "            # If activity = Remove/Cut\n",
    "            if Input[0] == 'Remove/Cut':\n",
    "                # DONT TOUCH\n",
    "                essayText = essayText[:Input[1]] + essayText[Input[1] + len(Input[2]):]\n",
    "                continue\n",
    "\n",
    "                \n",
    "            # If activity = Move...\n",
    "            if \"M\" in Input[0]:\n",
    "                # \"Move from to\" 텍스트를 제거\n",
    "                croppedTxt = Input[0][10:]\n",
    "                \n",
    "                # ' To '를 기준으로 문자열을 분할\n",
    "                splitTxt = croppedTxt.split(' To ')\n",
    "                \n",
    "                # 문자열을 다시 ', '를 기준으로 분할하여 배열로 저장\n",
    "                valueArr = [item.split(', ') for item in splitTxt]\n",
    "                \n",
    "                # Move from [2, 4] To [5, 7] = (2, 4, 5, 7)\n",
    "                moveData = (int(valueArr[0][0][1:]), int(valueArr[0][1][:-1]), int(valueArr[1][0][1:]), int(valueArr[1][1][:-1]))\n",
    "\n",
    "                # 같은 위치로 이동하는 경우 건너뛰기\n",
    "                if moveData[0] != moveData[2]:\n",
    "                    # 텍스트를 앞으로 이동시키는 경우 (다른 경우)\n",
    "                    if moveData[0] < moveData[2]:\n",
    "                        # DONT TOUCH\n",
    "                        essayText = essayText[:moveData[0]] + essayText[moveData[1]:moveData[3]] + essayText[moveData[0]:moveData[1]] + essayText[moveData[3]:]\n",
    "                    else:\n",
    "                        # DONT TOUCH\n",
    "                        essayText = essayText[:moveData[2]] + essayText[moveData[0]:moveData[1]] + essayText[moveData[2]:moveData[0]] + essayText[moveData[1]:]\n",
    "                continue\n",
    "                         \n",
    "            # If just input\n",
    "            # DONT TOUCH\n",
    "            essayText = essayText[:Input[1] - len(Input[2])] + Input[2] + essayText[Input[1] - len(Input[2]):]\n",
    "\n",
    "        # 결과 시리즈의 해당 인덱스에 에세이 텍스트를 설정  \n",
    "        essaySeries[index] = essayText\n",
    "     \n",
    "    # 결과 시리즈의 인덱스를 고유한 'id' 값으로 설정\n",
    "    essaySeries.index =  textInputDf['id'].unique()\n",
    "    \n",
    "    return essaySeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "28607191",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T09:20:53.834572Z",
     "iopub.status.busy": "2024-01-08T09:20:53.833830Z",
     "iopub.status.idle": "2024-01-08T09:21:09.725319Z",
     "shell.execute_reply": "2024-01-08T09:21:09.723918Z"
    },
    "papermill": {
     "duration": 16.046397,
     "end_time": "2024-01-08T09:21:09.728339",
     "exception": false,
     "start_time": "2024-01-08T09:20:53.681942",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "traindf = pd.read_csv('/kaggle/input/linking-writing-processes-to-writing-quality/train_logs.csv')\n",
    "train_scores = pd.read_csv('/kaggle/input/linking-writing-processes-to-writing-quality/train_scores.csv')\n",
    "testdf = pd.read_csv('/kaggle/input/linking-writing-processes-to-writing-quality/test_logs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7df09674",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T09:21:10.031709Z",
     "iopub.status.busy": "2024-01-08T09:21:10.031253Z",
     "iopub.status.idle": "2024-01-08T09:33:08.393677Z",
     "shell.execute_reply": "2024-01-08T09:33:08.390756Z"
    },
    "papermill": {
     "duration": 718.668103,
     "end_time": "2024-01-08T09:33:08.546156",
     "exception": false,
     "start_time": "2024-01-08T09:21:09.878053",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8min 24s, sys: 3min 33s, total: 11min 57s\n",
      "Wall time: 11min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_essays = getEssays(traindf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "db0e87eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T09:33:08.845330Z",
     "iopub.status.busy": "2024-01-08T09:33:08.844888Z",
     "iopub.status.idle": "2024-01-08T09:33:08.859063Z",
     "shell.execute_reply": "2024-01-08T09:33:08.857579Z"
    },
    "papermill": {
     "duration": 0.166811,
     "end_time": "2024-01-08T09:33:08.861677",
     "exception": false,
     "start_time": "2024-01-08T09:33:08.694866",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.81 ms, sys: 0 ns, total: 6.81 ms\n",
      "Wall time: 6.84 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_essays = getEssays(testdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f6f01dc9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T09:33:09.159911Z",
     "iopub.status.busy": "2024-01-08T09:33:09.159454Z",
     "iopub.status.idle": "2024-01-08T09:33:09.172200Z",
     "shell.execute_reply": "2024-01-08T09:33:09.171022Z"
    },
    "papermill": {
     "duration": 0.16485,
     "end_time": "2024-01-08T09:33:09.175047",
     "exception": false,
     "start_time": "2024-01-08T09:33:09.010197",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_essaysdf = pd.DataFrame({'id': train_essays.index, 'essay': train_essays.values})\n",
    "test_essaysdf = pd.DataFrame({'id': test_essays.index, 'essay': test_essays.values})\n",
    "\n",
    "merged_data = train_essaysdf.merge(train_scores, on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5530cfbc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T09:33:09.473011Z",
     "iopub.status.busy": "2024-01-08T09:33:09.471894Z",
     "iopub.status.idle": "2024-01-08T09:33:09.496094Z",
     "shell.execute_reply": "2024-01-08T09:33:09.495090Z"
    },
    "papermill": {
     "duration": 0.175534,
     "end_time": "2024-01-08T09:33:09.499023",
     "exception": false,
     "start_time": "2024-01-08T09:33:09.323489",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2e9df20e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T09:33:09.800758Z",
     "iopub.status.busy": "2024-01-08T09:33:09.800320Z",
     "iopub.status.idle": "2024-01-08T09:33:11.506808Z",
     "shell.execute_reply": "2024-01-08T09:33:11.505561Z"
    },
    "papermill": {
     "duration": 1.860606,
     "end_time": "2024-01-08T09:33:11.509895",
     "exception": false,
     "start_time": "2024-01-08T09:33:09.649289",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(ngram_range=(1, 2))\n",
    "X_tokenizer_train = count_vectorizer.fit_transform(merged_data['essay'])\n",
    "X_tokenizer_test = count_vectorizer.transform(test_essaysdf['essay'])\n",
    "count_vectorizer.get_feature_names_out() #ADDED\n",
    "y = merged_data['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7b0e2c71",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T09:33:11.811773Z",
     "iopub.status.busy": "2024-01-08T09:33:11.811363Z",
     "iopub.status.idle": "2024-01-08T09:33:11.818242Z",
     "shell.execute_reply": "2024-01-08T09:33:11.817063Z"
    },
    "papermill": {
     "duration": 0.161948,
     "end_time": "2024-01-08T09:33:11.820539",
     "exception": false,
     "start_time": "2024-01-08T09:33:11.658591",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame()\n",
    "df_test = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4c405561",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T09:33:12.434876Z",
     "iopub.status.busy": "2024-01-08T09:33:12.434047Z",
     "iopub.status.idle": "2024-01-08T09:33:18.121545Z",
     "shell.execute_reply": "2024-01-08T09:33:18.119962Z"
    },
    "papermill": {
     "duration": 5.84219,
     "end_time": "2024-01-08T09:33:18.124487",
     "exception": false,
     "start_time": "2024-01-08T09:33:12.282297",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_tokenizer_train = X_tokenizer_train.todense()\n",
    "X_tokenizer_test = X_tokenizer_test.todense()\n",
    "\n",
    "for i in range(X_tokenizer_train.shape[1]) : \n",
    "    L = list(X_tokenizer_train[:,i])\n",
    "    li = [int(x) for x in L ]\n",
    "    df_train[f'feature {i}'] = li\n",
    "    \n",
    "for i in range(X_tokenizer_test.shape[1]) : \n",
    "    L = list(X_tokenizer_test[:,i])\n",
    "    li = [int(x) for x in L ]\n",
    "    df_test[f'feature {i}'] = li    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "56ede365",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T09:33:18.435453Z",
     "iopub.status.busy": "2024-01-08T09:33:18.435019Z",
     "iopub.status.idle": "2024-01-08T09:33:18.443481Z",
     "shell.execute_reply": "2024-01-08T09:33:18.442276Z"
    },
    "papermill": {
     "duration": 0.164435,
     "end_time": "2024-01-08T09:33:18.445983",
     "exception": false,
     "start_time": "2024-01-08T09:33:18.281548",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train_index = train_essaysdf['id']\n",
    "df_test_index = test_essaysdf['id']\n",
    "\n",
    "df_train.loc[:, 'id'] = df_train_index\n",
    "df_test.loc[:, 'id'] = df_test_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0b41cf79",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T09:33:18.749096Z",
     "iopub.status.busy": "2024-01-08T09:33:18.748620Z",
     "iopub.status.idle": "2024-01-08T09:33:24.583693Z",
     "shell.execute_reply": "2024-01-08T09:33:24.582734Z"
    },
    "papermill": {
     "duration": 5.991285,
     "end_time": "2024-01-08T09:33:24.586388",
     "exception": false,
     "start_time": "2024-01-08T09:33:18.595103",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_agg_fe_df = traindf.groupby(\"id\")[['down_time', 'up_time', 'action_time', 'cursor_position', 'word_count']].agg(['mean', 'std', 'min', 'max', 'last', 'first', 'sem', 'median', 'sum'])\n",
    "train_agg_fe_df.columns = ['_'.join(x) for x in train_agg_fe_df.columns]\n",
    "train_agg_fe_df = train_agg_fe_df.add_prefix(\"tmp_\")\n",
    "train_agg_fe_df.reset_index(inplace=True)\n",
    "\n",
    "test_agg_fe_df = testdf.groupby(\"id\")[['down_time', 'up_time', 'action_time', 'cursor_position', 'word_count']].agg(['mean', 'std', 'min', 'max', 'last', 'first', 'sem', 'median', 'sum'])\n",
    "test_agg_fe_df.columns = ['_'.join(x) for x in test_agg_fe_df.columns]\n",
    "test_agg_fe_df = test_agg_fe_df.add_prefix(\"tmp_\")\n",
    "test_agg_fe_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5459640f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T09:33:24.887497Z",
     "iopub.status.busy": "2024-01-08T09:33:24.886751Z",
     "iopub.status.idle": "2024-01-08T09:33:24.946054Z",
     "shell.execute_reply": "2024-01-08T09:33:24.944535Z"
    },
    "papermill": {
     "duration": 0.213534,
     "end_time": "2024-01-08T09:33:24.949327",
     "exception": false,
     "start_time": "2024-01-08T09:33:24.735793",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "class Preprocessor:\n",
    "    \n",
    "    def __init__(self, seed):\n",
    "        self.seed = seed\n",
    "        \n",
    "        self.activities = ['Input', 'Remove/Cut', 'Nonproduction', 'Replace', 'Paste']\n",
    "        self.events = ['q', 'Space', 'Backspace', 'Shift', 'ArrowRight', 'Leftclick', 'ArrowLeft', '.', ',', \n",
    "              'ArrowDown', 'ArrowUp', 'Enter', 'CapsLock', \"'\", 'Delete', 'Unidentified']\n",
    "        self.text_changes = ['q', ' ', 'NoChange', '.', ',', '\\n', \"'\", '\"', '-', '?', ';', '=', '/', '\\\\', ':']\n",
    "        self.punctuations = ['\"', '.', ',', \"'\", '-', ';', ':', '?', '!', '<', '>', '/',\n",
    "                        '@', '#', '$', '%', '^', '&', '*', '(', ')', '_', '+']\n",
    "        self.gaps = [1, 2, 3, 5, 10, 20, 50, 100]\n",
    "        \n",
    "        self.idf = defaultdict(float)\n",
    "#         self.gaps = [1, 2]\n",
    "    \n",
    "    def activity_counts(self, df):\n",
    "        tmp_df = df.groupby('id').agg({'activity': list}).reset_index()\n",
    "        ret = list()\n",
    "        for li in tqdm(tmp_df['activity'].values):\n",
    "            items = list(Counter(li).items())\n",
    "            di = dict()\n",
    "            for k in self.activities:\n",
    "                di[k] = 0\n",
    "            for item in items:\n",
    "                k, v = item[0], item[1]\n",
    "                if k in di:\n",
    "                    di[k] = v\n",
    "            ret.append(di)\n",
    "        ret = pd.DataFrame(ret)\n",
    "        cols = [f'activity_{i}_count' for i in range(len(ret.columns))]\n",
    "        ret.columns = cols\n",
    "\n",
    "        cnts = ret.sum(1)\n",
    "\n",
    "        for col in cols:\n",
    "            if col in self.idf.keys():\n",
    "                idf = self.idf[col]\n",
    "            else:\n",
    "                idf = df.shape[0] / (ret[col].sum() + 1)\n",
    "                idf = np.log(idf)\n",
    "                self.idf[col] = idf\n",
    "\n",
    "            ret[col] = 1 + np.log(ret[col] / cnts)\n",
    "            ret[col] *= idf\n",
    "\n",
    "        return ret\n",
    "\n",
    "\n",
    "    def event_counts(self, df, colname):\n",
    "        tmp_df = df.groupby('id').agg({colname: list}).reset_index()\n",
    "        ret = list()\n",
    "        for li in tqdm(tmp_df[colname].values):\n",
    "            items = list(Counter(li).items())\n",
    "            di = dict()\n",
    "            for k in self.events:\n",
    "                di[k] = 0\n",
    "            for item in items:\n",
    "                k, v = item[0], item[1]\n",
    "                if k in di:\n",
    "                    di[k] = v\n",
    "            ret.append(di)\n",
    "        ret = pd.DataFrame(ret)\n",
    "        cols = [f'{colname}_{i}_count' for i in range(len(ret.columns))]\n",
    "        ret.columns = cols\n",
    "\n",
    "        cnts = ret.sum(1)\n",
    "\n",
    "        for col in cols:\n",
    "            if col in self.idf.keys():\n",
    "                idf = self.idf[col]\n",
    "            else:\n",
    "                idf = df.shape[0] / (ret[col].sum() + 1)\n",
    "                idf = np.log(idf)\n",
    "                self.idf[col] = idf\n",
    "            \n",
    "            ret[col] = 1 + np.log(ret[col] / cnts)\n",
    "            ret[col] *= idf\n",
    "\n",
    "        return ret\n",
    "\n",
    "\n",
    "    def text_change_counts(self, df):\n",
    "        tmp_df = df.groupby('id').agg({'text_change': list}).reset_index()\n",
    "        ret = list()\n",
    "        for li in tqdm(tmp_df['text_change'].values):\n",
    "            items = list(Counter(li).items())\n",
    "            di = dict()\n",
    "            for k in self.text_changes:\n",
    "                di[k] = 0\n",
    "            for item in items:\n",
    "                k, v = item[0], item[1]\n",
    "                if k in di:\n",
    "                    di[k] = v\n",
    "            ret.append(di)\n",
    "        ret = pd.DataFrame(ret)\n",
    "        cols = [f'text_change_{i}_count' for i in range(len(ret.columns))]\n",
    "        ret.columns = cols\n",
    "\n",
    "        cnts = ret.sum(1)\n",
    "\n",
    "        for col in cols:\n",
    "            if col in self.idf.keys():\n",
    "                idf = self.idf[col]\n",
    "            else:\n",
    "                idf = df.shape[0] / (ret[col].sum() + 1)\n",
    "                idf = np.log(idf)\n",
    "                self.idf[col] = idf\n",
    "            \n",
    "            ret[col] = 1 + np.log(ret[col] / cnts)\n",
    "            ret[col] *= idf\n",
    "            \n",
    "        return ret\n",
    "\n",
    "    def match_punctuations(self, df):\n",
    "        tmp_df = df.groupby('id').agg({'down_event': list}).reset_index()\n",
    "        ret = list()\n",
    "        for li in tqdm(tmp_df['down_event'].values):\n",
    "            cnt = 0\n",
    "            items = list(Counter(li).items())\n",
    "            for item in items:\n",
    "                k, v = item[0], item[1]\n",
    "                if k in self.punctuations:\n",
    "                    cnt += v\n",
    "            ret.append(cnt)\n",
    "        ret = pd.DataFrame({'punct_cnt': ret})\n",
    "        return ret\n",
    "\n",
    "\n",
    "    def get_input_words(self, df):\n",
    "        tmp_df = df[(~df['text_change'].str.contains('=>'))&(df['text_change'] != 'NoChange')].reset_index(drop=True)\n",
    "        tmp_df = tmp_df.groupby('id').agg({'text_change': list}).reset_index()\n",
    "        tmp_df['text_change'] = tmp_df['text_change'].apply(lambda x: ''.join(x))\n",
    "        tmp_df['text_change'] = tmp_df['text_change'].apply(lambda x: re.findall(r'q+', x))\n",
    "        tmp_df['input_word_count'] = tmp_df['text_change'].apply(len)\n",
    "        tmp_df['input_word_length_mean'] = tmp_df['text_change'].apply(lambda x: np.mean([len(i) for i in x] if len(x) > 0 else 0))\n",
    "        tmp_df['input_word_length_max'] = tmp_df['text_change'].apply(lambda x: np.max([len(i) for i in x] if len(x) > 0 else 0))\n",
    "        tmp_df['input_word_length_std'] = tmp_df['text_change'].apply(lambda x: np.std([len(i) for i in x] if len(x) > 0 else 0))\n",
    "        tmp_df.drop(['text_change'], axis=1, inplace=True)\n",
    "        return tmp_df\n",
    "    \n",
    "    def make_feats(self, df):\n",
    "        \n",
    "        print(\"Starting to engineer features\")\n",
    "        \n",
    "        # initialize features dataframe\n",
    "        feats = pd.DataFrame({'id': df['id'].unique().tolist()})\n",
    "        \n",
    "        # get shifted features\n",
    "        # time shift\n",
    "        print(\"Engineering time data\")\n",
    "        for gap in self.gaps:\n",
    "            print(f\"> for gap {gap}\")\n",
    "            df[f'up_time_shift{gap}'] = df.groupby('id')['up_time'].shift(gap)\n",
    "            df[f'action_time_gap{gap}'] = df['down_time'] - df[f'up_time_shift{gap}']\n",
    "        df.drop(columns=[f'up_time_shift{gap}' for gap in self.gaps], inplace=True)\n",
    "\n",
    "        # cursor position shift\n",
    "        print(\"Engineering cursor position data\")\n",
    "        for gap in self.gaps:\n",
    "            print(f\"> for gap {gap}\")\n",
    "            df[f'cursor_position_shift{gap}'] = df.groupby('id')['cursor_position'].shift(gap)\n",
    "            df[f'cursor_position_change{gap}'] = df['cursor_position'] - df[f'cursor_position_shift{gap}']\n",
    "            df[f'cursor_position_abs_change{gap}'] = np.abs(df[f'cursor_position_change{gap}'])\n",
    "        df.drop(columns=[f'cursor_position_shift{gap}' for gap in self.gaps], inplace=True)\n",
    "\n",
    "        # word count shift\n",
    "        print(\"Engineering word count data\")\n",
    "        for gap in self.gaps:\n",
    "            print(f\"> for gap {gap}\")\n",
    "            df[f'word_count_shift{gap}'] = df.groupby('id')['word_count'].shift(gap)\n",
    "            df[f'word_count_change{gap}'] = df['word_count'] - df[f'word_count_shift{gap}']\n",
    "            df[f'word_count_abs_change{gap}'] = np.abs(df[f'word_count_change{gap}'])\n",
    "        df.drop(columns=[f'word_count_shift{gap}' for gap in self.gaps], inplace=True)\n",
    "        \n",
    "        # get aggregate statistical features\n",
    "        print(\"Engineering statistical summaries for features\")\n",
    "        # [(feature name, [ stat summaries to add ])]\n",
    "        feats_stat = [\n",
    "            ('event_id', ['max']),\n",
    "            ('up_time', ['max']),\n",
    "            ('action_time', ['max', 'min', 'mean', 'std', 'quantile', 'sem', 'sum', 'skew']),\n",
    "            ('activity', ['nunique']),\n",
    "            ('down_event', ['nunique']),\n",
    "            ('up_event', ['nunique']),\n",
    "            ('text_change', ['nunique']),\n",
    "            ('cursor_position', ['nunique', 'max', 'quantile', 'sem', 'mean']),\n",
    "            ('word_count', ['nunique', 'max', 'quantile', 'sem', 'mean'])]\n",
    "        for gap in self.gaps:\n",
    "            feats_stat.extend([\n",
    "                (f'action_time_gap{gap}', ['max', 'min', 'mean', 'std', 'quantile', 'sem', 'sum', 'skew']),\n",
    "                (f'cursor_position_change{gap}', ['max', 'mean', 'std', 'quantile', 'sem', 'sum', 'skew']),\n",
    "                (f'word_count_change{gap}', ['max', 'mean', 'std', 'quantile', 'sem', 'sum', 'skew'])\n",
    "            ])\n",
    "        \n",
    "        pbar = tqdm(feats_stat)\n",
    "        for item in pbar:\n",
    "            colname, methods = item[0], item[1]\n",
    "            for method in methods:\n",
    "                pbar.set_postfix()\n",
    "                if isinstance(method, str):\n",
    "                    method_name = method\n",
    "                else:\n",
    "                    method_name = method.__name__\n",
    "                    \n",
    "                pbar.set_postfix(column=colname, method=method_name)\n",
    "                tmp_df = df.groupby(['id']).agg({colname: method}).reset_index().rename(columns={colname: f'{colname}_{method_name}'})\n",
    "                feats = feats.merge(tmp_df, on='id', how='left')\n",
    "\n",
    "        # counts\n",
    "        print(\"Engineering activity counts data\")\n",
    "        tmp_df = self.activity_counts(df)\n",
    "        feats = pd.concat([feats, tmp_df], axis=1)\n",
    "        \n",
    "        print(\"Engineering event counts data\")\n",
    "        tmp_df = self.event_counts(df, 'down_event')\n",
    "        feats = pd.concat([feats, tmp_df], axis=1)\n",
    "        tmp_df = self.event_counts(df, 'up_event')\n",
    "        feats = pd.concat([feats, tmp_df], axis=1)\n",
    "        \n",
    "        print(\"Engineering text change counts data\")\n",
    "        tmp_df = self.text_change_counts(df)\n",
    "        feats = pd.concat([feats, tmp_df], axis=1)\n",
    "        \n",
    "        print(\"Engineering punctuation counts data\")\n",
    "        tmp_df = self.match_punctuations(df)\n",
    "        feats = pd.concat([feats, tmp_df], axis=1)\n",
    "\n",
    "        # input words\n",
    "        print(\"Engineering input words data\")\n",
    "        tmp_df = self.get_input_words(df)\n",
    "        feats = pd.merge(feats, tmp_df, on='id', how='left')\n",
    "\n",
    "        # compare feats\n",
    "        print(\"Engineering ratios data\")\n",
    "        feats['word_time_ratio'] = feats['word_count_max'] / feats['up_time_max']\n",
    "        feats['word_event_ratio'] = feats['word_count_max'] / feats['event_id_max']\n",
    "        feats['event_time_ratio'] = feats['event_id_max']  / feats['up_time_max']\n",
    "        feats['idle_time_ratio'] = feats['action_time_gap1_sum'] / feats['up_time_max']\n",
    "        \n",
    "        print(\"Done!\")\n",
    "        return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3fc98788",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T09:33:25.262922Z",
     "iopub.status.busy": "2024-01-08T09:33:25.262470Z",
     "iopub.status.idle": "2024-01-08T09:33:25.267837Z",
     "shell.execute_reply": "2024-01-08T09:33:25.266584Z"
    },
    "papermill": {
     "duration": 0.159248,
     "end_time": "2024-01-08T09:33:25.270523",
     "exception": false,
     "start_time": "2024-01-08T09:33:25.111275",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3fdf9008",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T09:33:25.575033Z",
     "iopub.status.busy": "2024-01-08T09:33:25.574225Z",
     "iopub.status.idle": "2024-01-08T09:39:08.366721Z",
     "shell.execute_reply": "2024-01-08T09:39:08.365188Z"
    },
    "papermill": {
     "duration": 342.94775,
     "end_time": "2024-01-08T09:39:08.369410",
     "exception": false,
     "start_time": "2024-01-08T09:33:25.421660",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineering features for training data\n",
      "Starting to engineer features\n",
      "Engineering time data\n",
      "> for gap 1\n",
      "> for gap 2\n",
      "> for gap 3\n",
      "> for gap 5\n",
      "> for gap 10\n",
      "> for gap 20\n",
      "> for gap 50\n",
      "> for gap 100\n",
      "Engineering cursor position data\n",
      "> for gap 1\n",
      "> for gap 2\n",
      "> for gap 3\n",
      "> for gap 5\n",
      "> for gap 10\n",
      "> for gap 20\n",
      "> for gap 50\n",
      "> for gap 100\n",
      "Engineering word count data\n",
      "> for gap 1\n",
      "> for gap 2\n",
      "> for gap 3\n",
      "> for gap 5\n",
      "> for gap 10\n",
      "> for gap 20\n",
      "> for gap 50\n",
      "> for gap 100\n",
      "Engineering statistical summaries for features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [04:20<00:00,  7.90s/it, column=word_count_change100, method=skew]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineering activity counts data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2471/2471 [00:00<00:00, 4938.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineering event counts data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2471/2471 [00:00<00:00, 4406.80it/s]\n",
      "100%|██████████| 2471/2471 [00:00<00:00, 4802.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineering text change counts data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2471/2471 [00:00<00:00, 4835.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineering punctuation counts data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2471/2471 [00:00<00:00, 4807.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineering input words data\n",
      "Engineering ratios data\n",
      "Done!\n",
      "\n",
      "-------------------------\n",
      "Engineering features for test data\n",
      "-------------------------\n",
      "Starting to engineer features\n",
      "Engineering time data\n",
      "> for gap 1\n",
      "> for gap 2\n",
      "> for gap 3\n",
      "> for gap 5\n",
      "> for gap 10\n",
      "> for gap 20\n",
      "> for gap 50\n",
      "> for gap 100\n",
      "Engineering cursor position data\n",
      "> for gap 1\n",
      "> for gap 2\n",
      "> for gap 3\n",
      "> for gap 5\n",
      "> for gap 10\n",
      "> for gap 20\n",
      "> for gap 50\n",
      "> for gap 100\n",
      "Engineering word count data\n",
      "> for gap 1\n",
      "> for gap 2\n",
      "> for gap 3\n",
      "> for gap 5\n",
      "> for gap 10\n",
      "> for gap 20\n",
      "> for gap 50\n",
      "> for gap 100\n",
      "Engineering statistical summaries for features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:01<00:00, 17.62it/s, column=word_count_change100, method=skew]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineering activity counts data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 19388.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineering event counts data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 17476.27it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 19269.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineering text change counts data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 17722.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineering punctuation counts data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 20004.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineering input words data\n",
      "Engineering ratios data\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "preprocessor = Preprocessor(seed=42)\n",
    "\n",
    "print(\"Engineering features for training data\")\n",
    "\n",
    "other_train_feats = preprocessor.make_feats(traindf)\n",
    "\n",
    "print()\n",
    "print(\"-\"*25)\n",
    "print(\"Engineering features for test data\")\n",
    "print(\"-\"*25)\n",
    "other_test_feats = preprocessor.make_feats(testdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "355e4bd5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T09:39:08.857238Z",
     "iopub.status.busy": "2024-01-08T09:39:08.856732Z",
     "iopub.status.idle": "2024-01-08T09:39:08.879970Z",
     "shell.execute_reply": "2024-01-08T09:39:08.878931Z"
    },
    "papermill": {
     "duration": 0.267145,
     "end_time": "2024-01-08T09:39:08.882700",
     "exception": false,
     "start_time": "2024-01-08T09:39:08.615555",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train_all = pd.DataFrame()\n",
    "df_test_all = pd.DataFrame()\n",
    "\n",
    "df_train_all = df_train.merge(train_agg_fe_df,on='id')\n",
    "df_test_all = df_test.merge(test_agg_fe_df,on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "74c75b6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T09:39:09.364276Z",
     "iopub.status.busy": "2024-01-08T09:39:09.363812Z",
     "iopub.status.idle": "2024-01-08T09:39:09.369353Z",
     "shell.execute_reply": "2024-01-08T09:39:09.368258Z"
    },
    "papermill": {
     "duration": 0.250958,
     "end_time": "2024-01-08T09:39:09.371801",
     "exception": false,
     "start_time": "2024-01-08T09:39:09.120843",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def q1(x):\n",
    "    return x.quantile(0.25)\n",
    "def q3(x):\n",
    "    return x.quantile(0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4e1619d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T09:39:09.850928Z",
     "iopub.status.busy": "2024-01-08T09:39:09.850447Z",
     "iopub.status.idle": "2024-01-08T09:39:09.869820Z",
     "shell.execute_reply": "2024-01-08T09:39:09.868403Z"
    },
    "papermill": {
     "duration": 0.262125,
     "end_time": "2024-01-08T09:39:09.872249",
     "exception": false,
     "start_time": "2024-01-08T09:39:09.610124",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "AGGREGATIONS = ['count', 'mean', 'std', 'min', 'max', 'first', 'last', 'sem', q1, 'median', q3, 'skew', 'sum']\n",
    "\n",
    "def split_essays_into_sentences(df):\n",
    "    essay_df = df\n",
    "    essay_df['id'] = essay_df.index\n",
    "    essay_df['sent'] = essay_df['essay'].apply(lambda x: re.split('\\\\.|\\\\?|\\\\!',str(x)))\n",
    "    essay_df = essay_df.explode('sent')\n",
    "    essay_df['sent'] = essay_df['sent'].apply(lambda x: x.replace('\\n','').strip())\n",
    "    # Number of characters in sentences\n",
    "    essay_df['sent_len'] = essay_df['sent'].apply(lambda x: len(x))\n",
    "    # Number of words in sentences\n",
    "    essay_df['sent_word_count'] = essay_df['sent'].apply(lambda x: len(x.split(' ')))\n",
    "    essay_df = essay_df[essay_df.columns.tolist()].reset_index(drop=True)\n",
    "    return essay_df\n",
    "\n",
    "def compute_sentence_aggregations(df):\n",
    "    sent_agg_df = pd.concat(\n",
    "        [df[['id','sent_len']].groupby(['id']).agg(AGGREGATIONS), df[['id','sent_word_count']].groupby(['id']).agg(AGGREGATIONS)], axis=1\n",
    "    )\n",
    "    sent_agg_df.columns = ['_'.join(x) for x in sent_agg_df.columns]\n",
    "    sent_agg_df['id'] = sent_agg_df.index\n",
    "    sent_agg_df = sent_agg_df.reset_index(drop=True)\n",
    "    sent_agg_df.drop(columns=[\"sent_word_count_count\"], inplace=True)\n",
    "    sent_agg_df = sent_agg_df.rename(columns={\"sent_len_count\":\"sent_count\"})\n",
    "    return sent_agg_df\n",
    "\n",
    "def split_essays_into_paragraphs(df):\n",
    "    essay_df = df\n",
    "    essay_df['id'] = essay_df.index\n",
    "    essay_df['paragraph'] = essay_df['essay'].apply(lambda x: str(x).split('\\n'))\n",
    "    essay_df = essay_df.explode('paragraph')\n",
    "    # Number of characters in paragraphs\n",
    "    essay_df['paragraph_len'] = essay_df['paragraph'].apply(lambda x: len(x)) \n",
    "    # Number of words in paragraphs\n",
    "    essay_df['paragraph_word_count'] = essay_df['paragraph'].apply(lambda x: len(x.split(' ')))\n",
    "    essay_df = essay_df[essay_df.paragraph_len!=0].reset_index(drop=True)\n",
    "    return essay_df\n",
    "\n",
    "def compute_paragraph_aggregations(df):\n",
    "    paragraph_agg_df = pd.concat(\n",
    "        [df[['id','paragraph_len']].groupby(['id']).agg(AGGREGATIONS), df[['id','paragraph_word_count']].groupby(['id']).agg(AGGREGATIONS)], axis=1\n",
    "    ) \n",
    "    paragraph_agg_df.columns = ['_'.join(x) for x in paragraph_agg_df.columns]\n",
    "    paragraph_agg_df['id'] = paragraph_agg_df.index\n",
    "    paragraph_agg_df = paragraph_agg_df.reset_index(drop=True)\n",
    "    paragraph_agg_df.drop(columns=[\"paragraph_word_count_count\"], inplace=True)\n",
    "    paragraph_agg_df = paragraph_agg_df.rename(columns={\"paragraph_len_count\":\"paragraph_count\"})\n",
    "    return paragraph_agg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "af8e7e7d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T09:39:10.349085Z",
     "iopub.status.busy": "2024-01-08T09:39:10.348437Z",
     "iopub.status.idle": "2024-01-08T09:39:26.162259Z",
     "shell.execute_reply": "2024-01-08T09:39:26.161187Z"
    },
    "papermill": {
     "duration": 16.054573,
     "end_time": "2024-01-08T09:39:26.165286",
     "exception": false,
     "start_time": "2024-01-08T09:39:10.110713",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_sent_df = split_essays_into_sentences(train_essaysdf)\n",
    "train_sent_agg_df = compute_sentence_aggregations(train_sent_df)\n",
    "\n",
    "train_paragraph_df = split_essays_into_paragraphs(train_essaysdf)\n",
    "train_paragraph_agg_df = compute_paragraph_aggregations(train_paragraph_df)\n",
    "\n",
    "test_sent_agg_df = compute_sentence_aggregations(split_essays_into_sentences(test_essaysdf))\n",
    "test_paragraph_agg_df = compute_paragraph_aggregations(split_essays_into_paragraphs(test_essaysdf))\n",
    "\n",
    "train_paragraph_agg_df.loc[:, 'id'] = df_train_index\n",
    "train_sent_agg_df.loc[:, 'id'] = df_train_index\n",
    "\n",
    "test_paragraph_agg_df.loc[:, 'id'] = df_test_index\n",
    "test_sent_agg_df.loc[:, 'id'] = df_test_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b9da94e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T09:39:26.645293Z",
     "iopub.status.busy": "2024-01-08T09:39:26.644837Z",
     "iopub.status.idle": "2024-01-08T09:39:26.762387Z",
     "shell.execute_reply": "2024-01-08T09:39:26.760949Z"
    },
    "papermill": {
     "duration": 0.362166,
     "end_time": "2024-01-08T09:39:26.765551",
     "exception": false,
     "start_time": "2024-01-08T09:39:26.403385",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_train_feats = pd.DataFrame()\n",
    "new_test_feats = pd.DataFrame()\n",
    "\n",
    "new_train_feats = train_paragraph_agg_df.merge(df_train_all,on='id')\n",
    "new_train_feats = new_train_feats.merge(train_sent_agg_df,on='id')\n",
    "\n",
    "new_test_feats = test_paragraph_agg_df.merge(df_test_all,on='id')\n",
    "new_test_feats = new_test_feats.merge(test_sent_agg_df,on='id')\n",
    "\n",
    "train_feats = pd.DataFrame()\n",
    "test_feats = pd.DataFrame()\n",
    "\n",
    "train_feats = new_train_feats.merge(other_train_feats,on='id')\n",
    "test_feats = new_test_feats.merge(other_test_feats,on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0ec7fe40",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T09:39:27.246162Z",
     "iopub.status.busy": "2024-01-08T09:39:27.245735Z",
     "iopub.status.idle": "2024-01-08T09:39:39.366597Z",
     "shell.execute_reply": "2024-01-08T09:39:39.365384Z"
    },
    "papermill": {
     "duration": 12.36312,
     "end_time": "2024-01-08T09:39:39.369550",
     "exception": false,
     "start_time": "2024-01-08T09:39:27.006430",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for logs in [traindf, testdf]:\n",
    "    logs['up_time_lagged'] = logs.groupby('id')['up_time'].shift(1).fillna(logs['down_time'])\n",
    "    logs['time_diff'] = abs(logs['down_time'] - logs['up_time_lagged']) / 1000\n",
    "\n",
    "    group = logs.groupby('id')['time_diff']\n",
    "    largest_lantency = group.max()\n",
    "    smallest_lantency = group.min()\n",
    "    median_lantency = group.median()\n",
    "    initial_pause = logs.groupby('id')['down_time'].first() / 1000\n",
    "    pauses_half_sec = group.apply(lambda x: ((x > 0.5) & (x < 1)).sum())\n",
    "    pauses_1_sec = group.apply(lambda x: ((x > 1) & (x < 1.5)).sum())\n",
    "    pauses_1_half_sec = group.apply(lambda x: ((x > 1.5) & (x < 2)).sum())\n",
    "    pauses_2_sec = group.apply(lambda x: ((x > 2) & (x < 3)).sum())\n",
    "    pauses_3_sec = group.apply(lambda x: (x > 3).sum())\n",
    "\n",
    "    data.append(pd.DataFrame({\n",
    "        'id': logs['id'].unique(),\n",
    "        'largest_lantency': largest_lantency,\n",
    "        'smallest_lantency': smallest_lantency,\n",
    "        'median_lantency': median_lantency,\n",
    "        'initial_pause': initial_pause,\n",
    "        'pauses_half_sec': pauses_half_sec,\n",
    "        'pauses_1_sec': pauses_1_sec,\n",
    "        'pauses_1_half_sec': pauses_1_half_sec,\n",
    "        'pauses_2_sec': pauses_2_sec,\n",
    "        'pauses_3_sec': pauses_3_sec,\n",
    "    }).reset_index(drop=True))\n",
    "\n",
    "train_eD592674, test_eD592674 = data\n",
    "\n",
    "train_feats = train_feats.merge(train_eD592674, on='id', how='left')\n",
    "test_feats = test_feats.merge(test_eD592674, on='id', how='left')\n",
    "train_feats = train_feats.merge(train_scores, on='id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "98f041bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T09:39:39.845418Z",
     "iopub.status.busy": "2024-01-08T09:39:39.845005Z",
     "iopub.status.idle": "2024-01-08T09:39:39.852984Z",
     "shell.execute_reply": "2024-01-08T09:39:39.851972Z"
    },
    "papermill": {
     "duration": 0.250854,
     "end_time": "2024-01-08T09:39:39.855464",
     "exception": false,
     "start_time": "2024-01-08T09:39:39.604610",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "train_feats['score_class'] = le.fit_transform(train_feats['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a31d7cf3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T09:39:40.336488Z",
     "iopub.status.busy": "2024-01-08T09:39:40.336095Z",
     "iopub.status.idle": "2024-01-08T09:39:40.342488Z",
     "shell.execute_reply": "2024-01-08T09:39:40.341318Z"
    },
    "papermill": {
     "duration": 0.249783,
     "end_time": "2024-01-08T09:39:40.344903",
     "exception": false,
     "start_time": "2024-01-08T09:39:40.095120",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_col = ['score']\n",
    "\n",
    "drop_cols = ['id', 'score_class']\n",
    "train_cols = list()\n",
    "\n",
    "train_cols = [col for col in train_feats.columns if col not in target_col + drop_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6a847fe5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T09:39:40.829582Z",
     "iopub.status.busy": "2024-01-08T09:39:40.828861Z",
     "iopub.status.idle": "2024-01-08T09:39:41.018755Z",
     "shell.execute_reply": "2024-01-08T09:39:41.017620Z"
    },
    "papermill": {
     "duration": 0.438243,
     "end_time": "2024-01-08T09:39:41.021401",
     "exception": false,
     "start_time": "2024-01-08T09:39:40.583158",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2471, 659), (3, 657))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nan_cols = train_feats.columns[train_feats.isna().any()].tolist()\n",
    "\n",
    "# 결측치 최빈값으로 처리 \n",
    "for col in nan_cols:\n",
    "    mode_value_train = train_feats[col].mode()[0] #최빈값 여러 개 일 경우 첫 번째꺼 선택 \n",
    "    train_feats[col].fillna(mode_value_train, inplace=True)\n",
    "    \n",
    "for col in test_feats.columns[test_feats.isna().any()].tolist():\n",
    "    # Find the most frequent value in the training set for the current feature\n",
    "    most_frequent_value_train = train_feats[col].mode()[0]\n",
    "    \n",
    "    # Fill missing values in the test set with the most frequent value from the training set\n",
    "    test_feats[col].fillna(most_frequent_value_train, inplace=True)\n",
    "\n",
    "train_feats.shape, test_feats.shape   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "58e198f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T09:39:41.604597Z",
     "iopub.status.busy": "2024-01-08T09:39:41.604171Z",
     "iopub.status.idle": "2024-01-08T09:39:41.611535Z",
     "shell.execute_reply": "2024-01-08T09:39:41.610628Z"
    },
    "papermill": {
     "duration": 0.251763,
     "end_time": "2024-01-08T09:39:41.613639",
     "exception": false,
     "start_time": "2024-01-08T09:39:41.361876",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score', 'score_class'}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(train_feats.columns) - set(test_feats.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bf247450",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T09:39:42.097840Z",
     "iopub.status.busy": "2024-01-08T09:39:42.097396Z",
     "iopub.status.idle": "2024-01-08T09:39:42.102099Z",
     "shell.execute_reply": "2024-01-08T09:39:42.101182Z"
    },
    "papermill": {
     "duration": 0.250112,
     "end_time": "2024-01-08T09:39:42.104461",
     "exception": false,
     "start_time": "2024-01-08T09:39:41.854349",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_memory():\n",
    "    import gc\n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a808fdbd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T09:39:42.589381Z",
     "iopub.status.busy": "2024-01-08T09:39:42.588441Z",
     "iopub.status.idle": "2024-01-08T09:39:42.787097Z",
     "shell.execute_reply": "2024-01-08T09:39:42.785947Z"
    },
    "papermill": {
     "duration": 0.444949,
     "end_time": "2024-01-08T09:39:42.789956",
     "exception": false,
     "start_time": "2024-01-08T09:39:42.345007",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "clean_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "25665f02",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T09:39:43.268312Z",
     "iopub.status.busy": "2024-01-08T09:39:43.267633Z",
     "iopub.status.idle": "2024-01-08T09:39:43.272200Z",
     "shell.execute_reply": "2024-01-08T09:39:43.271139Z"
    },
    "papermill": {
     "duration": 0.245208,
     "end_time": "2024-01-08T09:39:43.274460",
     "exception": false,
     "start_time": "2024-01-08T09:39:43.029252",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "629b3ab2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T09:39:43.745182Z",
     "iopub.status.busy": "2024-01-08T09:39:43.744725Z",
     "iopub.status.idle": "2024-01-08T09:47:44.077119Z",
     "shell.execute_reply": "2024-01-08T09:47:44.075413Z"
    },
    "papermill": {
     "duration": 480.833694,
     "end_time": "2024-01-08T09:47:44.343227",
     "exception": false,
     "start_time": "2024-01-08T09:39:43.509533",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-\n",
      "Fold :  0\n",
      "Trian : (2223, 656) (2223, 1)\n",
      "Valid : (248, 656) (248, 1)\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=0.5420247656839267 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=0.9778252382803456 will be ignored. Current value: bagging_fraction=0.75\n",
      "Fold RMSE Score :  0.5761343114934508\n",
      "==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-\n",
      "Fold :  1\n",
      "Trian : (2224, 656) (2224, 1)\n",
      "Valid : (247, 656) (247, 1)\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=0.5420247656839267 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=0.9778252382803456 will be ignored. Current value: bagging_fraction=0.75\n",
      "Fold RMSE Score :  0.5164412370397702\n",
      "==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-\n",
      "Fold :  2\n",
      "Trian : (2224, 656) (2224, 1)\n",
      "Valid : (247, 656) (247, 1)\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=0.5420247656839267 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=0.9778252382803456 will be ignored. Current value: bagging_fraction=0.75\n",
      "Fold RMSE Score :  0.6792416920435415\n",
      "==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-\n",
      "Fold :  3\n",
      "Trian : (2224, 656) (2224, 1)\n",
      "Valid : (247, 656) (247, 1)\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=0.5420247656839267 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=0.9778252382803456 will be ignored. Current value: bagging_fraction=0.75\n",
      "Fold RMSE Score :  0.6185366928305793\n",
      "==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-\n",
      "Fold :  4\n",
      "Trian : (2224, 656) (2224, 1)\n",
      "Valid : (247, 656) (247, 1)\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=0.5420247656839267 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=0.9778252382803456 will be ignored. Current value: bagging_fraction=0.75\n",
      "Fold RMSE Score :  0.5887130937420096\n",
      "==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-\n",
      "Fold :  5\n",
      "Trian : (2224, 656) (2224, 1)\n",
      "Valid : (247, 656) (247, 1)\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=0.5420247656839267 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=0.9778252382803456 will be ignored. Current value: bagging_fraction=0.75\n",
      "Fold RMSE Score :  0.615207319972338\n",
      "==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-\n",
      "Fold :  6\n",
      "Trian : (2224, 656) (2224, 1)\n",
      "Valid : (247, 656) (247, 1)\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=0.5420247656839267 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=0.9778252382803456 will be ignored. Current value: bagging_fraction=0.75\n",
      "Fold RMSE Score :  0.6394176547128833\n",
      "==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-\n",
      "Fold :  7\n",
      "Trian : (2224, 656) (2224, 1)\n",
      "Valid : (247, 656) (247, 1)\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=0.5420247656839267 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=0.9778252382803456 will be ignored. Current value: bagging_fraction=0.75\n",
      "Fold RMSE Score :  0.6397020230833665\n",
      "==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-\n",
      "Fold :  8\n",
      "Trian : (2224, 656) (2224, 1)\n",
      "Valid : (247, 656) (247, 1)\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=0.5420247656839267 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=0.9778252382803456 will be ignored. Current value: bagging_fraction=0.75\n",
      "Fold RMSE Score :  0.6327619885996455\n",
      "==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-\n",
      "Fold :  9\n",
      "Trian : (2224, 656) (2224, 1)\n",
      "Valid : (247, 656) (247, 1)\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=0.5420247656839267 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=0.9778252382803456 will be ignored. Current value: bagging_fraction=0.75\n",
      "Fold RMSE Score :  0.559869996749793\n",
      "OOF RMSE Score :  0.6082289236472326\n",
      "==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-\n",
      "Fold :  0\n",
      "Trian : (2223, 656) (2223, 1)\n",
      "Valid : (248, 656) (248, 1)\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=0.5420247656839267 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=0.9778252382803456 will be ignored. Current value: bagging_fraction=0.75\n",
      "Fold RMSE Score :  0.5943540311773639\n",
      "==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-\n",
      "Fold :  1\n",
      "Trian : (2224, 656) (2224, 1)\n",
      "Valid : (247, 656) (247, 1)\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=0.5420247656839267 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=0.9778252382803456 will be ignored. Current value: bagging_fraction=0.75\n",
      "Fold RMSE Score :  0.583150046754761\n",
      "==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-\n",
      "Fold :  2\n",
      "Trian : (2224, 656) (2224, 1)\n",
      "Valid : (247, 656) (247, 1)\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=0.5420247656839267 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=0.9778252382803456 will be ignored. Current value: bagging_fraction=0.75\n",
      "Fold RMSE Score :  0.5672169212883619\n",
      "==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-\n",
      "Fold :  3\n",
      "Trian : (2224, 656) (2224, 1)\n",
      "Valid : (247, 656) (247, 1)\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=0.5420247656839267 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=0.9778252382803456 will be ignored. Current value: bagging_fraction=0.75\n",
      "Fold RMSE Score :  0.5930418035485244\n",
      "==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-\n",
      "Fold :  4\n",
      "Trian : (2224, 656) (2224, 1)\n",
      "Valid : (247, 656) (247, 1)\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=0.5420247656839267 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=0.9778252382803456 will be ignored. Current value: bagging_fraction=0.75\n",
      "Fold RMSE Score :  0.6104909633804227\n",
      "==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-\n",
      "Fold :  5\n",
      "Trian : (2224, 656) (2224, 1)\n",
      "Valid : (247, 656) (247, 1)\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=0.5420247656839267 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=0.9778252382803456 will be ignored. Current value: bagging_fraction=0.75\n",
      "Fold RMSE Score :  0.6354386000455576\n",
      "==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-\n",
      "Fold :  6\n",
      "Trian : (2224, 656) (2224, 1)\n",
      "Valid : (247, 656) (247, 1)\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=0.5420247656839267 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=0.9778252382803456 will be ignored. Current value: bagging_fraction=0.75\n",
      "Fold RMSE Score :  0.6373645137285746\n",
      "==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-\n",
      "Fold :  7\n",
      "Trian : (2224, 656) (2224, 1)\n",
      "Valid : (247, 656) (247, 1)\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=0.5420247656839267 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=0.9778252382803456 will be ignored. Current value: bagging_fraction=0.75\n",
      "Fold RMSE Score :  0.5767688411951472\n",
      "==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-\n",
      "Fold :  8\n",
      "Trian : (2224, 656) (2224, 1)\n",
      "Valid : (247, 656) (247, 1)\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=0.5420247656839267 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=0.9778252382803456 will be ignored. Current value: bagging_fraction=0.75\n",
      "Fold RMSE Score :  0.6580358756174901\n",
      "==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-\n",
      "Fold :  9\n",
      "Trian : (2224, 656) (2224, 1)\n",
      "Valid : (247, 656) (247, 1)\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=0.5420247656839267 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=0.9778252382803456 will be ignored. Current value: bagging_fraction=0.75\n",
      "Fold RMSE Score :  0.631669806322409\n",
      "OOF RMSE Score :  0.6094321972729696\n",
      "==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-\n",
      "Fold :  0\n",
      "Trian : (2223, 656) (2223, 1)\n",
      "Valid : (248, 656) (248, 1)\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=0.5420247656839267 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=0.9778252382803456 will be ignored. Current value: bagging_fraction=0.75\n",
      "Fold RMSE Score :  0.6786372516088968\n",
      "==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-\n",
      "Fold :  1\n",
      "Trian : (2224, 656) (2224, 1)\n",
      "Valid : (247, 656) (247, 1)\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=0.5420247656839267 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=0.9778252382803456 will be ignored. Current value: bagging_fraction=0.75\n",
      "Fold RMSE Score :  0.5884124710217634\n",
      "==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-\n",
      "Fold :  2\n",
      "Trian : (2224, 656) (2224, 1)\n",
      "Valid : (247, 656) (247, 1)\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=0.5420247656839267 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=0.9778252382803456 will be ignored. Current value: bagging_fraction=0.75\n",
      "Fold RMSE Score :  0.5708841149389373\n",
      "==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-\n",
      "Fold :  3\n",
      "Trian : (2224, 656) (2224, 1)\n",
      "Valid : (247, 656) (247, 1)\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=0.5420247656839267 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=0.9778252382803456 will be ignored. Current value: bagging_fraction=0.75\n",
      "Fold RMSE Score :  0.5864761076464314\n",
      "==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-\n",
      "Fold :  4\n",
      "Trian : (2224, 656) (2224, 1)\n",
      "Valid : (247, 656) (247, 1)\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=0.5420247656839267 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=0.9778252382803456 will be ignored. Current value: bagging_fraction=0.75\n",
      "Fold RMSE Score :  0.5760307275102077\n",
      "==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-\n",
      "Fold :  5\n",
      "Trian : (2224, 656) (2224, 1)\n",
      "Valid : (247, 656) (247, 1)\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=0.5420247656839267 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=0.9778252382803456 will be ignored. Current value: bagging_fraction=0.75\n",
      "Fold RMSE Score :  0.6049517550576012\n",
      "==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-\n",
      "Fold :  6\n",
      "Trian : (2224, 656) (2224, 1)\n",
      "Valid : (247, 656) (247, 1)\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=0.5420247656839267 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=0.9778252382803456 will be ignored. Current value: bagging_fraction=0.75\n",
      "Fold RMSE Score :  0.6813707041975821\n",
      "==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-\n",
      "Fold :  7\n",
      "Trian : (2224, 656) (2224, 1)\n",
      "Valid : (247, 656) (247, 1)\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=0.5420247656839267 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=0.9778252382803456 will be ignored. Current value: bagging_fraction=0.75\n",
      "Fold RMSE Score :  0.5618251900774653\n",
      "==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-\n",
      "Fold :  8\n",
      "Trian : (2224, 656) (2224, 1)\n",
      "Valid : (247, 656) (247, 1)\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=0.5420247656839267 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=0.9778252382803456 will be ignored. Current value: bagging_fraction=0.75\n",
      "Fold RMSE Score :  0.6468209508053815\n",
      "==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-\n",
      "Fold :  9\n",
      "Trian : (2224, 656) (2224, 1)\n",
      "Valid : (247, 656) (247, 1)\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=0.5420247656839267 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=0.9778252382803456 will be ignored. Current value: bagging_fraction=0.75\n",
      "Fold RMSE Score :  0.5995840847615153\n",
      "OOF RMSE Score :  0.6109471405152701\n",
      "==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-\n",
      "Fold :  0\n",
      "Trian : (2223, 656) (2223, 1)\n",
      "Valid : (248, 656) (248, 1)\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=0.5420247656839267 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=0.9778252382803456 will be ignored. Current value: bagging_fraction=0.75\n",
      "Fold RMSE Score :  0.615086785200718\n",
      "==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-\n",
      "Fold :  1\n",
      "Trian : (2224, 656) (2224, 1)\n",
      "Valid : (247, 656) (247, 1)\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=0.5420247656839267 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=0.9778252382803456 will be ignored. Current value: bagging_fraction=0.75\n",
      "Fold RMSE Score :  0.5897888336781285\n",
      "==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-\n",
      "Fold :  2\n",
      "Trian : (2224, 656) (2224, 1)\n",
      "Valid : (247, 656) (247, 1)\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=0.5420247656839267 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=0.9778252382803456 will be ignored. Current value: bagging_fraction=0.75\n",
      "Fold RMSE Score :  0.6174194824847233\n",
      "==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-\n",
      "Fold :  3\n",
      "Trian : (2224, 656) (2224, 1)\n",
      "Valid : (247, 656) (247, 1)\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=0.5420247656839267 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=0.9778252382803456 will be ignored. Current value: bagging_fraction=0.75\n",
      "Fold RMSE Score :  0.6054803523960337\n",
      "==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-\n",
      "Fold :  4\n",
      "Trian : (2224, 656) (2224, 1)\n",
      "Valid : (247, 656) (247, 1)\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=0.5420247656839267 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=0.9778252382803456 will be ignored. Current value: bagging_fraction=0.75\n",
      "Fold RMSE Score :  0.6450930051132586\n",
      "==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-\n",
      "Fold :  5\n",
      "Trian : (2224, 656) (2224, 1)\n",
      "Valid : (247, 656) (247, 1)\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=0.5420247656839267 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=0.9778252382803456 will be ignored. Current value: bagging_fraction=0.75\n",
      "Fold RMSE Score :  0.5562605236752971\n",
      "==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-\n",
      "Fold :  6\n",
      "Trian : (2224, 656) (2224, 1)\n",
      "Valid : (247, 656) (247, 1)\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=0.5420247656839267 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=0.9778252382803456 will be ignored. Current value: bagging_fraction=0.75\n",
      "Fold RMSE Score :  0.6325833517239688\n",
      "==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-\n",
      "Fold :  7\n",
      "Trian : (2224, 656) (2224, 1)\n",
      "Valid : (247, 656) (247, 1)\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=0.5420247656839267 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=0.9778252382803456 will be ignored. Current value: bagging_fraction=0.75\n",
      "Fold RMSE Score :  0.614013326232436\n",
      "==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-\n",
      "Fold :  8\n",
      "Trian : (2224, 656) (2224, 1)\n",
      "Valid : (247, 656) (247, 1)\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=0.5420247656839267 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=0.9778252382803456 will be ignored. Current value: bagging_fraction=0.75\n",
      "Fold RMSE Score :  0.6676455795160359\n",
      "==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-\n",
      "Fold :  9\n",
      "Trian : (2224, 656) (2224, 1)\n",
      "Valid : (247, 656) (247, 1)\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=0.5420247656839267 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=0.9778252382803456 will be ignored. Current value: bagging_fraction=0.75\n",
      "Fold RMSE Score :  0.5498456329723388\n",
      "OOF RMSE Score :  0.6103151010919755\n",
      "==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-\n",
      "Fold :  0\n",
      "Trian : (2223, 656) (2223, 1)\n",
      "Valid : (248, 656) (248, 1)\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=0.5420247656839267 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=0.9778252382803456 will be ignored. Current value: bagging_fraction=0.75\n",
      "Fold RMSE Score :  0.6008045242205295\n",
      "==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-\n",
      "Fold :  1\n",
      "Trian : (2224, 656) (2224, 1)\n",
      "Valid : (247, 656) (247, 1)\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=0.5420247656839267 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=0.9778252382803456 will be ignored. Current value: bagging_fraction=0.75\n",
      "Fold RMSE Score :  0.5770462235859576\n",
      "==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-\n",
      "Fold :  2\n",
      "Trian : (2224, 656) (2224, 1)\n",
      "Valid : (247, 656) (247, 1)\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=0.5420247656839267 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=0.9778252382803456 will be ignored. Current value: bagging_fraction=0.75\n",
      "Fold RMSE Score :  0.6234358977895229\n",
      "==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-\n",
      "Fold :  3\n",
      "Trian : (2224, 656) (2224, 1)\n",
      "Valid : (247, 656) (247, 1)\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=0.5420247656839267 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=0.9778252382803456 will be ignored. Current value: bagging_fraction=0.75\n",
      "Fold RMSE Score :  0.6008405060493279\n",
      "==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-\n",
      "Fold :  4\n",
      "Trian : (2224, 656) (2224, 1)\n",
      "Valid : (247, 656) (247, 1)\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=0.5420247656839267 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=0.9778252382803456 will be ignored. Current value: bagging_fraction=0.75\n",
      "Fold RMSE Score :  0.5785081636947155\n",
      "==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-\n",
      "Fold :  5\n",
      "Trian : (2224, 656) (2224, 1)\n",
      "Valid : (247, 656) (247, 1)\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=0.5420247656839267 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=0.9778252382803456 will be ignored. Current value: bagging_fraction=0.75\n",
      "Fold RMSE Score :  0.6489364528613356\n",
      "==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-\n",
      "Fold :  6\n",
      "Trian : (2224, 656) (2224, 1)\n",
      "Valid : (247, 656) (247, 1)\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=0.5420247656839267 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=0.9778252382803456 will be ignored. Current value: bagging_fraction=0.75\n",
      "Fold RMSE Score :  0.5980954073741542\n",
      "==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-\n",
      "Fold :  7\n",
      "Trian : (2224, 656) (2224, 1)\n",
      "Valid : (247, 656) (247, 1)\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=0.5420247656839267 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=0.9778252382803456 will be ignored. Current value: bagging_fraction=0.75\n",
      "Fold RMSE Score :  0.6242250870774921\n",
      "==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-\n",
      "Fold :  8\n",
      "Trian : (2224, 656) (2224, 1)\n",
      "Valid : (247, 656) (247, 1)\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=0.5420247656839267 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=0.9778252382803456 will be ignored. Current value: bagging_fraction=0.75\n",
      "Fold RMSE Score :  0.6387436561533243\n",
      "==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-==-\n",
      "Fold :  9\n",
      "Trian : (2224, 656) (2224, 1)\n",
      "Valid : (247, 656) (247, 1)\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=0.5420247656839267 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=0.9778252382803456 will be ignored. Current value: bagging_fraction=0.75\n",
      "Fold RMSE Score :  0.6148200038708784\n",
      "OOF RMSE Score :  0.6109617507293609\n"
     ]
    }
   ],
   "source": [
    "models_dict = {}\n",
    "scores = []\n",
    "\n",
    "test_predict_list = []\n",
    "best_params = {'boosting_type': 'gbdt', \n",
    "               'metric': 'rmse',\n",
    "               'reg_alpha': 0.003188447814669599, \n",
    "               'reg_lambda': 0.0010228604507564066, \n",
    "               'colsample_bytree': 0.5420247656839267, \n",
    "               'subsample': 0.9778252382803456, \n",
    "               'feature_fraction': 0.8,\n",
    "               'bagging_freq': 1,\n",
    "               'bagging_fraction': 0.75,\n",
    "               'learning_rate': 0.01716485155812008, \n",
    "               'num_leaves': 19, \n",
    "               'min_child_samples': 46,\n",
    "               'verbosity': -1,\n",
    "               'random_state': 42,\n",
    "               'n_estimators': 500,\n",
    "               'device_type': 'cpu'}\n",
    "\n",
    "for i in range(5): \n",
    "    kf = model_selection.KFold(n_splits=10, random_state=42 + i, shuffle=True)\n",
    "\n",
    "    oof_valid_preds = np.zeros(train_feats.shape[0], )\n",
    "\n",
    "    X_test = test_feats[train_cols]\n",
    "\n",
    "\n",
    "    for fold, (train_idx, valid_idx) in enumerate(kf.split(train_feats)):\n",
    "\n",
    "        print(\"==-\"* 50)\n",
    "        print(\"Fold : \", fold)\n",
    "\n",
    "        X_train, y_train = train_feats.iloc[train_idx][train_cols], train_feats.iloc[train_idx][target_col]\n",
    "        X_valid, y_valid = train_feats.iloc[valid_idx][train_cols], train_feats.iloc[valid_idx][target_col]\n",
    "\n",
    "        print(\"Trian :\", X_train.shape, y_train.shape)\n",
    "        print(\"Valid :\", X_valid.shape, y_valid.shape)\n",
    "\n",
    "        params = {\n",
    "            \"objective\": \"regression\",\n",
    "            \"metric\": \"rmse\",\n",
    "            'random_state': 42,\n",
    "            \"n_estimators\" : 12001,\n",
    "            \"verbosity\": -1,\n",
    "            \"device_type\": \"cpu\",\n",
    "            **best_params\n",
    "        }\n",
    "\n",
    "        model = lgb.LGBMRegressor(**params)\n",
    "\n",
    "        early_stopping_callback = lgb.early_stopping(200, first_metric_only=True, verbose=False)\n",
    "        verbose_callback = lgb.callback.record_evaluation({})\n",
    "\n",
    "        model.fit(X_train, y_train, eval_set=[(X_valid, y_valid)],  \n",
    "                  callbacks=[early_stopping_callback, verbose_callback],\n",
    "        )\n",
    "\n",
    "        valid_predict = model.predict(X_valid)\n",
    "        oof_valid_preds[valid_idx] = valid_predict\n",
    "\n",
    "        test_predict = model.predict(X_test)\n",
    "        test_predict_list.append(test_predict)\n",
    "\n",
    "        score = metrics.mean_squared_error(y_valid, valid_predict, squared=False)\n",
    "        print(\"Fold RMSE Score : \", score)\n",
    "\n",
    "        models_dict[f'{fold}_{i}'] = model\n",
    "\n",
    "\n",
    "    oof_score = metrics.mean_squared_error(train_feats[target_col], oof_valid_preds, squared=False)\n",
    "    scores.append(oof_score)\n",
    "    print(\"OOF RMSE Score : \", oof_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1fc83c77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T09:47:44.830204Z",
     "iopub.status.busy": "2024-01-08T09:47:44.829053Z",
     "iopub.status.idle": "2024-01-08T09:47:44.835966Z",
     "shell.execute_reply": "2024-01-08T09:47:44.835060Z"
    },
    "papermill": {
     "duration": 0.254638,
     "end_time": "2024-01-08T09:47:44.838587",
     "exception": false,
     "start_time": "2024-01-08T09:47:44.583949",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6099770226513618"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a79e27d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T09:47:45.424988Z",
     "iopub.status.busy": "2024-01-08T09:47:45.424284Z",
     "iopub.status.idle": "2024-01-08T09:47:45.439801Z",
     "shell.execute_reply": "2024-01-08T09:47:45.438669Z"
    },
    "papermill": {
     "duration": 0.260816,
     "end_time": "2024-01-08T09:47:45.442204",
     "exception": false,
     "start_time": "2024-01-08T09:47:45.181388",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000aaaa</td>\n",
       "      <td>1.500086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2222bbbb</td>\n",
       "      <td>1.471744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4444cccc</td>\n",
       "      <td>1.474145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id     score\n",
       "0  0000aaaa  1.500086\n",
       "1  2222bbbb  1.471744\n",
       "2  4444cccc  1.474145"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_feats['score'] = np.mean(test_predict_list, axis=0)\n",
    "sub3 = test_feats[['id', 'score']]\n",
    "sub3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "50d176ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T09:47:45.939369Z",
     "iopub.status.busy": "2024-01-08T09:47:45.938147Z",
     "iopub.status.idle": "2024-01-08T09:47:45.955049Z",
     "shell.execute_reply": "2024-01-08T09:47:45.953957Z"
    },
    "papermill": {
     "duration": 0.270228,
     "end_time": "2024-01-08T09:47:45.957848",
     "exception": false,
     "start_time": "2024-01-08T09:47:45.687620",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub1.rename(columns={'score': 'score_1'}, inplace=True)\n",
    "sub2.rename(columns={'score': 'score_2'}, inplace=True)\n",
    "sub3.rename(columns={'score': 'score_3'}, inplace=True)\n",
    "\n",
    "submission = pd.merge(sub1, sub2, on='id')\n",
    "submission = pd.merge(submission, sub3, on='id')\n",
    "\n",
    "submission['score'] = (submission['score_1']*0.2 +  #LGBM + NN (Weighted search for \"print(W)\")\n",
    "                       submission['score_2']*0.4 +  #LGBM Public\n",
    "                       submission['score_3']*0.4)   #Fusion\n",
    "\n",
    "submission_final = submission[['id', 'score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7fbc444a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T09:47:46.468179Z",
     "iopub.status.busy": "2024-01-08T09:47:46.466701Z",
     "iopub.status.idle": "2024-01-08T09:47:46.474906Z",
     "shell.execute_reply": "2024-01-08T09:47:46.473644Z"
    },
    "papermill": {
     "duration": 0.261016,
     "end_time": "2024-01-08T09:47:46.477765",
     "exception": false,
     "start_time": "2024-01-08T09:47:46.216749",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission_final.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e0c48f58",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T09:47:46.973209Z",
     "iopub.status.busy": "2024-01-08T09:47:46.972741Z",
     "iopub.status.idle": "2024-01-08T09:47:46.984510Z",
     "shell.execute_reply": "2024-01-08T09:47:46.983348Z"
    },
    "papermill": {
     "duration": 0.260947,
     "end_time": "2024-01-08T09:47:46.986981",
     "exception": false,
     "start_time": "2024-01-08T09:47:46.726034",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000aaaa</td>\n",
       "      <td>1.406839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2222bbbb</td>\n",
       "      <td>1.263909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4444cccc</td>\n",
       "      <td>1.201256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id     score\n",
       "0  0000aaaa  1.406839\n",
       "1  2222bbbb  1.263909\n",
       "2  4444cccc  1.201256"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7182425",
   "metadata": {
    "papermill": {
     "duration": 0.241275,
     "end_time": "2024-01-08T09:47:47.474599",
     "exception": false,
     "start_time": "2024-01-08T09:47:47.233324",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 6678907,
     "sourceId": 59291,
     "sourceType": "competition"
    },
    {
     "datasetId": 3949123,
     "sourceId": 6973319,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30626,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 17165.708545,
   "end_time": "2024-01-08T09:47:50.481581",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-01-08T05:01:44.773036",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
